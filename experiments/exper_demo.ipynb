{"cells":[{"cell_type":"markdown","metadata":{"id":"JddIWYuKhLwI"},"source":["# Distributed Vault Final Demo"]},{"cell_type":"markdown","metadata":{"id":"AyVzYN3xhQG8"},"source":["Here, we demonstrate some of the key features of our platform! To start, ensure that the rest of the files in the release are in the same folder as this notebook. The demo is intended to be ran on Google Colab through a mounted Google Drive, but it is possible for it to work on a local machine as well. Please read the set-up instructions for more information."]},{"cell_type":"markdown","metadata":{"id":"BDrZ9E1al4ev"},"source":["## Setup and imports"]},{"cell_type":"markdown","metadata":{"id":"uu8xRuc_cRtw"},"source":["We use Google Colab with Python 3. We recommend that you connect to a runtime with a GPU (most of the training was done on T4). If you are on Google Colab, please mount your drive and then run the cells below to install all dependencies."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29060,"status":"ok","timestamp":1738162592047,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"RpjjFDdI-D67","outputId":"67cb6af4-0bce-43ef-9a0e-56fd4ea0858c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":7750,"status":"ok","timestamp":1738129824451,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"bKYmlggAcVYO","outputId":"569e1de2-8456-4c98-de6b-e2c0a2a870eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting medmnist\n","  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.1.0)\n","Collecting fire (from medmnist)\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.20.1+cu121)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (2.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n","Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.13.1)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.36.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.1.10)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.12.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->medmnist) (12.8.61)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n","Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=a08cd6263070c7d658047956ebd843a470cb8e13981f62e97dda394d1f05a8b1\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","Successfully built fire\n","Installing collected packages: fire, medmnist\n","Successfully installed fire-0.7.0 medmnist-3.0.2\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.47.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.8.61)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"]}],"source":["%pip install medmnist\n","%pip install sentence-transformers scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"tjdayYG6nSsD"},"source":["You should insure that you are in the directory with the remainder of the files. On our drives, this folder is `/content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main`, but it will likely be different for you, so change the command in the cell below as needed. You might see warnings about a secret 'HF_Token', ignore this as we do not use one."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1738129824605,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"4edQQcJnnQkX","outputId":"083ca17a-4451-4271-b90b-c37da1570f6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/OneFL/OneFL-main/src\n"]}],"source":["import sys\n","#sys.path.append('/content/drive/MyDrive/OneFL/src')\n","%cd /content/drive/MyDrive/OneFL/OneFL-main/src"]},{"cell_type":"markdown","metadata":{"id":"9lJSS8QvoybR"},"source":["Import the following packages. Note that if you are not in the correct directory, the second half of the imports (local modules) will not import correctly."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496,"referenced_widgets":["e72e59ff077542bf955f4ef09e8d985b","f6710fa6bb764f348174162fa58ef85f","30b9a721f7834e4d9ce2637158f8c22b","0601eb475f474d819122d2aab6033ab5","ad7fbf5cb5644aa994049d1c26c038f7","17e5efb1fb644d79a3c8bbef4ab5e713","3b02e7fb0fde43d39e195c80174cd302","2b81c0edfd424ebf86ce57f5181a35ef","1e2d242258b74cd385eb1c1fb9fcba87","afc155a39d6140fdb044faca5163cc2a","062116cbb0bd44e79215ee61ff7e2862","03d51b68fd2f4b3bb671f1348670972c","6c3ba1f4a108478eb6c47fc03f298245","b7af2c03679443ffa731f672e85b91b6","1ba96aad754d45c382fa6bedb2b9666d","b4e3eea48f8045fbb1010a67b65baf48","53b9825d721b4dd697836864c3b462a3","60a6aacd70224b05ba8bd7b8c44398c7","9b4f9d602e2b44d787274710a36e483e","078b35207bf64d659bead32e92e4c17b","a8075bc29f4c494d98d9d44bfd74d079","31c0855f4cee47099003cb8ff4689cb0","606ef9e9d5d148d5b7980b02d0bcd4ef","c4525c4eed344707a222ebda07370ff2","29d442e983e14f1e898dcf51b69038cc","88bf7d7dd6394ba692d5bf60bc8529bf","0c12eb341aa84a9287ffc455ac9cdcfb","d79f846683cf48da9e22ddba3b53391a","8340ef952bb64b778c551b90b1c96614","c4864a55a0f6430d8c7035dc65fae9a6","4aa22beaa5d6450fbfb0e8ef2483eab6","199e6b169769479681358cdff06d48a1","4d42bb94e93445939dec5900c54b6d9e","dcbadc9f22e449b1a946838d63da3180","ac847d75070a4c46a439ca5a097159bd","08ff039e051b4b5da4b4e11d0b1305c7","1db710a5ef1c47dd8c347054066fa207","676b8b46c474407db6657fb4bbdb19fb","ffe708e312a84c3b923b79842591d727","2427897913f64b3b973eed0a784f57d6","67f011da12af4f2b80691595d4f346a4","ddde210d04c0419b8c08349341033d44","cf8ddbdaa6c84957bc91b767393ec023","694fe6b28aea4e38929ff388ac38c41d","64217dce8278444c8f46a0b034f6af7b","f716c47129a043e7b0bb9ace4a5425dd","279acabcc20240c4a3cf3975d9162f3c","7a8f21d0be194ada9d757e13ab4cfeda","5bd67a4956d54f809ecdd9a306f75423","6ad5946850b14549b88099aee912ab26","c518ed70cb5f4203a61987c27c40684a","e9494b76728f4f84b51aa89d8010f0b4","3a28fd9f8d784d23bdbd59ba1411ef63","b860f645ea2541d8ba2cfbddb23a9062","605fb77b34c14a74ad61e52235831bd9","d2b2ef83443440f8970a90339e726c1f","a302f88bcf06400eb65fc81c3d8bb3bd","06124c6a1a3341e4bdf894b25f158f98","0c36d1c7cf16414f866df2faace62b68","84c80a3bd7284cb8b53a6b35a2c68aaf","d3bb95adb9a144f0965ef60b5cf4c585","44e3fc4bca384e46820fca8e375623fb","d34b797bb3504521b94e6cc4175ba6c8","a35bfe9f1fdb4b0fb0e0143d12e38177","63d2e3a8e98c45349d88820fbf91b590","403caa4f5e16444182422e58808b10ab","667760e316e648fa8797c2a8dc90f0a1","35766f471d0f423bad81e7f9c09f47ab","a32bba96239a4296b1d560be00396c00","7b6e5bdab3e541d29b754b703e8ad4ab","4505de68ab704fe7becbac2e96589e94","497e662249e1470c993c7a503c735fc8","e1629ee018b044a8abb24dd876df0700","d4260183325e4714aee5787570d0ae1d","4e86bd969cae411b879048116ccb043b","f1cdaf5443394988ac481e00e46007e0","1c3e0ea5e2c746ccaee0b535449deeef","faf17580bb8a4516986835e0e08c3537","6800912879ba49238a501fcb48264546","afd1223b66404cf4acf652e67a70123e","310860f143f3412d8f77ab7fedd36099","8abf0042e2164af6911004b67fbf5fab","1deeccb91ec744569db28f0bd621e426","3554febdc74348b4b256fdb536037a81","02e28d7f9d8542f4bd8a85334ef49bca","6f5e1958a42e42f4a6d05cd8dc0316d9","8999697fd70f4c13a47b721b6f9b6164","ee3071c6f59d4b3aafa99e70845d4489","e899a4951c9d4a7fb967d141c0dcbede","3f16f2cfd45c414886dc68a4e9b5cf34","52cf5c7002664fe580dcd6f7a9e2bf62","0f421cc2e6124c38b6aac9d7c21a9647","60f76ea852e64b1db4a74e9d433a61b6","caf50034fb144fc4b1f8cd4ec92e7c4f","da4f18f408bc4f2698d929ade84358ff","a61104836a1d4573aae72ee8f2fd2a9c","80ebf767d72646ffb00c62c663740642","cc6b98cda2b94710810aad1e5c11514a","a77a05513da4483a8e7229623bbe0f59","865ee26bccea4487a08fb6ed3b0b8288","0004b56803a24a27bdb28dfa33b92f90","2715fefd1222474e87401e35e316b38b","28de121298b34888b5dfa5409481929c","f2f1567b1a924fdfa9294d3ba0d16bda","e1ffee9773e2419eb477c7d805c37c67","096754f92a0943bc9b5d8c05d2fa377e","73cbbb23fbf4465795a5b101541f81ba","040d6417172e44dd8d3b653235564239","f5d87904121248f998134ba9c164b36a","3eff7536f8ad4134bdb795268b8146f6","af9d1de993e14a6ead7b9bf4b29ad263","aa2cef53b5c94aadb65993b9e8643516","36d8d89d38e74a0a8c6a1752796b64ed","1f814c3783104cfaad874cce67030d18","5ade96e501dc4ab4992afd4c9fe35857","2b4ff6b93fb7466e82d779e3d9f40142","69ec8a1567c940e9b4c3d8589f068c6a","c84d656f95a64809a3e31dbbfcf79a35","218c3091ecfb4d5693159932c47d9e54","5c5b0e40c0ae41e796b24bbeb7c87bb3","896097a80d154dd29ec2998fc7478381"]},"executionInfo":{"elapsed":30792,"status":"ok","timestamp":1738129959799,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"FVHT-saEpzyD","outputId":"b5ace55b-0b19-4869-ecee-700ca47484f4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72e59ff077542bf955f4ef09e8d985b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03d51b68fd2f4b3bb671f1348670972c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606ef9e9d5d148d5b7980b02d0bcd4ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcbadc9f22e449b1a946838d63da3180"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64217dce8278444c8f46a0b034f6af7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2b2ef83443440f8970a90339e726c1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667760e316e648fa8797c2a8dc90f0a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf17580bb8a4516986835e0e08c3537"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e899a4951c9d4a7fb967d141c0dcbede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865ee26bccea4487a08fb6ed3b0b8288"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9d1de993e14a6ead7b9bf4b29ad263"}},"metadata":{}}],"source":["import tkinter as tk\n","from tkinter import messagebox\n","import spacy\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import torch\n","import os\n","from medmnist import INFO, BreastMNIST\n","from torchvision import transforms\n","import medmnist\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torchvision.models as models\n","import numpy as np\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","\n","# these are our modules!\n","import semantic_search as sems\n","import utils\n","from utils import fl_partition\n","import fedisca\n","from fedisca import FedISCA\n","from train_loc import LocalTrainer\n","from resnet import ResNet18, ResNet50"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1738129959799,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"J3AB6R5LNMHW"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"eNqahWnt-FM9"},"source":["## Set up federated scenario"]},{"cell_type":"markdown","metadata":{"id":"aCHrtEn0-UrU"},"source":["For the demo, we set up a specific federation scenario:\n","- 5 clients each with a local model\n","- Task: classification on the pneumoniamnist dataset (binary classification)\n","- Data split is non-iid (dirichlet with $\\beta=0.6$), so each distribution over the labels is different."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1139,"status":"ok","timestamp":1738130023325,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"XzBPSgNI-QRt","outputId":"89d26901-f7e9-449c-fbb6-51acabb8d1b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: ./pneumoniamnist.npz\n","Using downloaded and verified file: ./pneumoniamnist.npz\n","Using downloaded and verified file: ./pneumoniamnist.npz\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset PneumoniaMNIST of size 28 (pneumoniamnist)\n","    Number of datapoints: 4708\n","    Root location: ./\n","    Split: train\n","    Task: binary-class\n","    Number of channels: 1\n","    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n","    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n","    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n","    License: CC BY 4.0"]},"metadata":{},"execution_count":7}],"source":["data_flag = 'pneumoniamnist'\n","download = True\n","\n","info = medmnist.INFO[data_flag]\n","task = info['task']\n","n_channels = info['n_channels']\n","n_classes = len(info['label'])\n","\n","DataClass = getattr(medmnist, info['python_class'])\n","glb_train_dataset = DataClass(root=\"./\", split='train', download=download)\n","glb_val_dataset = DataClass(root=\"./\", split='val', download=download)\n","glb_test_dataset = DataClass(root=\"./\", split='test', download=download)\n","info[\"n_samples\"][\"train\"] = glb_train_dataset.imgs.shape[0]\n","info[\"n_samples\"][\"val\"] = glb_val_dataset.imgs.shape[0]\n","info[\"n_samples\"][\"test\"] = glb_test_dataset.imgs.shape[0]\n","glb_train_dataset"]},{"cell_type":"markdown","metadata":{"id":"4-Hrn_Pz_6lI"},"source":["Set up the partitioned dataset. This will create a folder called `pneumoniamnist_expr/sim_partitions_dirichlet` that contains subfolders 'client_0', ..., 'client_4'. Each client folder contains a unique .npz file that has a train and validation split that is a subset of the original training dataset."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1208,"status":"ok","timestamp":1738130026247,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"J-aLTykU_jtD"},"outputs":[],"source":["num_clients = 5\n","num_classes = 2\n","part_dir, list_name, split_ids = utils.fl_partition(\n","    glb_train_dataset,\n","    \"pneumonia\",\n","    num_clients,\n","    num_classes,\n","    iid=False,\n","    beta=0.6,\n","    val_split=0.2,\n","    seed=42\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1738116281310,"user":{"displayName":"Caleb Chin","userId":"06217181483891520714"},"user_tz":300},"id":"uBTAs441oVit","outputId":"d9eb780d-fde9-4c8f-d0ed-ffe7aeecc4d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["pneumonia_expr/sim_partitions_dirichlet\n"]}],"source":["print(part_dir)"]},{"cell_type":"markdown","metadata":{"id":"a6e1mS3fpee9"},"source":["We can visualize the label distribution"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1738130029852,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"},"user_tz":300},"id":"WSDt_TVGpidK","outputId":"aea79208-5e37-4897-ce7f-80b1c8309857"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x500 with 5 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAB1gAAAH7CAYAAABhUU1DAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXbRJREFUeJzt3XecFfW9P/7XAtKUIiBNpahEUQmiKGIFRbElFozx6o2oRA0Br8abGE3sjWgs2LGCJhpLEmsUC4JGRWzRa0FjQZaogCsBVJB6fn/4Y79uAD2wC7usz+fjcR5hP/OZmfecM+edffjamSkpFAqFAAAAAAAAAPCt6lR3AQAAAAAAAABrCgErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAsNI6deqUkpKSjBo1apXup6SkJCUlJat0H0t88MEHKSkpSadOnap0u3369ElJSUnGjRtXYfzII49cLe9hsdaUOpPkrLPOSklJSc4666zqLuUbzZw5M0OGDEnHjh1Tv379lJSUpE+fPtVa0/Leu3Hjxq10favze1rdKnOs36X3CQAAaisBKwAAQC2wvGB0TVWZoK+mOfbYY3PNNdekTp06OeiggzJw4MDstdde1V0Wy1GZ71Jt+x4CAADLVq+6CwAAAPguGzZsWE455ZS0a9euuktJktx6662ZM2dOOnToUN2lfKuhQ4fm0EMPTatWraq7lOVasGBB7rnnnjRs2DCvvvpqmjZtWt0lJVn+e7fddttl4sSJady4cTVVtmaYOHFitawLAADUDAJWAACAatSuXbsaE64mWSOC1SVatWpVo8PVJPn444+zcOHCrL/++jUmXE2W/941btw4m222WTVUtGapzHvk/QUAgDWfWwQDAACrzSeffJIrrrgi++yzTzp37pxGjRqladOm6dmzZy688MJ8+eWX37qNG264Idtss03WXnvtNG/ePPvss0+ee+655c5fuHBhbrzxxvTp0yctWrRIgwYN0rlz5wwePDhTpkypysPLlClTcvTRR6ddu3Zp2LBhunTpkt/+9reZO3fuctdZ3rNNFy9enOuvvz477rhjmjdvnrXWWiutW7dO9+7dc/zxx+eDDz5I8v9upfvkk08mSfr27Vv+jMevb/frz5ZdtGhRLr300vTo0SPrrLNOhedBFnOL01dffTUHHXRQ1ltvvTRq1Cjf//73c/nll2fRokVFH98So0aNSklJSY488sgKNfTt2zdJ8uSTT1Y4nq8/G/fbnsH6yCOPZL/99kvr1q1Tv379tG/fPj/+8Y/z4osvLnP+14/9lVdeyUEHHZRWrVqlQYMG2XzzzXPJJZekUCgs9335TyUlJenYsWOSZPLkyRWO4+vv78KFCzNixIjssMMOadasWfm58z//8z/58MMPl7vtJZ/byJEj07t37zRr1iwlJSXl58Y3WdlnsI4fPz577713mjdvnnXWWSc9e/bMzTff/K37W54lz3H+4IMPcs8992SnnXZK06ZN06RJk/Tp0ycPPfTQMtebPHlyLrzwwuy2227p0KFDGjRokObNm2ennXbKddddl8WLFy+1zrd9B4r9LiVLP0e1Mut+3YwZM/Kb3/wmW2yxRRo3bpwmTZpkm222yUUXXbTMPvL1z2vBggW58MILs8UWW6RRo0Zp2bJlDjroIFfMAgDAKuAKVgAAYLV55JFHcsIJJ2T99dfPJptsku233z6ffPJJJkyYkFNOOSX33Xdfxo4dmwYNGixz/ZNOOinDhw/PjjvumP333z+vvfZaHn744Tz22GO56667cuCBB1aY/9lnn+WHP/xhxo0bl3XWWSfbbLNN1ltvvbz22msZMWJE7r777jz22GPp0aNHpY/trbfeyq677prp06enXbt2+eEPf5gvvvgil112WcaOHbvC2/vpT3+akSNHpmHDhtlpp52y3nrrZcaMGXn//fdz1VVXZffdd0+nTp3Stm3bDBw4MKNHj860adPSv3//tG3btnw7m2yySYXtFgqFHHTQQRk9enR23nnndO3aNW+88UbRdT3//PMZPHhw2rZtm9133z3//ve/M27cuJx44ol5+umnc9dddy03PCrWXnvtlYYNG+aRRx5JmzZtKjyvtNgrVk8//fScd955KSkpyQ477JAOHTpk4sSJueuuu/KXv/wl119/fY4++uhlrvvII4/k0ksvzcYbb5w99tgjH3/8cZ5++un88pe/zJQpUzJ8+PCiahg4cGA+//zz/OUvf8naa6+dgw8+uHzZks9o3rx52W+//fL444+nYcOG6du3b5o2bZpnn302V155Zf70pz/lkUceydZbb73MfRx//PG55pprssMOO2TffffN+++/X+n3f3nuvvvu/Nd//VcWLVqULbfcMt26dcuUKVPy05/+dIXOoWW54oorctlll6Vnz57Zb7/98t577+XJJ5/Mk08+mSuuuCLHH398hfl/+MMfcvrpp6dz58753ve+lx133DEff/xxxo8fn2eeeSaPPvpo/vznPy/zvVjed2BFv0tfV5l1l3j//fez2267ZfLkyVlvvfWyzz77ZMGCBRk7dmx+/etf584778zjjz+eddddd6l1FyxYkH322SfPPvtsdtlll3Tt2jXPP/987rnnnowdOzb/+Mc/KvxxAgAAUEkFAACAldSxY8dCksLIkSOLmv/mm28Wxo8fv9T4jBkzCnvuuWchSeGiiy5aanmSQpJCo0aNCmPGjKmw7KKLLiokKTRr1qwwbdq0CssOO+ywQpLCfvvtt9Syyy67rJCk0KVLl8LChQvLxydNmlRIUujYsWNRx7TEtttuW0hSOOSQQwpz584tH588eXJh4403Lj+GsWPHVlhv4MCBS72HkydPLiQpbLDBBoWPP/54qX29+eabhcmTJ1cY23XXXZe5/f88riXbffvtt5c5b3nbWVJnksLPf/7zwoIFC8qXvf7664X11luvkKQwYsSIbz2+rxs5cmQhSWHgwIEVxseOHVtIUth1112XuV6hUCiceeaZhSSFM888s8L4ww8/XEhSaNiwYeHRRx+tsOzGG28sJCmstdZahddff32Zx76s4xgzZkyhpKSkULdu3cKUKVOWW9N/+rbz6de//nUhSWHjjTcuTJo0qXx8/vz5hUGDBhWSFDp37lyYN29ehfWW1Nm0adNlfqe+zfLeu+W97x9//HGhSZMmhSSFSy+9tMKyxx9/vNCwYcPymlbEkh5SUlJS+OMf/1hh2R133FEoKSkp1KtXr/Daa69VWPb8888vNVYoFAoffvhhoXv37oUkhbvuuqvCssp+B75uecdamXV79epVSFL44Q9/WPj888/Lx6dPn17YeuutC0kKhx12WIV1lnxeSQo9evSo0C/mzp1b6N+/fyFJ4dhjj11uPQAAwIpzi2AAAGC16dq1a7bffvulxtddd91ceeWVSb66Sm55jjvuuOy2224Vxn71q1+lZ8+emTVrVm688cby8YkTJ+ZPf/pT2rdvn9tvvz2tW7eusN6JJ56YffbZJ++8804efvjhyhxWnnnmmbzwwgtZe+21c80116Rhw4blyzp06JCLL754hbY3bdq0JMnWW29d4Sq4Jbp27VqpZ6VecMEF+d73vrdS67Zr1y6XXHJJ6tX7fzdE2mKLLXLGGWckSS655JKVrquqLHm/f/7zn2ePPfaosGzQoEHZb7/9smDBglx++eXLXP+ggw7KcccdV2Fst912S//+/bNo0aKVuiJ5Wb788stcffXVSZLLLruswhWGa621Vq644oq0adMmkyZNyp///OdlbuOXv/zlMr9TVe2mm27KZ599lu233z6/+MUvKizbfffdl3q/VtT++++fww8/vMLYj3/84xx00EFZuHBhrrjiigrLtt1222y55ZZLbad9+/a56KKLknxzL6nMd2BVePrppzNhwoQ0btw4119/fdZee+3yZeutt16uv/76JMkdd9yRf/3rX0utX1JSkpEjR1boFw0bNszZZ5+dJHn88cdX8REAAMB3i4AVAABYrRYtWpQxY8bk3HPPzc9//vMcddRROfLII3P++ecnSd5+++3lrjtw4MBljh9xxBFJUuG5lg899FAKhUL23nvvNGnSZJnrLXnO5LPPPrsSR/L/LNnvXnvtlZYtWy61fP/990+zZs2K3t5mm22WJk2a5KGHHsr555+fSZMmVaq+/zRgwICVXveQQw6pECAvseSzeeedd/LRRx+t9PYra+HChXnmmWeSpMJzXb9u0KBBSbLcoPQHP/jBMse7du2aJMt9LuqKevHFF/P555+nRYsWy9xn48aNc+ihh35jrV+/7fCqtOQc/88QdInlfTeLtbz1l4wv65nA8+bNywMPPJAzzjgjP/vZz8p7yXXXXZfkm3tJZb4Dq8LXe0ibNm2WWr7NNtuke/fuWbx4cflzXr+uQ4cO6d69+1LjVX3OAgAAX/EMVgAAYLV55513cuCBB37j8xpnz5693GWdO3f+xvGvX9n1/vvvJ/nqyrubbrrpG+v65JNPvnH5t1my3+XVV1JSkk6dOuXVV18tantNmjTJyJEjc9RRR+W0007Laaedlnbt2mX77bfPXnvtlcMOOyzrrLPOStXaunXrNG7ceKXWTZZ/jE2aNEnLli3z6aef5l//+lfat2+/0vuojE8//TRffvllkuXXuvHGGydZfui0vKuDmzZtmiTl26+sJftfXp3Jt9e6up6r+W3n+DcdQzFW5LudJM8991x+/OMfp7S0dLnbXF4vqex3YFUo9lx49dVXl3kufNs5O2/evCqoEgAAWELACgAArDYHH3xw3njjjey33345+eSTs/nmm6dp06ZZa621Mn/+/DRo0KBS2y8UCuX/Xrx4cZJkq622WuaVXV/Xq1evSu13VRgwYED69euX+++/P3//+9/zzDPP5J577sk999yTM844I4899li6deu2wttt1KjRKqi2oq9/Dt9myedUk9Sps+bc7Gl1fJ41wdfPqTlz5uSAAw7ItGnTctRRR2Xw4MHZZJNN0rRp09StWzf//Oc/s+mmmy73PKyN79madM4CAEBtIGAFAABWi7feeiv/93//l9atW+eee+6p8AzP5KurW7/NpEmTstVWWy01/sEHHyRJNthgg/KxDTfcMEmy44475qqrrlr5wouw/vrrV6hjWSZPnrzC223WrFl+8pOf5Cc/+UmSZMqUKTn++ONz3333ZejQocu8VeiqtrzbFX/22Wf59NNPk1T8HOrXr1++fFlW5n35Ji1btkyDBg0yb968vP/++/n+97+/1JwlVzcv+dyqy5L9f9MtoGtSrW+99dZyz/FvOveLMWnSpGX+IcSyvttPPfVUpk2blq233jo333zzUusU00tqmiWf75LPe1lqyrkAAAB4BisAALCazJgxI0nSvn37pcLVJPnjH//4rdv4wx/+8I3jS56pmiR77713kuT++++vslu6Ls+uu+6aJBk9enT5cX7d/fffn5kzZ1Z6PxtuuGHOPvvsJMkrr7xSYdmSIHPhwoWV3s83ufvuu5d5u9Eln8Emm2xSIQBa8u+JEycutU6hUMjDDz+8zP2s7PHUq1cvO+20U5Jk1KhRy5yzJJTr27fvCm27qvXs2TPrrLNOZsyYkfvvv3+p5XPnzs0dd9yRpPprXXKO33bbbctcfuutt1Zq+8v7bi/Z7te/20u+Y8u7LW4xveSbVOa7tLLrLjm+0aNHZ9q0aUst/8c//pFXXnklderUyS677LLCdQEAAFVLwAoAAKwW3/ve91K3bt289tprGTduXIVlDzzwQC677LJv3ca111671LqXXXZZnn/++TRp0iSDBg0qH+/Ro0cGDBiQKVOm5KCDDlrmFXZffPFFbrvttmUGGiti5513ztZbb53PP/88Q4YMqRBATpkyJb/85S9XaHv/+Mc/cuedd2bu3LlLLXvggQeSJB07dqwwvuQKv296vm1V+Oijj/LLX/4yixYtKh+bOHFizjnnnCTJL37xiwrz+/Xrl+SrAO3NN98sH1+wYEF+/etf54UXXljmfpYczzvvvJMFCxasUI3/+7//m+Sr82XMmDEVlo0aNSr3339/1lprrZxwwgkrtN2q1rBhwwwZMiTJVzV//WreBQsW5IQTTsjUqVPTuXPnHHzwwdVVZpJk0KBBWWeddTJ+/PhcccUVFZaNGzcuI0aMqNT277nnnvIweYk///nP+ctf/pJ69erl+OOPLx/v2rVrkmTMmDEVzqkkuf7663PnnXdWqpbKfJdWdt2ddtopvXr1yty5c3Pcccdlzpw55cvKyspy3HHHJUkOPfTQ8qvzAQCA6uMWwQAAQKWde+653xiwXHPNNdl6660zdOjQXH755dl9992z8847p3379nn77bfz8ssv57TTTst55533jfs57rjjsttuu2XnnXfO+uuvn9dffz2vvfZa6tatm5tvvjlt27atMH/kyJGZOXNmHn744Wy66abp3r17OnfunEKhkA8++CCvvvpq5s+fn4kTJ6ZNmzaVeg/+8Ic/pE+fPrnjjjvy1FNPZaeddsqcOXPyxBNP5Pvf/35atWqV8ePHF7WtyZMn59BDD02jRo2y9dZbZ8MNN8zChQvz2muv5e233079+vVz0UUXVVhnwIABGTlyZE4++eQ8/vjjad26dUpKSnL00Udnhx12qNSxfd3Pfvaz3Hjjjfnb3/6WXr165d///nfGjh2b+fPn58ADD8zgwYMrzN9xxx2z//7757777kvPnj2z0047pVGjRnn55Zcze/bsnHDCCbn88suX2k+HDh3Ss2fPvPjii+nWrVt69uyZhg0bplWrVvnd7373jTXuvffe5efTHnvskR133DEdOnTIW2+9lZdffjl169bNiBEjssUWW1TZ+7Kyzj777Lz44osZM2ZMunbtmr59+6ZJkyYZP358SktL07Jly9x9993lV0ZWl/bt2+eGG27If//3f+eEE07IjTfemC233DIffvhh/v73v+fEE08s6o8klueEE07If/3Xf+XSSy9Nly5d8t5772XChAlJkosvvrjCrZ579OhRfk716NEjffr0SYsWLfLKK6/k7bffzm9+85ucf/75K11LZb5LlVn39ttvz2677Zb77rsvnTt3zi677JIFCxZk7NixmT17drbeeutVfrtzAACgOK5gBQAAKu3999/PhAkTlvuaPXt2kq+uNr3pppvSo0ePvPTSS3nooYfSuHHj3HHHHTn33HO/dT+XXXZZrrnmmsyePTv33ntvJk+enL322itPPfXUMq/wa9KkSR599NHcfvvt6devX0pLS3PPPffkiSeeyNy5c3P44YfnnnvuycYbb1zp92DzzTfPiy++mCOPPDKLFi3KvffemzfffDPHH398xowZs0IB2fbbb5/f/e536du3bz766KPcf//9efTRR1O3bt0MGTIk//d//5e99tqrwjr77rtvbrjhhmy55ZZ54okncvPNN+emm27KP//5z0of29f16tUrzz77bLbccss89thjGTduXLp06ZJLL700d911V0pKSpZa584778xpp52Wdu3aZdy4cXnuueey88475+WXX17mM3WX+Mtf/pLDDjsss2fPzp133pmbbrppqascl+fcc8/Nww8/nL333jsTJ07MXXfdlY8++ig/+tGP8uyzz+boo49e2begSjVo0CCjR4/ONddck+7du+fvf/977rnnnqy11lo5/vjj8+qrr2abbbap7jKTfHX15Lhx49K/f/9Mnjw59913Xz777LOMGDEil156aaW2fcIJJ+Suu+5KvXr1cv/99+f111/PzjvvnAceeGCpq6KTr25V/fvf/z6bbrppnn766Tz66KPp0KFDHnnkkfz0pz+tVC2V+S5VZt2NNtooL7/8ck499dS0bNkyDz74YB577LFsvPHG+d3vfpenn3466667bqWODQAAqBolhUKhUN1FAAAAAN89nTp1yuTJkzNp0qR06tSpussBAAAoiitYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEiewQoAAAAAAABQJFewAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKzXeBx98kJKSkgqvxo0bp3379tl9991zxhln5L333quSfZ111lkpKSnJuHHjqmR7q0qnTp3SqVOnFV7vqaeeyi9/+cv07ds3zZo1S0lJSY488sgqrw+gWHr80lamx3/xxRf54x//mEMOOSTf+9730qhRozRv3jy77rpr/vSnP62aQgGKoM8vbWV/l7/iiiuy7777plOnTll77bXTvHnzdO/ePWeddVZmzJhR9YUCfAs9fmkr2+P/0/jx41O3bt2UlJTkd7/7XeULA1hBevzSVrbHH3nkkUu9l19/seaqV90FQLE23njj/Pd//3eSZN68eZk+fXqef/75nHvuubngggty8skn5/zzz9eUvsHNN9+cW265JY0bN06HDh0ye/bs6i4JIIkeX1l///vf85Of/CQtW7bM7rvvngEDBmT69On561//msMOOyzPPPNMrrrqquouE/gO0+cr76abbkqS7Lrrrmnbtm2+/PLLTJgwIWeffXZuvvnmPP/882nbtm01Vwl8F+nxVWvOnDkZOHBgGjVqlC+++KK6ywG+4/T4qnPCCSekefPm1V0GVUjAyhpjk002yVlnnbXU+NNPP52f/OQnGTZsWOrWrZtzzz139Re3hhg6dGh+9atfZbPNNssLL7yQ3r17V3dJAEn0+Mpq27Zt/vCHP+SQQw5J/fr1y8cvuOCC9OrVK1dffXWOOOKIbLfddtVYJfBdps9X3oQJE9KwYcOlxk8//fScd955ueSSS/L73/++GioDvuv0+Kr161//OtOnT8+pp56a0047rbrLAb7j9Piqc+KJJ1bJXQ6oOdwimDXeTjvtlNGjR6dBgwa56KKLMmXKlPJls2bNyoUXXphdd9017du3T/369dO+ffscccQRS93CoE+fPjn77LOTJH379i2/RP/rTW/s2LE5+uijs+mmm2adddbJOuusk549e+b6669fZm0vv/xyDj744HTo0CENGjTIeuutl2233Tbnn3/+UnOnT5+eX/ziF9lkk03SoEGDtGrVKgMGDMjrr79ePmfJrRkmT56cyZMnV7iVwLL+j+4/9ezZM1tssUXq1q37rXMBagI9vrgev9VWW+W///u/K4SrSdKmTZscd9xxSb66TTxATaPPF/+7/LLC1ST50Y9+lCR59913v3UbAKuTHl98j//6cVx99dW59NJLs/766xe9HsDqpseveI+n9nEFK7XCpptumkMOOSR/+MMfcu+99+b4449PkkycODFnnHFG+vbtmwMPPDBrr7123nrrrdx+++3529/+lpdffjkdO3ZMkvJnkT755JMZOHBgeRP/+mX7F154Yd59991sv/32OfDAAzNz5syMHj06xx13XN5+++1ccskl5XNfeeWV7LDDDqlbt27233//dOzYMTNnzsybb76Z66+/Pr/97W/L57733nvp06dP/vWvf2XPPffMAQcckOnTp+cvf/lLHnnkkYwZMya9evVK8+bNc+aZZ2b48OFJvvqrlyX69OlT5e8rQE2gx1eux6+11lpJknr1/NoH1Ez6fOX6/N/+9rckyZZbbrnS2wBYVfT44nv8Z599lqOOOip77rlnjj766IwaNWqF3muA1U2PX7Hf4x988MF89tlnadCgQbp27Zrdd999qT+UZw1TgBpu0qRJhSSF/v37f+O8m266qZCk8JOf/KR8bObMmYVPP/10qblPPPFEoU6dOoWf/vSnFcbPPPPMQpLC2LFjl7mP999/f6mxBQsWFPbYY49C3bp1C5MnTy4fP+mkkwpJCvfee+9S65SVlVX4eYcddijUrVu3MHr06Arjb7/9dqFJkyaFbt26VRjv2LFjoWPHjsussVjjx48vJCkMHDiwUtsBqAw9ftX0+CUWLlxY6NatW6GkpKTw2muvVck2AVaEPl/1ff66664rnHnmmYWTTjqp0KdPn0KSQo8ePQozZsxY6W0CrAw9vmp7/KBBgwpNmzYtlJaWFgqFQmHkyJGFJIVhw4at1PYAKkOPr7oeP3DgwEKSpV7t2rVbat+sWdwimFqjffv2SZKysrLysWbNmqVFixZLze3bt2+22GKLPP744yu0j86dOy81Vq9evfzsZz/LokWLMnbs2KWWN2rUaKmxli1blv/7H//4R5599tkMHDgw/fv3rzDve9/7Xo455pi89tprFW5LAPBdo8evnNNPPz2vvfZajjrqKFc2ATWaPl+866+/PmeffXYuvfTSjBs3LnvuuWdGjx6dddddt8r2AVCV9Phv9/DDD+emm27K73//+2y44YaV3h7A6qLHf7tddtkld911V0pLSzN37ty88847OeecczJz5sz88Ic/zIsvvljpfVA93CuOWm/cuHEZPnx4JkyYkLKysixcuLB82Ypegv/ZZ5/l4osvzr333pv33nsvX3zxRYXlH330Ufm/DznkkAwfPjwHHnhgfvzjH2ePPfbILrvsstQzNJ577rkkybRp05Z5z/a33nqr/H/9x3GAivT45RsxYkSGDRuWHj165PLLL6/SbQOsLvr80pb8B5iysrKMHz8+p5xySrbeeus89NBD+f73v18l+wBYHfT4r/z73//OT3/60+y+++459thjV3o7ADWJHv//HH300RV+3mSTTXL66adn/fXXz6BBg3LOOefk/vvvr9Q+qB4CVmqNJY10vfXWKx+7++678+Mf/zjrrLNO+vfvn06dOqVx48YpKSnJqFGjMnny5KK3P3/+/PTp0ycvv/xyevTokZ/85Cdp2bJl6tWrlw8++CC33HJL5s2bVz6/V69eGTduXC644ILcfvvtGTlyZJJk2223zYUXXpi+ffsmSWbMmJHkq2cnLXl+0rL85/9xAHyX6PEr5sYbb8zPf/7zdOvWLY899ljWWWedKt0+QFXT51dcq1at8oMf/CBbbbVVunTpkmOOOSYTJkyo8v0AVJYe/81OOumkzJo1KzfeeGOltgNQHfT4lTdw4MAMGTIkzzzzzCrbB6uWgJVaY9y4cUm+apZLnHXWWWnYsGFeeumldOnSpcL8O+64Y4W2f9999+Xll1/OoEGDlvql94477sgtt9yy1Do777xzHn744cydOzcTJkzIAw88kGuuuSb77rtvXn/99Wy00UZp2rRpkuTKK6/M0KFDV6gmgO8KPb54N9xwQ4477rhsvvnmGTNmTIVb4ADUVPr8yttwww3TtWvXvPDCC5kzZ04aN25cLXUALI8e/83+8Y9/5IsvvljmLTCT5NRTT82pp56aE044IcOHD19ldQCsDD1+5dWtWzfNmzfPv//972rZP5XnGazUCv/85z9z1113pUGDBjnwwAPLx99777107dp1qUb+8ccf5/33319qO3Xr1k2SLFq0aKll7733XpJk//33X2rZ3//+92+sr1GjRunTp08uueSS/OY3v8ncuXPz2GOPJfnqr2qSZPz48d+4jf+sc1k1AtRGenzxloSrXbt2zRNPPFHhL0gBaip9vvI+/vjjlJSUlL8HADWFHv/tDjrooAwaNGip1y677JLkq9Bi0KBB6d279wptF2BV0+Mrp7S0NFOnTk2nTp2qbJusXgJW1njPPPNM+vfvn3nz5uWUU06pcD/1jh075t133820adPKx7788ssMHjw4CxYsWGpbSx6+PWXKlKWWdezYMUny9NNPVxh/8sknc8MNNyw1f/z48fnyyy+XGl9SS8OGDZMk2223XXr16pU//elPufPOO5eav3jx4jz55JNL1VlWVrbM7QPUJnp88W688cYcd9xx2WyzzfLEE0+kdevWK7Q+QHXQ54vz8ccf58MPP1xqvFAo5Kyzzsq0adOy++67p0GDBkVvE2BV0+OLc8YZZ+TGG29c6nXUUUcl+SqAvfHGG/PjH/+46G0CrGp6fHGmTp26zN/jZ86cmSOPPDJJcthhhxW9PWoWtwhmjfHuu++WP3B6/vz5mT59ep5//vm89tprqVu3bk477bSceeaZFdY5/vjjc/zxx6dHjx45+OCDs3Dhwjz22GMpFArp3r17Xn311Qrz+/btm5KSkvzmN7/JG2+8kWbNmqV58+YZOnRofvCDH6RTp0656KKL8vrrr2fLLbfM22+/nQcffDAHHnhg/vznP1fY1oUXXpixY8dml112SefOndOwYcO8/PLLGTNmTDbaaKMKf9Xzpz/9KX379s2hhx6a4cOHZ+utt06jRo1SWlqa8ePH55NPPqnQuHfbbbe8+OKL2XvvvbPzzjunfv362WWXXcr/unF5nn766fJbKXzyySflY0uaeatWrXLxxRcX/6EAVBE9vnI9/oknnsixxx6bQqGQXXbZJddee+1Sc7baaqsccMABxX4kAFVKn69cn3/77bezxx57ZPvtt0+XLl3Spk2blJWV5e9//3vefvvttG/fPldfffXKfjwAlaLHV/6/1wDUVHp85Xr8W2+9lT322CM77LBDunTpkvXWWy9TpkzJ6NGj8+mnn2a33XbLySefvLIfD9WtADXcpEmTCkkqvBo1alRo165doW/fvoXTTz+98O677y5z3cWLFxdGjBhR2GKLLQoNGzYstG3btjBo0KDC9OnTC7vuumthWV+BUaNGFbp161Zo0KBBIUmhY8eO5cvef//9woABAwrrrbdeoXHjxoVtt922cMcddxTGjh1bSFI488wzy+eOHj26cMQRRxQ23XTTQpMmTQrrrLNOYfPNNy/85je/KXzyySdL7XfGjBmF0047rbDlllsWGjVqVFhnnXUKXbp0KRx22GGFv/71rxXmfvbZZ4Vjjjmm0K5du0LdunWX2vfyjBw5cqn38uuvrx8rwOqgx1dNj/+2/p6kMHDgwG/cBsCqoM9XTZ//+OOPCyeffHKhV69ehfXWW69Qr169QpMmTQpbb7114fTTTy98+umn37g+wKqgx1fdf69ZliW/4w8bNmyl1geoDD2+anp8aWlp4ac//Wmhe/fuhZYtWxbq1atXaN68eWGXXXYpjBgxorBw4cJvXJ+araRQKBSqLq4FAAAAAAAAqL08gxUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAItWr7gJqosWLF+ejjz5KkyZNUlJSUt3lAN9BhUIhn332Wdq3b586dfwtTFXS44GaQJ9fdfR5oLrp8auOHg/UBPr8qqPPA9VtRXq8gHUZPvroo2y44YbVXQZApkyZkg022KC6y6hV9HigJtHnq54+D9QUenzV0+OBmkSfr3r6PFBTFNPjBazL0KRJkyRfvYFNmzat5mqA76LZs2dnww03LO9HVB09HqgJ9PlVR58Hqpsev+ro8UBNoM+vOvo8UN1WpMcLWJdhye0HmjZtqpED1crtUKqeHg/UJPp81dPngZpCj696ejxQk+jzVU+fB2qKYnq8m8QDAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFCketVdALC00tLSlJWVVXcZVKFWrVqlQ4cO1V0GAAAAAABQSQJWqGFKS0uzWdeumTtnTnWXQhVq1Lhx3po4UcgKAAAAAABrOAEr1DBlZWWZO2dODjnv2rTu3KW6y6EKTJ/0Tu46bXDKysoErAAAAAAAsIYTsEIN1bpzl6zftXt1lwEAAAAAAMDX1KnuAgAAAAAAAADWFAJWAAAAAAAAgCK5RTAAAAAAAADfaaWlpSkrK6vuMqhCrVq1SocOHVbJtgWsAAAAAAAAfGeVlpZms65dM3fOnOouhSrUqHHjvDVx4ioJWQWsAAAAAAAAfGeVlZVl7pw5OeS8a9O6c5fqLocqMH3SO7nrtMEpKysTsAIAAAAAAMCq0Lpzl6zftXt1l8EaoE51FwAAAAAAAACwphCwAgAAAAAAABRptQasTz31VH7wgx+kffv2KSkpyb333ltheaFQyBlnnJF27dqlUaNG6devX955550Kc2bMmJHDDz88TZs2TfPmzTNo0KB8/vnnFeb83//9X3beeec0bNgwG264YS666KJVfWgAAAAAAADAd8BqDVi/+OKLdO/ePVdfffUyl1900UW54oorMmLEiEyYMCFrr712+vfvny+//LJ8zuGHH5433ngjjz32WB588ME89dRTOfbYY8uXz549O3vuuWc6duyYl156Kb///e9z1lln5frrr1/lxwcAAAAAAADUbvVW58723nvv7L333stcVigUMnz48Jx22mnZf//9kyS33npr2rRpk3vvvTeHHnpoJk6cmNGjR+eFF15Iz549kyRXXnll9tlnn1x88cVp3759brvttsyfPz8333xz6tevny222CKvvPJKLr300gpBLAAAAAAAAMCKqjHPYJ00aVKmTp2afv36lY81a9YsvXr1yvjx45Mk48ePT/PmzcvD1STp169f6tSpkwkTJpTP2WWXXVK/fv3yOf3798/bb7+df//736vpaAAAAAAAAIDaaLVewfpNpk6dmiRp06ZNhfE2bdqUL5s6dWpat25dYXm9evXSokWLCnM6d+681DaWLFt33XWX2ve8efMyb9688p9nz55dyaMBoKbQ4wFqN30eoPbS4wFqN30eWJPVmCtYq9OwYcPSrFmz8teGG25Y3SUBUEX0eIDaTZ8HqL30eIDaTZ8H1mQ1JmBt27ZtkmTatGkVxqdNm1a+rG3btpk+fXqF5QsXLsyMGTMqzFnWNr6+j/906qmnZtasWeWvKVOmVP6AAKgR9HiA2k2fB6i99HiA2k2fB9ZkNeYWwZ07d07btm0zZsyYbLXVVkm+uiXAhAkTMnjw4CRJ7969M3PmzLz00kvZZpttkiRPPPFEFi9enF69epXP+e1vf5sFCxZkrbXWSpI89thj2XTTTZd5e+AkadCgQRo0aLCKjxCA6qDHA9Ru+jxA7aXHA9Ru+jywJlutV7B+/vnneeWVV/LKK68kSSZNmpRXXnklpaWlKSkpyYknnpjzzjsv999/f1577bUcccQRad++fQ444IAkSdeuXbPXXnvlmGOOyfPPP59nnnkmQ4cOzaGHHpr27dsnSQ477LDUr18/gwYNyhtvvJE777wzl19+eU466aTVeagAAAAAAABALbRar2B98cUX07dv3/Kfl4SeAwcOzKhRo3LyySfniy++yLHHHpuZM2dmp512yujRo9OwYcPydW677bYMHTo0u+++e+rUqZMBAwbkiiuuKF/erFmzPProoxkyZEi22WabtGrVKmeccUaOPfbY1XegAAAAAAAAQK20WgPWPn36pFAoLHd5SUlJzjnnnJxzzjnLndOiRYvcfvvt37if73//+/n73/++0nUCAAAAAAAALMtqvUUwAAAAAAAAwJpMwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUKQaFbAuWrQop59+ejp37pxGjRpl4403zrnnnptCoVA+p1Ao5Iwzzki7du3SqFGj9OvXL++8806F7cyYMSOHH354mjZtmubNm2fQoEH5/PPPV/fhAAAAAAAAALVMjQpYL7zwwlx77bW56qqrMnHixFx44YW56KKLcuWVV5bPueiii3LFFVdkxIgRmTBhQtZee+30798/X375Zfmcww8/PG+88UYee+yxPPjgg3nqqady7LHHVschAQAAAAAAALVIveou4OueffbZ7L///tl3332TJJ06dcqf/vSnPP/880m+unp1+PDhOe2007L//vsnSW699da0adMm9957bw499NBMnDgxo0ePzgsvvJCePXsmSa688srss88+ufjii9O+ffvqOTgAAAAAAABgjVejrmDdYYcdMmbMmPzzn/9Mkrz66qt5+umns/feeydJJk2alKlTp6Zfv37l6zRr1iy9evXK+PHjkyTjx49P8+bNy8PVJOnXr1/q1KmTCRMmLHO/8+bNy+zZsyu8AKgd9HiA2k2fB6i99HiA2k2fB9ZkNSpgPeWUU3LooYdms802y1prrZUePXrkxBNPzOGHH54kmTp1apKkTZs2FdZr06ZN+bKpU6emdevWFZbXq1cvLVq0KJ/zn4YNG5ZmzZqVvzbccMOqPjQAqokeD1C76fMAtZceD1C76fPAmqxGBax33XVXbrvtttx+++15+eWXc8stt+Tiiy/OLbfcskr3e+qpp2bWrFnlrylTpqzS/QGw+ujxALWbPg9Qe+nxALWbPg+syWrUM1h/9atflV/FmiTdunXL5MmTM2zYsAwcODBt27ZNkkybNi3t2rUrX2/atGnZaqutkiRt27bN9OnTK2x34cKFmTFjRvn6/6lBgwZp0KDBKjgiAKqbHg9Qu+nzALWXHg9Qu+nzwJqsRl3BOmfOnNSpU7GkunXrZvHixUmSzp07p23bthkzZkz58tmzZ2fChAnp3bt3kqR3796ZOXNmXnrppfI5TzzxRBYvXpxevXqthqMAAAAAAAAAaqsadQXrD37wg5x//vnp0KFDtthii/zjH//IpZdemqOPPjpJUlJSkhNPPDHnnXdeunTpks6dO+f0009P+/btc8ABByRJunbtmr322ivHHHNMRowYkQULFmTo0KE59NBD0759+2o8OgAAAAAAAGBNV6MC1iuvvDKnn356fv7zn2f69Olp3759jjvuuJxxxhnlc04++eR88cUXOfbYYzNz5szstNNOGT16dBo2bFg+57bbbsvQoUOz++67p06dOhkwYECuuOKK6jgkAAAAAAAAoBapUQFrkyZNMnz48AwfPny5c0pKSnLOOefknHPOWe6cFi1a5Pbbb18FFQIAAAAAAADfZTXqGawAAAAAAAAANZmAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEgCVgAAAAAAAIAiCVgBAAAAAAAAiiRgBQAAAAAAACiSgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEgCVgAAAAAAAIAiCVgBAAAAAAAAiiRgBQAAAAAAACiSgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEgCVgAAAAAAAIAiCVgBAAAAAAAAiiRgBQAAAAAAACiSgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIq00gHrU089ldLS0m+cM2XKlDz11FMruwsAAAAAAACAGmWlA9a+fftm1KhR3zjn1ltvTd++fVd2FwAAAAAAAAA1ykoHrIVC4VvnLF68OCUlJSu7CwAAAAAAAIAaZZU+g/Wdd95Js2bNVuUuAAAAAAAAAFabeisy+eijj67w87333psPPvhgqXmLFi0qf/7q3nvvXakCAQAAAAAAAGqKFQpYv/7M1ZKSkrzyyit55ZVXljm3pKQk2267bS677LLK1AcAAAAAAABQY6xQwDpp0qQkXz1/daONNsqJJ56YE044Yal5devWzbrrrpu11167aqoEAAAAAAAAqAFWKGDt2LFj+b9HjhyZHj16VBgDAAAAAAAAqM1WKGD9uoEDB1ZlHQAAAAAAAAA13koHrEs8//zzeeGFFzJz5swsWrRoqeUlJSU5/fTTK7sbAAAAAAAAgGq30gHrjBkzcsABB+SZZ55JoVBY7jwBKwAAAAAAAFBbrHTAetJJJ+Xpp59Onz59MnDgwGywwQapV6/SF8QCAAAAAAAA1FgrnYg++OCD2W677TJmzJiUlJRUZU0AAAAAAAAANVKdlV1x7ty52WWXXYSrAAAAAAAAwHfGSgesW221VT744IMqLAUAAAAAAACgZlvpgPXMM8/M/fffn+eee64q6wEAAAAAAACosVb6GaxTp07Nvvvum1133TWHH354tt566zRt2nSZc4844oiVLhAAAAAAAACgpljpgPXII49MSUlJCoVCRo0alVGjRi31PNZCoZCSkpIVClg//PDD/PrXv87DDz+cOXPmZJNNNsnIkSPTs2fP8m2eeeaZueGGGzJz5szsuOOOufbaa9OlS5fybcyYMSPHH398HnjggdSpUycDBgzI5ZdfnnXWWWdlDxcAAAAAAABg5QPWkSNHVmUdSZJ///vf2XHHHdO3b988/PDDWW+99fLOO+9k3XXXLZ9z0UUX5Yorrsgtt9ySzp075/TTT0///v3z5ptvpmHDhkmSww8/PB9//HEee+yxLFiwIEcddVSOPfbY3H777VVeMwAAAAAAAPDdsdIB68CBA6uyjiTJhRdemA033LBCeNu5c+fyfxcKhQwfPjynnXZa9t9//yTJrbfemjZt2uTee+/NoYcemokTJ2b06NF54YUXyq96vfLKK7PPPvvk4osvTvv27au8bgAAAAAAAOC7oU51F/B1999/f3r27Jkf/ehHad26dXr06JEbbrihfPmkSZMyderU9OvXr3ysWbNm6dWrV8aPH58kGT9+fJo3b14eriZJv379UqdOnUyYMGGZ+503b15mz55d4QVA7aDHA9Ru+jxA7aXHA9Ru+jywJlvpgLW0tLToV7Hef//98uepPvLIIxk8eHD+53/+J7fcckuSZOrUqUmSNm3aVFivTZs25cumTp2a1q1bV1her169tGjRonzOfxo2bFiaNWtW/tpwww2LrhmAmk2PB6jd9HmA2kuPB6jd9HlgTbbSAWunTp3SuXPnb31ttNFGRW9z8eLF2XrrrXPBBRekR48eOfbYY3PMMcdkxIgRK1tmUU499dTMmjWr/DVlypRVuj8AVh89HqB20+cBai89HqB20+eBNdlKP4P1iCOOSElJyVLjs2bNyquvvppJkyZl1113TadOnYreZrt27bL55ptXGOvatWv+8pe/JEnatm2bJJk2bVratWtXPmfatGnZaqutyudMnz69wjYWLlyYGTNmlK//nxo0aJAGDRoUXScAaw49HqB20+cBai89HqB20+eBNdlKB6yjRo1a7rJCoZBLLrkkF110UW666aait7njjjvm7bffrjD2z3/+Mx07dkySdO7cOW3bts2YMWPKA9XZs2dnwoQJGTx4cJKkd+/emTlzZl566aVss802SZInnngiixcvTq9evVbgCAEAAAAAAAAqWulbBH+TkpKS/PKXv8wWW2yRX/3qV0Wv94tf/CLPPfdcLrjggrz77ru5/fbbc/3112fIkCHl2z3xxBNz3nnn5f77789rr72WI444Iu3bt88BBxyQ5KsrXvfaa68cc8wxef755/PMM89k6NChOfTQQ9O+fftVcbgAAAAAAADAd8RKX8FajJ49e+bGG28sev62226be+65J6eeemrOOeecdO7cOcOHD8/hhx9ePufkk0/OF198kWOPPTYzZ87MTjvtlNGjR6dhw4blc2677bYMHTo0u+++e+rUqZMBAwbkiiuuqNJjAwAAAAAAAL57VmnA+t5772XhwoUrtM5+++2X/fbbb7nLS0pKcs455+Scc85Z7pwWLVrk9ttvX6H9AgAAAAAAAHybKg9YFy9enA8//DCjRo3Kfffdl913372qdwEAAAAAAABQLVY6YK1Tp05KSkqWu7xQKGTdddfNJZdcsrK7AAAAAAAAAKhRVjpg3WWXXZYZsNapUyfrrrtutt122xx11FFp3bp1pQoEAAAAAAAAqClWOmAdN25cFZYBAAAAAAAAUPPVqe4CAAAAAAAAANYUK30F69c988wzeeWVVzJ79uw0bdo0W221VXbccceq2DQAAAAAAABAjVGpgPXZZ5/NUUcdlXfffTdJUigUyp/L2qVLl4wcOTK9e/eufJUAAAAAAAAANcBKB6xvvPFG9txzz8yZMyd77LFH+vbtm3bt2mXq1KkZO3ZsHn300fTv3z/PPfdcNt9886qsGQAAAAAAAKBarHTAes4552T+/Pl56KGHstdee1VY9utf/zqjR4/OD3/4w5xzzjm54447Kl0oAAAAAAAAQHWrs7Irjhs3LgcffPBS4eoSe+21Vw4++OCMHTt2pYsDAAAAAAAAqElWOmCdNWtWOnfu/I1zOnfunFmzZq3sLgAAAAAAAABqlJUOWNu3b5/nnnvuG+dMmDAh7du3X9ldAAAAAAAAANQoKx2w/vCHP8y4ceNy+umn58svv6yw7Msvv8yZZ56ZsWPHZv/99690kQAAAAAAAAA1Qb2VXfH000/Pgw8+mAsuuCDXXXddtttuu7Rp0ybTpk3LCy+8kE8++SQbbbRRTj/99KqsFwAAAAAAAKDarHTA2rJlyzz33HM5+eSTc8cdd+Shhx4qX9awYcMcddRRufDCC9OiRYsqKRQAAAAAAACguq10wJokrVq1ys0335zrrrsub731VmbPnp2mTZtms802y1prrVVVNQIAAAAAAADUCCscsJ5//vn54osvcvbZZ5eHqGuttVa6detWPmf+/Pn57W9/myZNmuSUU06pumoBAAAAAAAAqlGdFZn8+OOP54wzzkjLli2/8QrV+vXrp2XLlvntb3+bsWPHVrpIAAAAAAAAgJpghQLWW2+9Neuuu26GDh36rXOHDBmSFi1aZOTIkStdHAAAAAAAAEBNskIB67PPPpt+/fqlQYMG3zq3QYMG6devX5555pmVLg4AAAAAAACgJlmhgPWjjz7KRhttVPT8zp075+OPP17hogAAAAAAAABqohUKWOvUqZMFCxYUPX/BggWpU2eFdgEAAAAAAABQY61Q+tm+ffu8/vrrRc9//fXXs/76669wUQAAAAAAAAA10QoFrDvvvHOeeOKJfPDBB98694MPPsgTTzyRXXbZZWVrAwAAAAAAAKhRVihgHTJkSBYsWJCDDz44ZWVly5336aef5kc/+lEWLlyYwYMHV7pIAAAAAAAAgJqg3opM3nrrrXPiiSdm+PDh2XzzzfOzn/0sffv2zQYbbJAk+fDDDzNmzJhcf/31+eSTT3LSSSdl6623XiWFAwAAAAAAAKxuKxSwJskll1yShg0b5ve//33OP//8nH/++RWWFwqF1K1bN6eeemrOO++8KisUAAAAAAAAoLqtcMBaUlKSCy64IIMGDcrIkSPz7LPPZurUqUmStm3bZscdd8yRRx6ZjTfeuMqLBQAAAAAAAKhOKxywLrHxxhu7QhUAAAAAAAD4TqlT3QUAAAAAAAAArCkErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFKledRcAAAAAAFDTlZaWpqysrLrLoAq1atUqHTp0qO4yAFgDCVgBAAAAAL5BaWlpNuvaNXPnzKnuUqhCjRo3zlsTJwpZAVhhAlYAAAAAgG9QVlaWuXPm5JDzrk3rzl2quxyqwPRJ7+Su0wanrKxMwArAChOwAgAAAAAUoXXnLlm/a/fqLgMAqGZ1qrsAAAAAAAAAgDWFgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAoUo0OWH/3u9+lpKQkJ554YvnYl19+mSFDhqRly5ZZZ511MmDAgEybNq3CeqWlpdl3333TuHHjtG7dOr/61a+ycOHC1Vw9AAAAAAAAUNvU2ID1hRdeyHXXXZfvf//7FcZ/8Ytf5IEHHsjdd9+dJ598Mh999FEOOuig8uWLFi3Kvvvum/nz5+fZZ5/NLbfcklGjRuWMM85Y3YcAAAAAAAAA1DI1MmD9/PPPc/jhh+eGG27IuuuuWz4+a9as3HTTTbn00kuz2267ZZtttsnIkSPz7LPP5rnnnkuSPProo3nzzTfzxz/+MVtttVX23nvvnHvuubn66qszf/786jokAAAAAAAAoBaokQHrkCFDsu+++6Zfv34Vxl966aUsWLCgwvhmm22WDh06ZPz48UmS8ePHp1u3bmnTpk35nP79+2f27Nl54403lrm/efPmZfbs2RVeANQOejxA7abPA9ReejxA7abPA2uyGhew3nHHHXn55ZczbNiwpZZNnTo19evXT/PmzSuMt2nTJlOnTi2f8/VwdcnyJcuWZdiwYWnWrFn5a8MNN6yCIwGgJtDjAWo3fR6g9tLjAWo3fR5Yk9WogHXKlCk54YQTctttt6Vhw4arbb+nnnpqZs2aVf6aMmXKats3AKuWHg9Qu+nzALWXHg9Qu+nzwJqsXnUX8HUvvfRSpk+fnq233rp8bNGiRXnqqady1VVX5ZFHHsn8+fMzc+bMClexTps2LW3btk2StG3bNs8//3yF7U6bNq182bI0aNAgDRo0qOKjAaAm0OMBajd9HqD20uMBajd9HliT1agrWHffffe89tpreeWVV8pfPXv2zOGHH17+77XWWitjxowpX+ftt99OaWlpevfunSTp3bt3XnvttUyfPr18zmOPPZamTZtm8803X+3HBAAAAAAAANQeNeoK1iZNmmTLLbesMLb22munZcuW5eODBg3KSSedlBYtWqRp06Y5/vjj07t372y//fZJkj333DObb755fvKTn+Siiy7K1KlTc9ppp2XIkCH+GgYAAAAAAAColBoVsBbjsssuS506dTJgwIDMmzcv/fv3zzXXXFO+vG7dunnwwQczePDg9O7dO2uvvXYGDhyYc845pxqrBgAAAAAAAGqDGh+wjhs3rsLPDRs2zNVXX52rr756uet07NgxDz300CquDAAAAAAAAPiuqVHPYAUAAAAAAACoyQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEWqV90FAAAAAMCqUlpamrKysuougyrWqlWrdOjQobrLAAC+owSsAAAAANRKpaWl2axr18ydM6e6S6GKNWrcOG9NnChkBQCqhYAVAAAAgFqprKwsc+fMySHnXZvWnbtUdzlUkemT3sldpw1OWVmZgBUAqBYCVgAAAABqtdadu2T9rt2ruwwAAGqJOtVdAAAAAAAAAMCaQsAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABSpXnUXAAAAUN1KS0tTVlZW3WVQhVq1apUOHTpUdxkAAADUQgJWAADgO620tDSbde2auXPmVHcpVKFGjRvnrYkThawAAABUOQErAADwnVZWVpa5c+bkkPOuTevOXaq7HKrA9Env5K7TBqesrEzACgAAQJUTsAIAACRp3blL1u/avbrLAAAAAGq4OtVdAAAAAAAAAMCaQsAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkepVdwEAAN8lpaWlKSsrq+4yqGKtWrVKhw4dqrsMAAAAAFYDASsAwGpSWlqazbp2zdw5c6q7FKpYo8aN89bEiUJWAAAAgO8AASsAwGpSVlaWuXPm5JDzrk3rzl2quxyqyPRJ7+Su0wanrKxMwAoAAADwHSBgBQBYzVp37pL1u3av7jIAAAAAgJVQp7oLAAAAAAAAAFhTCFgBAAAAAAAAiiRgBQAAAAAAACiSgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEgCVgAAAAAAAIAiCVgBAAAAAAAAilSvugsAgDVFaWlpysrKqrsMqlCrVq3SoUOH6i4DAAAAAFiD1KiAddiwYfnrX/+at956K40aNcoOO+yQCy+8MJtuumn5nC+//DL/+7//mzvuuCPz5s1L//79c80116RNmzblc0pLSzN48OCMHTs266yzTgYOHJhhw4alXr0adbgArEFKS0uzWdeumTtnTnWXQhVq1Lhx3po4UcgKAAAAABStRiWOTz75ZIYMGZJtt902CxcuzG9+85vsueeeefPNN7P22msnSX7xi1/kb3/7W+6+++40a9YsQ4cOzUEHHZRnnnkmSbJo0aLsu+++adu2bZ599tl8/PHHOeKII7LWWmvlggsuqM7DA2ANVlZWlrlz5uSQ865N685dqrscqsD0Se/krtMGp6ysTMAKAAAAABStRgWso0ePrvDzqFGj0rp167z00kvZZZddMmvWrNx00025/fbbs9tuuyVJRo4cma5du+a5557L9ttvn0cffTRvvvlmHn/88bRp0yZbbbVVzj333Pz617/OWWedlfr161fHoQFQS7Tu3CXrd+1e3WUAAAAAAFBN6lR3Ad9k1qxZSZIWLVokSV566aUsWLAg/fr1K5+z2WabpUOHDhk/fnySZPz48enWrVuFWwb3798/s2fPzhtvvLEaqwcAAAAAAABqmxp1BevXLV68OCeeeGJ23HHHbLnllkmSqVOnpn79+mnevHmFuW3atMnUqVPL53w9XF2yfMmyZZk3b17mzZtX/vPs2bOr6jAAqGZ6PEDtps8D1F56PEDtps8Da7IaewXrkCFD8vrrr+eOO+5Y5fsaNmxYmjVrVv7acMMNV/k+AVg99HiA2k2fB6i99HiA2k2fB9ZkNTJgHTp0aB588MGMHTs2G2ywQfl427ZtM3/+/MycObPC/GnTpqVt27blc6ZNm7bU8iXLluXUU0/NrFmzyl9TpkypwqMBoDrp8QC1mz4PUHvp8QC1mz4PrMlq1C2CC4VCjj/++Nxzzz0ZN25cOnfuXGH5Nttsk7XWWitjxozJgAEDkiRvv/12SktL07t37yRJ7969c/7552f69Olp3bp1kuSxxx5L06ZNs/nmmy9zvw0aNEiDBg1W4ZEBUF30eIDaTZ8HqL30eIDaTZ8H1mQ1KmAdMmRIbr/99tx3331p0qRJ+TNTmzVrlkaNGqVZs2YZNGhQTjrppLRo0SJNmzbN8ccfn969e2f77bdPkuy5557ZfPPN85Of/CQXXXRRpk6dmtNOOy1DhgzRrAEAAAAAAIBKqVEB67XXXpsk6dOnT4XxkSNH5sgjj0ySXHbZZalTp04GDBiQefPmpX///rnmmmvK59atWzcPPvhgBg8enN69e2fttdfOwIEDc84556yuwwAAAAAAAABqqRoVsBYKhW+d07Bhw1x99dW5+uqrlzunY8eOeeihh6qyNAAAAAAAAIDUqe4CAAAAAAAAANYUAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEgCVgAAAAAAAIAiCVgBAAAAAAAAiiRgBQAAAAAAACiSgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAokoAVAAAAAAAAoEgCVgAAAAAAAIAiCVgBAAAAAAAAiiRgBQAAAAAAACiSgBUAAAAAAACgSAJWAAAAAAAAgCIJWAEAAAAAAACKJGAFAAAAAAAAKJKAFQAAAAAAAKBIAlYAAAAAAACAIglYAQAAAAAAAIokYAUAAAAAAAAoUr3qLqA2KS0tTVlZWXWXQRVq1apVOnToUN1lAAAAAAAAUEMIWKtIaWlpNuvaNXPnzKnuUqhCjRo3zlsTJwpZAQAAAAAASCJgrTJlZWWZO2dODjnv2rTu3KW6y6EKTJ/0Tu46bXDKysoErAAAAAAAACQRsFa51p27ZP2u3au7DAAAAAAAAGAVqFPdBQAAAAAAAACsKQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFKledRcAAAAAAACwMkpLS1NWVlbdZVCFWrVqlQ4dOlR3GfCNBKwAAAAAAMAap7S0NJt17Zq5c+ZUdylUoUaNG+etiROFrNRoAlYAAACoIq6gqH1cQQEANVdZWVnmzpmTQ867Nq07d6nucqgC0ye9k7tOG5yysjK/g1Gj1dqA9eqrr87vf//7TJ06Nd27d8+VV16Z7bbbrrrLAgAAoJZyBUXt5AoKAKj5WnfukvW7dq/uMoDvkFoZsN5555056aSTMmLEiPTq1SvDhw9P//798/bbb6d169bVXR4AAAC1kCsoah9XUAAAAMtSKwPWSy+9NMccc0yOOuqoJMmIESPyt7/9LTfffHNOOeWUaq4OAACA2swVFAAAALVbrQtY58+fn5deeimnnnpq+VidOnXSr1+/jB8/fpnrzJs3L/PmzSv/edasWUmS2bNnF73fzz//PEny4cT/y/w5X6xM6dQwn0x+L8lXn+2KnAuV5VyqfVbmXFoyr1AorLK6viuqoscnvpu1UXX0eedR7aTPVy+/y7Msfpenqujx1UuPZ3n8Lk9VWNnzSJ+vOvo8y+J3earKqv5dvqRQy/6f4KOPPsr666+fZ599Nr179y4fP/nkk/Pkk09mwoQJS61z1lln5eyzz16dZQIUZcqUKdlggw2qu4w1mh4P1GT6fOXp80BNpcdXnh4P1GT6fOXp80BNVUyPF7Bm6b+UWbx4cWbMmJGWLVumpKRktdS9Jpk9e3Y23HDDTJkyJU2bNq3uclhDOY++WaFQyGeffZb27dunTp061V3OGk2PXzG+m1QV59I30+erjj6/Ynw3qQrOo2+mx1cdPX7F+G5SVZxL30yfrzr6/Irx3aQqOI++2Yr0+Fp3i+BWrVqlbt26mTZtWoXxadOmpW3btstcp0GDBmnQoEGFsebNm6+qEmuNpk2b+gJSac6j5WvWrFl1l1Ar6PErx3eTquJcWj59vmro8yvHd5Oq4DxaPj2+aujxK8d3k6riXFo+fb5q6PMrx3eTquA8Wr5ie3yt+xOb+vXrZ5tttsmYMWPKxxYvXpwxY8ZUuKIVAAAAAAAAYEXVuitYk+Skk07KwIED07Nnz2y33XYZPnx4vvjiixx11FHVXRoAAAAAAACwBquVAeuPf/zjfPLJJznjjDMyderUbLXVVhk9enTatGlT3aXVCg0aNMiZZ5651O0bYEU4j6Bm8t2kqjiXoGby3aQqOI+gZvLdpKo4l6Bm8t2kKjiPqk5JoVAoVHcRAAAAAAAAAGuCWvcMVgAAAAAAAIBVRcAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwskKuvvrqdOrUKQ0bNkyvXr3y/PPPV3dJrIGeeuqp/OAHP0j79u1TUlKSe++9t7pLAv5/+jyVpcdDzaXHU1l6PNRs+jyVpc9DzaXHU1l6fNUTsFK0O++8MyeddFLOPPPMvPzyy+nevXv69++f6dOnV3dprGG++OKLdO/ePVdffXV1lwJ8jT5PVdDjoWbS46kKejzUXPo8VUGfh5pJj6cq6PFVr6RQKBSquwjWDL169cq2226bq666KkmyePHibLjhhjn++ONzyimnVHN1rKlKSkpyzz335IADDqjuUuA7T5+nqunxUHPo8VQ1PR5qFn2eqqbPQ82hx1PV9Piq4QpWijJ//vy89NJL6devX/lYnTp10q9fv4wfP74aKwOgKujzALWXHg9Qu+nzALWXHg81l4CVopSVlWXRokVp06ZNhfE2bdpk6tSp1VQVAFVFnweovfR4gNpNnweovfR4qLkErAAAAAAAAABFErBSlFatWqVu3bqZNm1ahfFp06albdu21VQVAFVFnweovfR4gNpNnweovfR4qLkErBSlfv362WabbTJmzJjyscWLF2fMmDHp3bt3NVYGQFXQ5wFqLz0eoHbT5wFqLz0eaq561V0Aa46TTjopAwcOTM+ePbPddttl+PDh+eKLL3LUUUdVd2msYT7//PO8++675T9PmjQpr7zySlq0aJEOHTpUY2Xw3abPUxX0eKiZ9Hiqgh4PNZc+T1XQ56Fm0uOpCnp81SspFAqF6i6CNcdVV12V3//+95k6dWq22mqrXHHFFenVq1d1l8UaZty4cenbt+9S4wMHDsyoUaNWf0FAOX2eytLjoebS46ksPR5qNn2eytLnoebS46ksPb7qCVgBAAAAAAAAiuQZrAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBK1TCBx98kJKSklx88cVVts1x48alpKQk48aNq7JtArDi9HiA2k2fB6i99HiA2k2fpyYQsPKdNGrUqJSUlOTFF1+s7lIAqGJ6PEDtps8D1F56PEDtps9TmwhYAQAAAAAAAIokYAUAAAAAAAAokoAVlmH+/Pk544wzss0226RZs2ZZe+21s/POO2fs2LHLXeeyyy5Lx44d06hRo+y66655/fXXl5rz1ltv5eCDD06LFi3SsGHD9OzZM/fff/+31vPOO+9kwIABadu2bRo2bJgNNtgghx56aGbNmlWp4wT4LtLjAWo3fR6g9tLjAWo3fZ41Sb3qLgBqotmzZ+fGG2/Mf/3Xf+WYY47JZ599lptuuin9+/fP888/n6222qrC/FtvvTWfffZZhgwZki+//DKXX355dtttt7z22mtp06ZNkuSNN97IjjvumPXXXz+nnHJK1l577dx111054IAD8pe//CUHHnjgMmuZP39++vfvn3nz5uX4449P27Zt8+GHH+bBBx/MzJkz06xZs1X9dgDUKno8QO2mzwPUXno8QO2mz7NGKcB30MiRIwtJCi+88MIyly9cuLAwb968CmP//ve/C23atCkcffTR5WOTJk0qJCk0atSo8K9//at8fMKECYUkhV/84hflY7vvvnuhW7duhS+//LJ8bPHixYUddtih0KVLl/KxsWPHFpIUxo4dWygUCoV//OMfhSSFu+++u1LHDPBdoccD1G76PEDtpccD1G76PLWJWwTDMtStWzf169dPkixevDgzZszIwoUL07Nnz7z88stLzT/ggAOy/vrrl/+83XbbpVevXnnooYeSJDNmzMgTTzyRQw45JJ999lnKyspSVlaWTz/9NP37988777yTDz/8cJm1LPlLmEceeSRz5syp6kMF+M7R4wFqN30eoPbS4wFqN32eNYmAFZbjlltuyfe///00bNgwLVu2zHrrrZe//e1vy7y/epcuXZYa+973vpcPPvggSfLuu++mUCjk9NNPz3rrrVfhdeaZZyZJpk+fvsw6OnfunJNOOik33nhjWrVqlf79++fqq692n3eAStDjAWo3fR6g9tLjAWo3fZ41hWewwjL88Y9/zJFHHpkDDjggv/rVr9K6devUrVs3w4YNy3vvvbfC21u8eHGS5Je//GX69++/zDmbbLLJcte/5JJLcuSRR+a+++7Lo48+mv/5n//JsGHD8txzz2WDDTZY4XoAvsv0eIDaTZ8HqL30eIDaTZ9nTSJghWX485//nI022ih//etfU1JSUj6+5K9a/tM777yz1Ng///nPdOrUKUmy0UYbJUnWWmut9OvXb6Vq6tatW7p165bTTjstzz77bHbccceMGDEi55133kptD+C7So8HqN30eYDaS48HqN30edYkbhEMy1C3bt0kSaFQKB+bMGFCxo8fv8z59957b4V7tT///POZMGFC9t577yRJ69at06dPn1x33XX5+OOPl1r/k08+WW4ts2fPzsKFCyuMdevWLXXq1Mm8efOKPygAkujxALWdPg9Qe+nxALWbPs+axBWsfKfdfPPNGT169FLjffr0yV//+tcceOCB2XfffTNp0qSMGDEim2++eT7//POl5m+yySbZaaedMnjw4MybNy/Dhw9Py5Ytc/LJJ5fPufrqq7PTTjulW7duOeaYY7LRRhtl2rRpGT9+fP71r3/l1VdfXWaNTzzxRIYOHZof/ehH+d73vpeFCxfmD3/4Q+rWrZsBAwZU3ZsBUMvo8QC1mz4PUHvp8QC1mz5PbSBg5Tvt2muvXeZ4aWlpPv/881x33XV55JFHsvnmm+ePf/xj7r777owbN26p+UcccUTq1KmT4cOHZ/r06dluu+1y1VVXpV27duVzNt9887z44os5++yzM2rUqHz66adp3bp1evTokTPOOGO5NXbv3j39+/fPAw88kA8//DCNGzdO9+7d8/DDD2f77bev9HsAUFvp8QC1mz4PUHvp8QC1mz5PbVBS+Pq11gAAAAAAAAAsl2ewAgAAAAAAABRJwAoAAAAAAABQJAErAAAAAAAAQJEErAAAAAAAAABFErACAAAAAAAAFEnACgAAAAAAAFAkASsAAAAAAABAkQSsAAAAAAAAAEUSsAIAAAAAAAAUScAKAAAAAAAAUCQBKwAAAAAAAECRBKwAAAAAAAAARRKwAgAAAAAAABTp/wNQJVnCZJmauAAAAABJRU5ErkJggg==\n"},"metadata":{}}],"source":["fig, axes = plt.subplots(1, 5, figsize=(20, 5), sharey=True)\n","\n","for list_ind, ax in enumerate(axes):\n","    f_name = list_name[list_ind]\n","    data = np.load(f_name)\n","    labels = data['train_labels'].flatten().tolist()\n","    label_counts = Counter(labels)\n","    categories = list(label_counts.keys())\n","    counts = list(label_counts.values())\n","\n","    # Plot on the current subplot\n","    ax.bar(categories, counts, color='skyblue', edgecolor='black')\n","    ax.set_title(f\"Dataset {list_ind + 1}\", fontsize=14)\n","    ax.set_xlabel('Labels', fontsize=12)\n","    ax.set_xticks(ticks=categories)\n","    ax.tick_params(axis='y', labelsize=10)\n","\n","fig.supylabel('Count', fontsize=14)\n","fig.suptitle('Label distribution for iid partition', fontsize=16)\n","fig.subplots_adjust(left=0.05, right=0.95, top=0.85, bottom=0.1, wspace=0.3)\n","#plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Zm1T9K1YkLAu"},"source":["Train local model on each partitioned dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"elapsed":4664,"status":"error","timestamp":1734500950363,"user":{"displayName":"Caleb Chin","userId":"06217181483891520714"},"user_tz":300},"id":"lKW4vsB5kIWI","outputId":"a8e0f99d-1db5-46da-a9ed-a51d55e19496"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch num: 1 \n","Train loss: 0.030282 \n","Val loss: 0.003600 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n","Epoch num: 2 \n","Train loss: 0.017632 \n","Val loss: 0.013272 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-8eef5eab3f4e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloc_trainer_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pneumonia_models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"client_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloc_trainer_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/train_loc.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mbest_vloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m       \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/train_loc.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0mtot_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0;31m# for debugging can print batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;31m#print(\"Batch %d loss: %f\" % (i, loss.item()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["data_flag = 'pneumoniamnist'\n","\n","info = medmnist.INFO[data_flag].copy()\n","task = info['task']\n","n_channels = info['n_channels']\n","n_classes = len(info['label'])\n","\n","for i in range(num_clients):\n","    DataClass = getattr(medmnist, info['python_class'])\n","    root = os.path.join(part_dir, \"client_\" + str(i))\n","    train_dataset = DataClass(root=os.path.join(part_dir, \"client_\" + str(i)), split='train', download=False)\n","    val_dataset = DataClass(root=os.path.join(part_dir, \"client_\" + str(i)), split='val', download=False)\n","    info = medmnist.INFO[data_flag].copy()\n","    train_dataset.info = info\n","    val_dataset.info = info\n","    train_dataset.info[\"n_samples\"][\"train\"] = train_dataset.imgs.shape[0]\n","    val_dataset.info[\"n_samples\"][\"val\"] = val_dataset.imgs.shape[0]\n","\n","    aug_list = []\n","    aug_list.append(transforms.RandomCrop(28, padding=4))\n","    aug_list.append(transforms.RandomHorizontalFlip())\n","    preprocess_list = [transforms.ToTensor(), transforms.Normalize(mean=[.5], std=[.5])]\n","\n","    loc_trainer_test = LocalTrainer(ResNet18(in_channels=1, num_classes=2), DataClass, os.path.join(\"pneumonia_models\", \"client_\" + str(i)), n_classes, root=root, epochs=100, lr_adj = [50, 75], aug=aug_list, preprocess=preprocess_list, seed=i)\n","    loc_trainer_test.train()"]},{"cell_type":"markdown","metadata":{"id":"gso4DfVWodA9"},"source":["This will create a folder `pneumonia_models` containing subfolders of each client's privately trained model. If you do not want to train these models yourself, we provide them as binaries with the GitHub release. Ensure that the folder containing the trained models is named `pneumonia_models` and that the subfolders are `client_0`, `client_1`, etc. Each client folder should contain a single file `best.pth` which represents the trained model."]},{"cell_type":"markdown","source":["## Training heterogenous models"],"metadata":{"id":"SwUPptv4zzLw"}},{"cell_type":"code","source":["data_flag = 'pneumoniamnist'\n","\n","info = medmnist.INFO[data_flag].copy()\n","task = info['task']\n","n_channels = info['n_channels']\n","n_classes = len(info['label'])\n","\n","model_types = [\"ResNet18\", \"ResNet50\", \"ResNet18\", \"ResNet50\", \"ResNet50\"]\n","\n","for i in range(num_clients):\n","    DataClass = getattr(medmnist, info['python_class'])\n","    root = os.path.join(part_dir, \"client_\" + str(i))\n","    train_dataset = DataClass(root=os.path.join(part_dir, \"client_\" + str(i)), split='train', download=False)\n","    val_dataset = DataClass(root=os.path.join(part_dir, \"client_\" + str(i)), split='val', download=False)\n","    info = medmnist.INFO[data_flag].copy()\n","    train_dataset.info = info\n","    val_dataset.info = info\n","    train_dataset.info[\"n_samples\"][\"train\"] = train_dataset.imgs.shape[0]\n","    val_dataset.info[\"n_samples\"][\"val\"] = val_dataset.imgs.shape[0]\n","\n","    aug_list = []\n","    aug_list.append(transforms.RandomCrop(28, padding=4))\n","    aug_list.append(transforms.RandomHorizontalFlip())\n","    preprocess_list = [transforms.ToTensor(), transforms.Normalize(mean=[.5], std=[.5])]\n","    if model_types[i] == \"ResNet18\":\n","      loc_trainer_test = LocalTrainer(ResNet18(in_channels=1, num_classes=2), DataClass, os.path.join(\"pneumonia_models\", \"client_\" + str(i)), n_classes, root=root, epochs=100, lr_adj = [50, 75], aug=aug_list, preprocess=preprocess_list, seed=i)\n","    elif model_types[i] == \"ResNet50\":\n","      loc_trainer_test = LocalTrainer(ResNet50(in_channels=1, num_classes=2), DataClass, os.path.join(\"pneumonia_models\", \"client_\" + str(i)), n_classes, root=root, epochs=100, lr_adj = [50, 75], aug=aug_list, preprocess=preprocess_list, seed=i)\n","    loc_trainer_test.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6Jf5JEoz-UW","executionInfo":{"status":"ok","timestamp":1738117910997,"user_tz":300,"elapsed":1084745,"user":{"displayName":"Caleb Chin","userId":"06217181483891520714"}},"outputId":"49a9f145-246c-4a8b-800e-2585354285b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch num: 1 \n","Train loss: 0.033534 \n","Val loss: 0.004027 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n","Epoch num: 2 \n","Train loss: 0.021329 \n","Val loss: 0.005733 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n","Epoch num: 3 \n","Train loss: 0.014763 \n","Val loss: 0.012783 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n","Epoch num: 4 \n","Train loss: 0.010145 \n","Val loss: 0.008992 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n","Epoch num: 5 \n","Train loss: 0.009127 \n","Val loss: 0.001764 \n","Val acc: 0.947368\n","Val balanced acc: 0.748054\n","Epoch num: 6 \n","Train loss: 0.007544 \n","Val loss: 0.005786 \n","Val acc: 0.901754\n","Val balanced acc: 0.500000\n","Epoch num: 7 \n","Train loss: 0.009066 \n","Val loss: 0.004566 \n","Val acc: 0.905263\n","Val balanced acc: 0.517857\n","Epoch num: 8 \n","Train loss: 0.008772 \n","Val loss: 0.000613 \n","Val acc: 0.964912\n","Val balanced acc: 0.948722\n","Epoch num: 9 \n","Train loss: 0.007443 \n","Val loss: 0.001976 \n","Val acc: 0.936842\n","Val balanced acc: 0.678571\n","Epoch num: 10 \n","Train loss: 0.006650 \n","Val loss: 0.001136 \n","Val acc: 0.954386\n","Val balanced acc: 0.767857\n","Epoch num: 11 \n","Train loss: 0.007137 \n","Val loss: 0.001018 \n","Val acc: 0.947368\n","Val balanced acc: 0.954906\n","Epoch num: 12 \n","Train loss: 0.006731 \n","Val loss: 0.001854 \n","Val acc: 0.894737\n","Val balanced acc: 0.941634\n","Epoch num: 13 \n","Train loss: 0.006173 \n","Val loss: 0.000770 \n","Val acc: 0.968421\n","Val balanced acc: 0.934755\n","Epoch num: 14 \n","Train loss: 0.006401 \n","Val loss: 0.004186 \n","Val acc: 0.838597\n","Val balanced acc: 0.910506\n","Epoch num: 15 \n","Train loss: 0.006607 \n","Val loss: 0.000942 \n","Val acc: 0.954386\n","Val balanced acc: 0.974708\n","Epoch num: 16 \n","Train loss: 0.005889 \n","Val loss: 0.002453 \n","Val acc: 0.933333\n","Val balanced acc: 0.660714\n","Epoch num: 17 \n","Train loss: 0.005461 \n","Val loss: 0.000546 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 18 \n","Train loss: 0.004712 \n","Val loss: 0.000989 \n","Val acc: 0.968421\n","Val balanced acc: 0.839286\n","Epoch num: 19 \n","Train loss: 0.006225 \n","Val loss: 0.002552 \n","Val acc: 0.877193\n","Val balanced acc: 0.931907\n","Epoch num: 20 \n","Train loss: 0.005012 \n","Val loss: 0.000681 \n","Val acc: 0.975439\n","Val balanced acc: 0.938646\n","Epoch num: 21 \n","Train loss: 0.004805 \n","Val loss: 0.000983 \n","Val acc: 0.943860\n","Val balanced acc: 0.952960\n","Epoch num: 22 \n","Train loss: 0.003656 \n","Val loss: 0.000531 \n","Val acc: 0.978947\n","Val balanced acc: 0.940592\n","Epoch num: 23 \n","Train loss: 0.004068 \n","Val loss: 0.000865 \n","Val acc: 0.954386\n","Val balanced acc: 0.958797\n","Epoch num: 24 \n","Train loss: 0.005420 \n","Val loss: 0.000981 \n","Val acc: 0.961404\n","Val balanced acc: 0.946776\n","Epoch num: 25 \n","Train loss: 0.005105 \n","Val loss: 0.003309 \n","Val acc: 0.845614\n","Val balanced acc: 0.914397\n","Epoch num: 26 \n","Train loss: 0.004622 \n","Val loss: 0.001783 \n","Val acc: 0.922807\n","Val balanced acc: 0.957198\n","Epoch num: 27 \n","Train loss: 0.004351 \n","Val loss: 0.002737 \n","Val acc: 0.915789\n","Val balanced acc: 0.571429\n","Epoch num: 28 \n","Train loss: 0.003590 \n","Val loss: 0.002312 \n","Val acc: 0.891228\n","Val balanced acc: 0.939689\n","Epoch num: 29 \n","Train loss: 0.005500 \n","Val loss: 0.015648 \n","Val acc: 0.610526\n","Val balanced acc: 0.784047\n","Epoch num: 30 \n","Train loss: 0.007410 \n","Val loss: 0.002294 \n","Val acc: 0.933333\n","Val balanced acc: 0.660714\n","Epoch num: 31 \n","Train loss: 0.005178 \n","Val loss: 0.000569 \n","Val acc: 0.971930\n","Val balanced acc: 0.952613\n","Epoch num: 32 \n","Train loss: 0.004615 \n","Val loss: 0.001193 \n","Val acc: 0.961404\n","Val balanced acc: 0.803571\n","Epoch num: 33 \n","Train loss: 0.004248 \n","Val loss: 0.000738 \n","Val acc: 0.975439\n","Val balanced acc: 0.875000\n","Epoch num: 34 \n","Train loss: 0.002835 \n","Val loss: 0.000536 \n","Val acc: 0.978947\n","Val balanced acc: 0.908769\n","Epoch num: 35 \n","Train loss: 0.003177 \n","Val loss: 0.000494 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 36 \n","Train loss: 0.002788 \n","Val loss: 0.000636 \n","Val acc: 0.978947\n","Val balanced acc: 0.908769\n","Epoch num: 37 \n","Train loss: 0.003050 \n","Val loss: 0.000543 \n","Val acc: 0.975439\n","Val balanced acc: 0.906823\n","Epoch num: 38 \n","Train loss: 0.003048 \n","Val loss: 0.000564 \n","Val acc: 0.975439\n","Val balanced acc: 0.906823\n","Epoch num: 39 \n","Train loss: 0.002205 \n","Val loss: 0.000624 \n","Val acc: 0.975439\n","Val balanced acc: 0.890912\n","Epoch num: 40 \n","Train loss: 0.002659 \n","Val loss: 0.000462 \n","Val acc: 0.985965\n","Val balanced acc: 0.960395\n","Epoch num: 41 \n","Train loss: 0.002889 \n","Val loss: 0.000404 \n","Val acc: 0.985965\n","Val balanced acc: 0.960395\n","Epoch num: 42 \n","Train loss: 0.002118 \n","Val loss: 0.000441 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 43 \n","Train loss: 0.002319 \n","Val loss: 0.000528 \n","Val acc: 0.982456\n","Val balanced acc: 0.926626\n","Epoch num: 44 \n","Train loss: 0.002011 \n","Val loss: 0.000660 \n","Val acc: 0.975439\n","Val balanced acc: 0.875000\n","Epoch num: 45 \n","Train loss: 0.002422 \n","Val loss: 0.000534 \n","Val acc: 0.975439\n","Val balanced acc: 0.906823\n","Epoch num: 46 \n","Train loss: 0.002273 \n","Val loss: 0.000444 \n","Val acc: 0.985965\n","Val balanced acc: 0.960395\n","Epoch num: 47 \n","Train loss: 0.001824 \n","Val loss: 0.000474 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 48 \n","Train loss: 0.002034 \n","Val loss: 0.000509 \n","Val acc: 0.982456\n","Val balanced acc: 0.926626\n","Epoch num: 49 \n","Train loss: 0.002294 \n","Val loss: 0.000533 \n","Val acc: 0.982456\n","Val balanced acc: 0.926626\n","Epoch num: 50 \n","Train loss: 0.002302 \n","Val loss: 0.000456 \n","Val acc: 0.985965\n","Val balanced acc: 0.960395\n","Epoch num: 51 \n","Train loss: 0.001556 \n","Val loss: 0.000512 \n","Val acc: 0.982456\n","Val balanced acc: 0.926626\n","Epoch num: 52 \n","Train loss: 0.002013 \n","Val loss: 0.000556 \n","Val acc: 0.982456\n","Val balanced acc: 0.926626\n","Epoch num: 53 \n","Train loss: 0.001761 \n","Val loss: 0.000540 \n","Val acc: 0.982456\n","Val balanced acc: 0.926626\n","Epoch num: 54 \n","Train loss: 0.001489 \n","Val loss: 0.000492 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 55 \n","Train loss: 0.001797 \n","Val loss: 0.000486 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 56 \n","Train loss: 0.001832 \n","Val loss: 0.000472 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 57 \n","Train loss: 0.001473 \n","Val loss: 0.000479 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 58 \n","Train loss: 0.001581 \n","Val loss: 0.000486 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 59 \n","Train loss: 0.002144 \n","Val loss: 0.000481 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 60 \n","Train loss: 0.001382 \n","Val loss: 0.000500 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 61 \n","Train loss: 0.001591 \n","Val loss: 0.000481 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 62 \n","Train loss: 0.001515 \n","Val loss: 0.000476 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 63 \n","Train loss: 0.001363 \n","Val loss: 0.000493 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 64 \n","Train loss: 0.001649 \n","Val loss: 0.000503 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 65 \n","Train loss: 0.001518 \n","Val loss: 0.000500 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 66 \n","Train loss: 0.001587 \n","Val loss: 0.000491 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 67 \n","Train loss: 0.001437 \n","Val loss: 0.000480 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 68 \n","Train loss: 0.002184 \n","Val loss: 0.000489 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 69 \n","Train loss: 0.001479 \n","Val loss: 0.000495 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 70 \n","Train loss: 0.001725 \n","Val loss: 0.000486 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 71 \n","Train loss: 0.002079 \n","Val loss: 0.000483 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 72 \n","Train loss: 0.001701 \n","Val loss: 0.000489 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 73 \n","Train loss: 0.001918 \n","Val loss: 0.000493 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 74 \n","Train loss: 0.001544 \n","Val loss: 0.000490 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 75 \n","Train loss: 0.001508 \n","Val loss: 0.000498 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 76 \n","Train loss: 0.001503 \n","Val loss: 0.000486 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 77 \n","Train loss: 0.001833 \n","Val loss: 0.000488 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 78 \n","Train loss: 0.001581 \n","Val loss: 0.000480 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 79 \n","Train loss: 0.001748 \n","Val loss: 0.000476 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 80 \n","Train loss: 0.001501 \n","Val loss: 0.000490 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 81 \n","Train loss: 0.001487 \n","Val loss: 0.000489 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 82 \n","Train loss: 0.001690 \n","Val loss: 0.000472 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 83 \n","Train loss: 0.001943 \n","Val loss: 0.000473 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 84 \n","Train loss: 0.001331 \n","Val loss: 0.000480 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 85 \n","Train loss: 0.001219 \n","Val loss: 0.000483 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 86 \n","Train loss: 0.001402 \n","Val loss: 0.000484 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 87 \n","Train loss: 0.001390 \n","Val loss: 0.000480 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 88 \n","Train loss: 0.001299 \n","Val loss: 0.000473 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 89 \n","Train loss: 0.001922 \n","Val loss: 0.000485 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 90 \n","Train loss: 0.001586 \n","Val loss: 0.000474 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 91 \n","Train loss: 0.001620 \n","Val loss: 0.000477 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 92 \n","Train loss: 0.001468 \n","Val loss: 0.000480 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 93 \n","Train loss: 0.001189 \n","Val loss: 0.000491 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 94 \n","Train loss: 0.001350 \n","Val loss: 0.000492 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 95 \n","Train loss: 0.001523 \n","Val loss: 0.000476 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 96 \n","Train loss: 0.001906 \n","Val loss: 0.000478 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 97 \n","Train loss: 0.001839 \n","Val loss: 0.000485 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 98 \n","Train loss: 0.001570 \n","Val loss: 0.000480 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","Epoch num: 99 \n","Train loss: 0.001620 \n","Val loss: 0.000476 \n","Val acc: 0.982456\n","Val balanced acc: 0.942538\n","Epoch num: 100 \n","Train loss: 0.001339 \n","Val loss: 0.000481 \n","Val acc: 0.978947\n","Val balanced acc: 0.924680\n","All done!\n","Epoch num: 1 \n","Train loss: 0.062602 \n","Val loss: 0.005752 \n","Val acc: 0.605042\n","Val balanced acc: 0.500000\n","Epoch num: 2 \n","Train loss: 0.035207 \n","Val loss: 0.005724 \n","Val acc: 0.605042\n","Val balanced acc: 0.500000\n","Epoch num: 3 \n","Train loss: 0.022912 \n","Val loss: 0.006327 \n","Val acc: 0.605042\n","Val balanced acc: 0.500000\n","Epoch num: 4 \n","Train loss: 0.016987 \n","Val loss: 0.008848 \n","Val acc: 0.605042\n","Val balanced acc: 0.500000\n","Epoch num: 5 \n","Train loss: 0.011171 \n","Val loss: 0.020720 \n","Val acc: 0.605042\n","Val balanced acc: 0.500000\n","Epoch num: 6 \n","Train loss: 0.009126 \n","Val loss: 0.030173 \n","Val acc: 0.605042\n","Val balanced acc: 0.500000\n","Epoch num: 7 \n","Train loss: 0.008460 \n","Val loss: 0.027744 \n","Val acc: 0.621849\n","Val balanced acc: 0.521277\n","Epoch num: 8 \n","Train loss: 0.007268 \n","Val loss: 0.027514 \n","Val acc: 0.621849\n","Val balanced acc: 0.521277\n","Epoch num: 9 \n","Train loss: 0.006397 \n","Val loss: 0.011416 \n","Val acc: 0.722689\n","Val balanced acc: 0.652630\n","Epoch num: 10 \n","Train loss: 0.005588 \n","Val loss: 0.018051 \n","Val acc: 0.714286\n","Val balanced acc: 0.638298\n","Epoch num: 11 \n","Train loss: 0.004901 \n","Val loss: 0.006915 \n","Val acc: 0.840336\n","Val balanced acc: 0.808954\n","Epoch num: 12 \n","Train loss: 0.005168 \n","Val loss: 0.003755 \n","Val acc: 0.865546\n","Val balanced acc: 0.840869\n","Epoch num: 13 \n","Train loss: 0.007366 \n","Val loss: 0.005676 \n","Val acc: 0.873950\n","Val balanced acc: 0.862589\n","Epoch num: 14 \n","Train loss: 0.006393 \n","Val loss: 0.002890 \n","Val acc: 0.899160\n","Val balanced acc: 0.909279\n","Epoch num: 15 \n","Train loss: 0.005722 \n","Val loss: 0.004221 \n","Val acc: 0.857143\n","Val balanced acc: 0.874557\n","Epoch num: 16 \n","Train loss: 0.004688 \n","Val loss: 0.003336 \n","Val acc: 0.915966\n","Val balanced acc: 0.915780\n","Epoch num: 17 \n","Train loss: 0.005257 \n","Val loss: 0.003735 \n","Val acc: 0.915966\n","Val balanced acc: 0.923168\n","Epoch num: 18 \n","Train loss: 0.004166 \n","Val loss: 0.005301 \n","Val acc: 0.848740\n","Val balanced acc: 0.871306\n","Epoch num: 19 \n","Train loss: 0.003117 \n","Val loss: 0.004201 \n","Val acc: 0.865546\n","Val balanced acc: 0.881501\n","Epoch num: 20 \n","Train loss: 0.003632 \n","Val loss: 0.004839 \n","Val acc: 0.873950\n","Val balanced acc: 0.892139\n","Epoch num: 21 \n","Train loss: 0.004084 \n","Val loss: 0.017329 \n","Val acc: 0.739496\n","Val balanced acc: 0.781028\n","Epoch num: 22 \n","Train loss: 0.004736 \n","Val loss: 0.005167 \n","Val acc: 0.865546\n","Val balanced acc: 0.885195\n","Epoch num: 23 \n","Train loss: 0.004238 \n","Val loss: 0.005953 \n","Val acc: 0.865546\n","Val balanced acc: 0.881501\n","Epoch num: 24 \n","Train loss: 0.003574 \n","Val loss: 0.002513 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 25 \n","Train loss: 0.004274 \n","Val loss: 0.004758 \n","Val acc: 0.857143\n","Val balanced acc: 0.878251\n","Epoch num: 26 \n","Train loss: 0.003849 \n","Val loss: 0.002829 \n","Val acc: 0.899160\n","Val balanced acc: 0.912973\n","Epoch num: 27 \n","Train loss: 0.002548 \n","Val loss: 0.003666 \n","Val acc: 0.915966\n","Val balanced acc: 0.923168\n","Epoch num: 28 \n","Train loss: 0.003006 \n","Val loss: 0.002852 \n","Val acc: 0.941177\n","Val balanced acc: 0.932920\n","Epoch num: 29 \n","Train loss: 0.002755 \n","Val loss: 0.003096 \n","Val acc: 0.932773\n","Val balanced acc: 0.940751\n","Epoch num: 30 \n","Train loss: 0.002793 \n","Val loss: 0.004866 \n","Val acc: 0.899160\n","Val balanced acc: 0.909279\n","Epoch num: 31 \n","Train loss: 0.002183 \n","Val loss: 0.002668 \n","Val acc: 0.932773\n","Val balanced acc: 0.937057\n","Epoch num: 32 \n","Train loss: 0.002964 \n","Val loss: 0.002878 \n","Val acc: 0.924370\n","Val balanced acc: 0.930112\n","Epoch num: 33 \n","Train loss: 0.003220 \n","Val loss: 0.002953 \n","Val acc: 0.899160\n","Val balanced acc: 0.912973\n","Epoch num: 34 \n","Train loss: 0.002030 \n","Val loss: 0.004545 \n","Val acc: 0.865546\n","Val balanced acc: 0.885195\n","Epoch num: 35 \n","Train loss: 0.001708 \n","Val loss: 0.011395 \n","Val acc: 0.798319\n","Val balanced acc: 0.829639\n","Epoch num: 36 \n","Train loss: 0.001987 \n","Val loss: 0.006417 \n","Val acc: 0.848740\n","Val balanced acc: 0.871306\n","Epoch num: 37 \n","Train loss: 0.001959 \n","Val loss: 0.004843 \n","Val acc: 0.865546\n","Val balanced acc: 0.885195\n","Epoch num: 38 \n","Train loss: 0.002189 \n","Val loss: 0.003547 \n","Val acc: 0.915966\n","Val balanced acc: 0.926862\n","Epoch num: 39 \n","Train loss: 0.001220 \n","Val loss: 0.002918 \n","Val acc: 0.941177\n","Val balanced acc: 0.944001\n","Epoch num: 40 \n","Train loss: 0.001678 \n","Val loss: 0.002397 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 41 \n","Train loss: 0.000995 \n","Val loss: 0.002292 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 42 \n","Train loss: 0.000783 \n","Val loss: 0.002197 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 43 \n","Train loss: 0.000862 \n","Val loss: 0.002124 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 44 \n","Train loss: 0.001145 \n","Val loss: 0.002269 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 45 \n","Train loss: 0.001124 \n","Val loss: 0.002297 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 46 \n","Train loss: 0.000633 \n","Val loss: 0.002267 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 47 \n","Train loss: 0.000920 \n","Val loss: 0.002168 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 48 \n","Train loss: 0.001489 \n","Val loss: 0.002375 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 49 \n","Train loss: 0.000799 \n","Val loss: 0.002629 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 50 \n","Train loss: 0.000909 \n","Val loss: 0.002574 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 51 \n","Train loss: 0.000620 \n","Val loss: 0.002359 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 52 \n","Train loss: 0.000870 \n","Val loss: 0.002420 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 53 \n","Train loss: 0.000552 \n","Val loss: 0.002678 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 54 \n","Train loss: 0.000962 \n","Val loss: 0.002689 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 55 \n","Train loss: 0.000774 \n","Val loss: 0.002706 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 56 \n","Train loss: 0.000577 \n","Val loss: 0.002701 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 57 \n","Train loss: 0.000545 \n","Val loss: 0.002708 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 58 \n","Train loss: 0.000620 \n","Val loss: 0.002728 \n","Val acc: 0.932773\n","Val balanced acc: 0.929669\n","Epoch num: 59 \n","Train loss: 0.000298 \n","Val loss: 0.002755 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 60 \n","Train loss: 0.000747 \n","Val loss: 0.002757 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 61 \n","Train loss: 0.000628 \n","Val loss: 0.002772 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 62 \n","Train loss: 0.000245 \n","Val loss: 0.002763 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 63 \n","Train loss: 0.000455 \n","Val loss: 0.002765 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 64 \n","Train loss: 0.000310 \n","Val loss: 0.002735 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 65 \n","Train loss: 0.000572 \n","Val loss: 0.002734 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 66 \n","Train loss: 0.000667 \n","Val loss: 0.002697 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 67 \n","Train loss: 0.000828 \n","Val loss: 0.002709 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 68 \n","Train loss: 0.000418 \n","Val loss: 0.002708 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 69 \n","Train loss: 0.000419 \n","Val loss: 0.002697 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 70 \n","Train loss: 0.000517 \n","Val loss: 0.002666 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 71 \n","Train loss: 0.000843 \n","Val loss: 0.002680 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 72 \n","Train loss: 0.000649 \n","Val loss: 0.002664 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 73 \n","Train loss: 0.000485 \n","Val loss: 0.002642 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 74 \n","Train loss: 0.000359 \n","Val loss: 0.002656 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 75 \n","Train loss: 0.000714 \n","Val loss: 0.002664 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 76 \n","Train loss: 0.000414 \n","Val loss: 0.002680 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 77 \n","Train loss: 0.000704 \n","Val loss: 0.002668 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 78 \n","Train loss: 0.000710 \n","Val loss: 0.002664 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 79 \n","Train loss: 0.000779 \n","Val loss: 0.002663 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 80 \n","Train loss: 0.000472 \n","Val loss: 0.002668 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 81 \n","Train loss: 0.000564 \n","Val loss: 0.002679 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 82 \n","Train loss: 0.000394 \n","Val loss: 0.002682 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 83 \n","Train loss: 0.000373 \n","Val loss: 0.002679 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 84 \n","Train loss: 0.000317 \n","Val loss: 0.002627 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 85 \n","Train loss: 0.000416 \n","Val loss: 0.002640 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 86 \n","Train loss: 0.000878 \n","Val loss: 0.002644 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 87 \n","Train loss: 0.000706 \n","Val loss: 0.002674 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 88 \n","Train loss: 0.000516 \n","Val loss: 0.002670 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 89 \n","Train loss: 0.000295 \n","Val loss: 0.002663 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 90 \n","Train loss: 0.000664 \n","Val loss: 0.002680 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 91 \n","Train loss: 0.000625 \n","Val loss: 0.002688 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 92 \n","Train loss: 0.000494 \n","Val loss: 0.002720 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 93 \n","Train loss: 0.000293 \n","Val loss: 0.002694 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 94 \n","Train loss: 0.000555 \n","Val loss: 0.002691 \n","Val acc: 0.949580\n","Val balanced acc: 0.950946\n","Epoch num: 95 \n","Train loss: 0.000442 \n","Val loss: 0.002681 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 96 \n","Train loss: 0.000438 \n","Val loss: 0.002666 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 97 \n","Train loss: 0.000446 \n","Val loss: 0.002641 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 98 \n","Train loss: 0.000525 \n","Val loss: 0.002644 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 99 \n","Train loss: 0.000877 \n","Val loss: 0.002673 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","Epoch num: 100 \n","Train loss: 0.000486 \n","Val loss: 0.002669 \n","Val acc: 0.941177\n","Val balanced acc: 0.940307\n","All done!\n","Epoch num: 1 \n","Train loss: 0.017730 \n","Val loss: 0.004620 \n","Val acc: 0.950000\n","Val balanced acc: 0.500000\n","Epoch num: 2 \n","Train loss: 0.003923 \n","Val loss: 0.004629 \n","Val acc: 0.950000\n","Val balanced acc: 0.500000\n","Epoch num: 3 \n","Train loss: 0.004103 \n","Val loss: 0.062963 \n","Val acc: 0.050000\n","Val balanced acc: 0.500000\n","Epoch num: 4 \n","Train loss: 0.003865 \n","Val loss: 0.198108 \n","Val acc: 0.050000\n","Val balanced acc: 0.500000\n","Epoch num: 5 \n","Train loss: 0.002399 \n","Val loss: 0.197078 \n","Val acc: 0.050000\n","Val balanced acc: 0.500000\n","Epoch num: 6 \n","Train loss: 0.003467 \n","Val loss: 0.252833 \n","Val acc: 0.050000\n","Val balanced acc: 0.500000\n","Epoch num: 7 \n","Train loss: 0.002578 \n","Val loss: 0.371586 \n","Val acc: 0.050000\n","Val balanced acc: 0.500000\n","Epoch num: 8 \n","Train loss: 0.002777 \n","Val loss: 0.211840 \n","Val acc: 0.050000\n","Val balanced acc: 0.500000\n","Epoch num: 9 \n","Train loss: 0.001684 \n","Val loss: 0.033736 \n","Val acc: 0.087500\n","Val balanced acc: 0.519737\n","Epoch num: 10 \n","Train loss: 0.002067 \n","Val loss: 0.050767 \n","Val acc: 0.100000\n","Val balanced acc: 0.526316\n","Epoch num: 11 \n","Train loss: 0.001712 \n","Val loss: 0.043810 \n","Val acc: 0.137500\n","Val balanced acc: 0.546053\n","Epoch num: 12 \n","Train loss: 0.001585 \n","Val loss: 0.002593 \n","Val acc: 0.962500\n","Val balanced acc: 0.625000\n","Epoch num: 13 \n","Train loss: 0.001626 \n","Val loss: 0.006137 \n","Val acc: 0.812500\n","Val balanced acc: 0.901316\n","Epoch num: 14 \n","Train loss: 0.001663 \n","Val loss: 0.001150 \n","Val acc: 0.962500\n","Val balanced acc: 0.980263\n","Epoch num: 15 \n","Train loss: 0.001586 \n","Val loss: 0.002219 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 16 \n","Train loss: 0.001401 \n","Val loss: 0.000512 \n","Val acc: 1.000000\n","Val balanced acc: 1.000000\n","Epoch num: 17 \n","Train loss: 0.001279 \n","Val loss: 0.001008 \n","Val acc: 0.975000\n","Val balanced acc: 0.986842\n","Epoch num: 18 \n","Train loss: 0.001929 \n","Val loss: 0.000955 \n","Val acc: 0.975000\n","Val balanced acc: 0.986842\n","Epoch num: 19 \n","Train loss: 0.001541 \n","Val loss: 0.008194 \n","Val acc: 0.850000\n","Val balanced acc: 0.921053\n","Epoch num: 20 \n","Train loss: 0.001873 \n","Val loss: 0.000940 \n","Val acc: 0.962500\n","Val balanced acc: 0.743421\n","Epoch num: 21 \n","Train loss: 0.001502 \n","Val loss: 0.000367 \n","Val acc: 0.987500\n","Val balanced acc: 0.875000\n","Epoch num: 22 \n","Train loss: 0.001286 \n","Val loss: 0.007574 \n","Val acc: 0.950000\n","Val balanced acc: 0.500000\n","Epoch num: 23 \n","Train loss: 0.001773 \n","Val loss: 0.006293 \n","Val acc: 0.762500\n","Val balanced acc: 0.875000\n","Epoch num: 24 \n","Train loss: 0.000922 \n","Val loss: 0.003996 \n","Val acc: 0.887500\n","Val balanced acc: 0.940789\n","Epoch num: 25 \n","Train loss: 0.001496 \n","Val loss: 0.001625 \n","Val acc: 0.962500\n","Val balanced acc: 0.861842\n","Epoch num: 26 \n","Train loss: 0.000943 \n","Val loss: 0.004456 \n","Val acc: 0.862500\n","Val balanced acc: 0.927632\n","Epoch num: 27 \n","Train loss: 0.001256 \n","Val loss: 0.000169 \n","Val acc: 1.000000\n","Val balanced acc: 1.000000\n","Epoch num: 28 \n","Train loss: 0.000727 \n","Val loss: 0.002838 \n","Val acc: 0.962500\n","Val balanced acc: 0.625000\n","Epoch num: 29 \n","Train loss: 0.001032 \n","Val loss: 0.000181 \n","Val acc: 0.987500\n","Val balanced acc: 0.875000\n","Epoch num: 30 \n","Train loss: 0.000998 \n","Val loss: 0.003689 \n","Val acc: 0.962500\n","Val balanced acc: 0.625000\n","Epoch num: 31 \n","Train loss: 0.000999 \n","Val loss: 0.003689 \n","Val acc: 0.950000\n","Val balanced acc: 0.500000\n","Epoch num: 32 \n","Train loss: 0.000801 \n","Val loss: 0.000402 \n","Val acc: 0.987500\n","Val balanced acc: 0.875000\n","Epoch num: 33 \n","Train loss: 0.000855 \n","Val loss: 0.001055 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 34 \n","Train loss: 0.001215 \n","Val loss: 0.001614 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 35 \n","Train loss: 0.000591 \n","Val loss: 0.001890 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 36 \n","Train loss: 0.000885 \n","Val loss: 0.003050 \n","Val acc: 0.962500\n","Val balanced acc: 0.625000\n","Epoch num: 37 \n","Train loss: 0.000900 \n","Val loss: 0.006076 \n","Val acc: 0.950000\n","Val balanced acc: 0.500000\n","Epoch num: 38 \n","Train loss: 0.000498 \n","Val loss: 0.001995 \n","Val acc: 0.962500\n","Val balanced acc: 0.625000\n","Epoch num: 39 \n","Train loss: 0.000881 \n","Val loss: 0.001549 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 40 \n","Train loss: 0.000948 \n","Val loss: 0.001613 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 41 \n","Train loss: 0.000622 \n","Val loss: 0.001589 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 42 \n","Train loss: 0.001023 \n","Val loss: 0.001401 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 43 \n","Train loss: 0.001182 \n","Val loss: 0.001211 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 44 \n","Train loss: 0.000541 \n","Val loss: 0.001088 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 45 \n","Train loss: 0.000711 \n","Val loss: 0.000731 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 46 \n","Train loss: 0.000318 \n","Val loss: 0.000570 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 47 \n","Train loss: 0.000639 \n","Val loss: 0.000543 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 48 \n","Train loss: 0.000411 \n","Val loss: 0.000492 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 49 \n","Train loss: 0.000724 \n","Val loss: 0.000638 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 50 \n","Train loss: 0.000550 \n","Val loss: 0.000646 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 51 \n","Train loss: 0.000755 \n","Val loss: 0.000619 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 52 \n","Train loss: 0.000407 \n","Val loss: 0.000653 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 53 \n","Train loss: 0.000232 \n","Val loss: 0.000678 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 54 \n","Train loss: 0.000210 \n","Val loss: 0.000674 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 55 \n","Train loss: 0.000328 \n","Val loss: 0.000666 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 56 \n","Train loss: 0.000530 \n","Val loss: 0.000685 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 57 \n","Train loss: 0.000394 \n","Val loss: 0.000692 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 58 \n","Train loss: 0.000293 \n","Val loss: 0.000669 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 59 \n","Train loss: 0.000585 \n","Val loss: 0.000688 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 60 \n","Train loss: 0.000282 \n","Val loss: 0.000703 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 61 \n","Train loss: 0.000394 \n","Val loss: 0.000697 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 62 \n","Train loss: 0.000235 \n","Val loss: 0.000665 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 63 \n","Train loss: 0.000270 \n","Val loss: 0.000672 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 64 \n","Train loss: 0.000195 \n","Val loss: 0.000615 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 65 \n","Train loss: 0.000549 \n","Val loss: 0.000606 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 66 \n","Train loss: 0.000495 \n","Val loss: 0.000575 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 67 \n","Train loss: 0.000498 \n","Val loss: 0.000601 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 68 \n","Train loss: 0.000631 \n","Val loss: 0.000630 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 69 \n","Train loss: 0.001063 \n","Val loss: 0.000651 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 70 \n","Train loss: 0.000289 \n","Val loss: 0.000619 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 71 \n","Train loss: 0.000209 \n","Val loss: 0.000608 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 72 \n","Train loss: 0.000324 \n","Val loss: 0.000578 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 73 \n","Train loss: 0.000632 \n","Val loss: 0.000599 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 74 \n","Train loss: 0.000646 \n","Val loss: 0.000648 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 75 \n","Train loss: 0.000415 \n","Val loss: 0.000647 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 76 \n","Train loss: 0.000455 \n","Val loss: 0.000651 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 77 \n","Train loss: 0.000284 \n","Val loss: 0.000656 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 78 \n","Train loss: 0.000361 \n","Val loss: 0.000669 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 79 \n","Train loss: 0.000312 \n","Val loss: 0.000651 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 80 \n","Train loss: 0.000323 \n","Val loss: 0.000641 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 81 \n","Train loss: 0.000489 \n","Val loss: 0.000655 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 82 \n","Train loss: 0.000247 \n","Val loss: 0.000652 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 83 \n","Train loss: 0.000332 \n","Val loss: 0.000641 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 84 \n","Train loss: 0.000192 \n","Val loss: 0.000642 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 85 \n","Train loss: 0.000224 \n","Val loss: 0.000650 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 86 \n","Train loss: 0.000254 \n","Val loss: 0.000640 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 87 \n","Train loss: 0.000334 \n","Val loss: 0.000632 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 88 \n","Train loss: 0.000421 \n","Val loss: 0.000656 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 89 \n","Train loss: 0.000520 \n","Val loss: 0.000637 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 90 \n","Train loss: 0.000225 \n","Val loss: 0.000663 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 91 \n","Train loss: 0.000345 \n","Val loss: 0.000652 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 92 \n","Train loss: 0.000527 \n","Val loss: 0.000672 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 93 \n","Train loss: 0.000344 \n","Val loss: 0.000654 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 94 \n","Train loss: 0.000350 \n","Val loss: 0.000656 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 95 \n","Train loss: 0.000339 \n","Val loss: 0.000635 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 96 \n","Train loss: 0.000196 \n","Val loss: 0.000598 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 97 \n","Train loss: 0.000684 \n","Val loss: 0.000643 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 98 \n","Train loss: 0.000306 \n","Val loss: 0.000641 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 99 \n","Train loss: 0.000554 \n","Val loss: 0.000632 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","Epoch num: 100 \n","Train loss: 0.000287 \n","Val loss: 0.000621 \n","Val acc: 0.975000\n","Val balanced acc: 0.750000\n","All done!\n","Epoch num: 1 \n","Train loss: 0.069865 \n","Val loss: 0.014343 \n","Val acc: 0.533333\n","Val balanced acc: 0.500000\n","Epoch num: 2 \n","Train loss: 0.023352 \n","Val loss: 0.018623 \n","Val acc: 0.533333\n","Val balanced acc: 0.500000\n","Epoch num: 3 \n","Train loss: 0.020950 \n","Val loss: 0.009334 \n","Val acc: 0.497436\n","Val balanced acc: 0.467033\n","Epoch num: 4 \n","Train loss: 0.022276 \n","Val loss: 0.035528 \n","Val acc: 0.533333\n","Val balanced acc: 0.500000\n","Epoch num: 5 \n","Train loss: 0.015204 \n","Val loss: 0.034785 \n","Val acc: 0.543590\n","Val balanced acc: 0.511676\n","Epoch num: 6 \n","Train loss: 0.020404 \n","Val loss: 0.002606 \n","Val acc: 0.907692\n","Val balanced acc: 0.907967\n","Epoch num: 7 \n","Train loss: 0.011852 \n","Val loss: 0.002727 \n","Val acc: 0.912821\n","Val balanced acc: 0.917582\n","Epoch num: 8 \n","Train loss: 0.011173 \n","Val loss: 0.001708 \n","Val acc: 0.933333\n","Val balanced acc: 0.933379\n","Epoch num: 9 \n","Train loss: 0.014948 \n","Val loss: 0.003540 \n","Val acc: 0.887179\n","Val balanced acc: 0.880495\n","Epoch num: 10 \n","Train loss: 0.015235 \n","Val loss: 0.006122 \n","Val acc: 0.851282\n","Val balanced acc: 0.860577\n","Epoch num: 11 \n","Train loss: 0.014543 \n","Val loss: 0.001993 \n","Val acc: 0.923077\n","Val balanced acc: 0.918956\n","Epoch num: 12 \n","Train loss: 0.009394 \n","Val loss: 0.002550 \n","Val acc: 0.917949\n","Val balanced acc: 0.922390\n","Epoch num: 13 \n","Train loss: 0.006667 \n","Val loss: 0.001786 \n","Val acc: 0.928205\n","Val balanced acc: 0.929258\n","Epoch num: 14 \n","Train loss: 0.008379 \n","Val loss: 0.002353 \n","Val acc: 0.907692\n","Val balanced acc: 0.912775\n","Epoch num: 15 \n","Train loss: 0.010806 \n","Val loss: 0.001303 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 16 \n","Train loss: 0.008227 \n","Val loss: 0.001626 \n","Val acc: 0.943590\n","Val balanced acc: 0.941621\n","Epoch num: 17 \n","Train loss: 0.007243 \n","Val loss: 0.001474 \n","Val acc: 0.938462\n","Val balanced acc: 0.941621\n","Epoch num: 18 \n","Train loss: 0.009251 \n","Val loss: 0.001445 \n","Val acc: 0.938462\n","Val balanced acc: 0.935440\n","Epoch num: 19 \n","Train loss: 0.007362 \n","Val loss: 0.001395 \n","Val acc: 0.943590\n","Val balanced acc: 0.945055\n","Epoch num: 20 \n","Train loss: 0.010453 \n","Val loss: 0.001475 \n","Val acc: 0.953846\n","Val balanced acc: 0.952610\n","Epoch num: 21 \n","Train loss: 0.007389 \n","Val loss: 0.001141 \n","Val acc: 0.958974\n","Val balanced acc: 0.960852\n","Epoch num: 22 \n","Train loss: 0.007653 \n","Val loss: 0.001664 \n","Val acc: 0.953846\n","Val balanced acc: 0.952610\n","Epoch num: 23 \n","Train loss: 0.009866 \n","Val loss: 0.002193 \n","Val acc: 0.928205\n","Val balanced acc: 0.931319\n","Epoch num: 24 \n","Train loss: 0.010305 \n","Val loss: 0.034819 \n","Val acc: 0.594872\n","Val balanced acc: 0.619505\n","Epoch num: 25 \n","Train loss: 0.010002 \n","Val loss: 0.012072 \n","Val acc: 0.733333\n","Val balanced acc: 0.747253\n","Epoch num: 26 \n","Train loss: 0.009596 \n","Val loss: 0.001246 \n","Val acc: 0.948718\n","Val balanced acc: 0.951236\n","Epoch num: 27 \n","Train loss: 0.004825 \n","Val loss: 0.001585 \n","Val acc: 0.928205\n","Val balanced acc: 0.925824\n","Epoch num: 28 \n","Train loss: 0.009332 \n","Val loss: 0.001209 \n","Val acc: 0.953846\n","Val balanced acc: 0.953297\n","Epoch num: 29 \n","Train loss: 0.011811 \n","Val loss: 0.002296 \n","Val acc: 0.917949\n","Val balanced acc: 0.922390\n","Epoch num: 30 \n","Train loss: 0.011043 \n","Val loss: 0.002227 \n","Val acc: 0.943590\n","Val balanced acc: 0.940934\n","Epoch num: 31 \n","Train loss: 0.008776 \n","Val loss: 0.002296 \n","Val acc: 0.892308\n","Val balanced acc: 0.897665\n","Epoch num: 32 \n","Train loss: 0.005996 \n","Val loss: 0.002011 \n","Val acc: 0.938462\n","Val balanced acc: 0.940934\n","Epoch num: 33 \n","Train loss: 0.008191 \n","Val loss: 0.001703 \n","Val acc: 0.943590\n","Val balanced acc: 0.945055\n","Epoch num: 34 \n","Train loss: 0.006296 \n","Val loss: 0.001409 \n","Val acc: 0.948718\n","Val balanced acc: 0.949863\n","Epoch num: 35 \n","Train loss: 0.005433 \n","Val loss: 0.001424 \n","Val acc: 0.948718\n","Val balanced acc: 0.948489\n","Epoch num: 36 \n","Train loss: 0.005252 \n","Val loss: 0.001368 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 37 \n","Train loss: 0.004235 \n","Val loss: 0.001262 \n","Val acc: 0.938462\n","Val balanced acc: 0.938874\n","Epoch num: 38 \n","Train loss: 0.004107 \n","Val loss: 0.001256 \n","Val acc: 0.938462\n","Val balanced acc: 0.940247\n","Epoch num: 39 \n","Train loss: 0.004569 \n","Val loss: 0.001280 \n","Val acc: 0.943590\n","Val balanced acc: 0.945742\n","Epoch num: 40 \n","Train loss: 0.004340 \n","Val loss: 0.001179 \n","Val acc: 0.943590\n","Val balanced acc: 0.945055\n","Epoch num: 41 \n","Train loss: 0.004769 \n","Val loss: 0.001153 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 42 \n","Train loss: 0.004588 \n","Val loss: 0.001165 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 43 \n","Train loss: 0.004502 \n","Val loss: 0.001219 \n","Val acc: 0.943590\n","Val balanced acc: 0.942995\n","Epoch num: 44 \n","Train loss: 0.004122 \n","Val loss: 0.001204 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 45 \n","Train loss: 0.004961 \n","Val loss: 0.001207 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 46 \n","Train loss: 0.006309 \n","Val loss: 0.001205 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 47 \n","Train loss: 0.004758 \n","Val loss: 0.001203 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 48 \n","Train loss: 0.003963 \n","Val loss: 0.001195 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 49 \n","Train loss: 0.003824 \n","Val loss: 0.001188 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 50 \n","Train loss: 0.004286 \n","Val loss: 0.001191 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 51 \n","Train loss: 0.004118 \n","Val loss: 0.001199 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 52 \n","Train loss: 0.005424 \n","Val loss: 0.001201 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 53 \n","Train loss: 0.004831 \n","Val loss: 0.001201 \n","Val acc: 0.948718\n","Val balanced acc: 0.949176\n","Epoch num: 54 \n","Train loss: 0.004261 \n","Val loss: 0.001191 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 55 \n","Train loss: 0.004444 \n","Val loss: 0.001195 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 56 \n","Train loss: 0.003905 \n","Val loss: 0.001199 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 57 \n","Train loss: 0.004187 \n","Val loss: 0.001195 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 58 \n","Train loss: 0.006294 \n","Val loss: 0.001217 \n","Val acc: 0.938462\n","Val balanced acc: 0.937500\n","Epoch num: 59 \n","Train loss: 0.003973 \n","Val loss: 0.001202 \n","Val acc: 0.938462\n","Val balanced acc: 0.937500\n","Epoch num: 60 \n","Train loss: 0.003877 \n","Val loss: 0.001183 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 61 \n","Train loss: 0.004486 \n","Val loss: 0.001187 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 62 \n","Train loss: 0.006190 \n","Val loss: 0.001200 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 63 \n","Train loss: 0.004564 \n","Val loss: 0.001190 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 64 \n","Train loss: 0.010696 \n","Val loss: 0.001239 \n","Val acc: 0.948718\n","Val balanced acc: 0.947115\n","Epoch num: 65 \n","Train loss: 0.004685 \n","Val loss: 0.001201 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 66 \n","Train loss: 0.007455 \n","Val loss: 0.001216 \n","Val acc: 0.948718\n","Val balanced acc: 0.949176\n","Epoch num: 67 \n","Train loss: 0.007069 \n","Val loss: 0.001210 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 68 \n","Train loss: 0.008172 \n","Val loss: 0.001210 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 69 \n","Train loss: 0.005292 \n","Val loss: 0.001195 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 70 \n","Train loss: 0.003812 \n","Val loss: 0.001193 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 71 \n","Train loss: 0.004198 \n","Val loss: 0.001191 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 72 \n","Train loss: 0.003439 \n","Val loss: 0.001191 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 73 \n","Train loss: 0.004010 \n","Val loss: 0.001192 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 74 \n","Train loss: 0.003692 \n","Val loss: 0.001176 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 75 \n","Train loss: 0.004457 \n","Val loss: 0.001179 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 76 \n","Train loss: 0.003663 \n","Val loss: 0.001192 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 77 \n","Train loss: 0.003928 \n","Val loss: 0.001194 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 78 \n","Train loss: 0.003767 \n","Val loss: 0.001186 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 79 \n","Train loss: 0.004191 \n","Val loss: 0.001191 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 80 \n","Train loss: 0.004479 \n","Val loss: 0.001200 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 81 \n","Train loss: 0.004194 \n","Val loss: 0.001187 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 82 \n","Train loss: 0.005143 \n","Val loss: 0.001199 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 83 \n","Train loss: 0.005168 \n","Val loss: 0.001199 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 84 \n","Train loss: 0.005651 \n","Val loss: 0.001193 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 85 \n","Train loss: 0.004437 \n","Val loss: 0.001183 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 86 \n","Train loss: 0.004168 \n","Val loss: 0.001184 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 87 \n","Train loss: 0.003471 \n","Val loss: 0.001182 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 88 \n","Train loss: 0.004719 \n","Val loss: 0.001196 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 89 \n","Train loss: 0.003997 \n","Val loss: 0.001189 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 90 \n","Train loss: 0.003866 \n","Val loss: 0.001196 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 91 \n","Train loss: 0.004539 \n","Val loss: 0.001194 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 92 \n","Train loss: 0.006838 \n","Val loss: 0.001215 \n","Val acc: 0.938462\n","Val balanced acc: 0.937500\n","Epoch num: 93 \n","Train loss: 0.004123 \n","Val loss: 0.001199 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 94 \n","Train loss: 0.005460 \n","Val loss: 0.001208 \n","Val acc: 0.938462\n","Val balanced acc: 0.937500\n","Epoch num: 95 \n","Train loss: 0.004267 \n","Val loss: 0.001190 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 96 \n","Train loss: 0.003684 \n","Val loss: 0.001194 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 97 \n","Train loss: 0.003990 \n","Val loss: 0.001190 \n","Val acc: 0.943590\n","Val balanced acc: 0.943681\n","Epoch num: 98 \n","Train loss: 0.004232 \n","Val loss: 0.001192 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 99 \n","Train loss: 0.004593 \n","Val loss: 0.001192 \n","Val acc: 0.938462\n","Val balanced acc: 0.938187\n","Epoch num: 100 \n","Train loss: 0.003942 \n","Val loss: 0.001207 \n","Val acc: 0.938462\n","Val balanced acc: 0.937500\n","All done!\n","Epoch num: 1 \n","Train loss: 0.015774 \n","Val loss: 0.000477 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 2 \n","Train loss: 0.012802 \n","Val loss: 0.000473 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 3 \n","Train loss: 0.008212 \n","Val loss: 0.000399 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 4 \n","Train loss: 0.007713 \n","Val loss: 0.000358 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 5 \n","Train loss: 0.004358 \n","Val loss: 0.000269 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 6 \n","Train loss: 0.003332 \n","Val loss: 0.000305 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 7 \n","Train loss: 0.004573 \n","Val loss: 0.000198 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 8 \n","Train loss: 0.004005 \n","Val loss: 0.000280 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 9 \n","Train loss: 0.002929 \n","Val loss: 0.000317 \n","Val acc: 0.988462\n","Val balanced acc: 0.498062\n","Epoch num: 10 \n","Train loss: 0.002818 \n","Val loss: 0.000548 \n","Val acc: 0.969231\n","Val balanced acc: 0.736434\n","Epoch num: 11 \n","Train loss: 0.003832 \n","Val loss: 0.000265 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 12 \n","Train loss: 0.002882 \n","Val loss: 0.000186 \n","Val acc: 0.988462\n","Val balanced acc: 0.498062\n","Epoch num: 13 \n","Train loss: 0.003271 \n","Val loss: 0.000165 \n","Val acc: 0.988462\n","Val balanced acc: 0.498062\n","Epoch num: 14 \n","Train loss: 0.003068 \n","Val loss: 0.000906 \n","Val acc: 0.976923\n","Val balanced acc: 0.988372\n","Epoch num: 15 \n","Train loss: 0.002579 \n","Val loss: 0.000207 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 16 \n","Train loss: 0.002220 \n","Val loss: 0.000703 \n","Val acc: 0.961538\n","Val balanced acc: 0.980620\n","Epoch num: 17 \n","Train loss: 0.002343 \n","Val loss: 0.000176 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 18 \n","Train loss: 0.002419 \n","Val loss: 0.000399 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 19 \n","Train loss: 0.002005 \n","Val loss: 0.000448 \n","Val acc: 0.988462\n","Val balanced acc: 0.994186\n","Epoch num: 20 \n","Train loss: 0.002303 \n","Val loss: 0.000134 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 21 \n","Train loss: 0.002465 \n","Val loss: 0.000424 \n","Val acc: 0.973077\n","Val balanced acc: 0.738372\n","Epoch num: 22 \n","Train loss: 0.002669 \n","Val loss: 0.000477 \n","Val acc: 0.969231\n","Val balanced acc: 0.736434\n","Epoch num: 23 \n","Train loss: 0.002202 \n","Val loss: 0.000982 \n","Val acc: 0.969231\n","Val balanced acc: 0.984496\n","Epoch num: 24 \n","Train loss: 0.001656 \n","Val loss: 0.001744 \n","Val acc: 0.942308\n","Val balanced acc: 0.970930\n","Epoch num: 25 \n","Train loss: 0.002289 \n","Val loss: 0.008518 \n","Val acc: 0.750000\n","Val balanced acc: 0.874031\n","Epoch num: 26 \n","Train loss: 0.003023 \n","Val loss: 0.000286 \n","Val acc: 0.980769\n","Val balanced acc: 0.742248\n","Epoch num: 27 \n","Train loss: 0.002981 \n","Val loss: 0.000246 \n","Val acc: 0.980769\n","Val balanced acc: 0.494186\n","Epoch num: 28 \n","Train loss: 0.002526 \n","Val loss: 0.000317 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 29 \n","Train loss: 0.002175 \n","Val loss: 0.000455 \n","Val acc: 0.984615\n","Val balanced acc: 0.992248\n","Epoch num: 30 \n","Train loss: 0.006389 \n","Val loss: 0.000513 \n","Val acc: 0.969231\n","Val balanced acc: 0.736434\n","Epoch num: 31 \n","Train loss: 0.003010 \n","Val loss: 0.000170 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 32 \n","Train loss: 0.001830 \n","Val loss: 0.000116 \n","Val acc: 0.988462\n","Val balanced acc: 0.498062\n","Epoch num: 33 \n","Train loss: 0.005030 \n","Val loss: 0.000233 \n","Val acc: 0.988462\n","Val balanced acc: 0.994186\n","Epoch num: 34 \n","Train loss: 0.001986 \n","Val loss: 0.000315 \n","Val acc: 0.980769\n","Val balanced acc: 0.742248\n","Epoch num: 35 \n","Train loss: 0.001319 \n","Val loss: 0.000241 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 36 \n","Train loss: 0.001691 \n","Val loss: 0.000190 \n","Val acc: 0.988462\n","Val balanced acc: 0.498062\n","Epoch num: 37 \n","Train loss: 0.001248 \n","Val loss: 0.000204 \n","Val acc: 0.980769\n","Val balanced acc: 0.494186\n","Epoch num: 38 \n","Train loss: 0.001694 \n","Val loss: 0.000269 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 39 \n","Train loss: 0.002659 \n","Val loss: 0.000173 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 40 \n","Train loss: 0.001149 \n","Val loss: 0.000207 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 41 \n","Train loss: 0.001817 \n","Val loss: 0.000152 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 42 \n","Train loss: 0.000960 \n","Val loss: 0.000136 \n","Val acc: 0.992308\n","Val balanced acc: 0.500000\n","Epoch num: 43 \n","Train loss: 0.001126 \n","Val loss: 0.000183 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 44 \n","Train loss: 0.000909 \n","Val loss: 0.000173 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 45 \n","Train loss: 0.000837 \n","Val loss: 0.000147 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 46 \n","Train loss: 0.001871 \n","Val loss: 0.000153 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 47 \n","Train loss: 0.000905 \n","Val loss: 0.000173 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 48 \n","Train loss: 0.001286 \n","Val loss: 0.000183 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 49 \n","Train loss: 0.000776 \n","Val loss: 0.000175 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 50 \n","Train loss: 0.000906 \n","Val loss: 0.000194 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 51 \n","Train loss: 0.000850 \n","Val loss: 0.000198 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 52 \n","Train loss: 0.000804 \n","Val loss: 0.000181 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 53 \n","Train loss: 0.001226 \n","Val loss: 0.000166 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 54 \n","Train loss: 0.000800 \n","Val loss: 0.000199 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 55 \n","Train loss: 0.000945 \n","Val loss: 0.000202 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 56 \n","Train loss: 0.000761 \n","Val loss: 0.000197 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 57 \n","Train loss: 0.001095 \n","Val loss: 0.000200 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 58 \n","Train loss: 0.000853 \n","Val loss: 0.000202 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 59 \n","Train loss: 0.000840 \n","Val loss: 0.000190 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 60 \n","Train loss: 0.000777 \n","Val loss: 0.000206 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 61 \n","Train loss: 0.000778 \n","Val loss: 0.000194 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 62 \n","Train loss: 0.001478 \n","Val loss: 0.000186 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 63 \n","Train loss: 0.000799 \n","Val loss: 0.000189 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 64 \n","Train loss: 0.000892 \n","Val loss: 0.000201 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 65 \n","Train loss: 0.001007 \n","Val loss: 0.000222 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 66 \n","Train loss: 0.000744 \n","Val loss: 0.000214 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 67 \n","Train loss: 0.000602 \n","Val loss: 0.000199 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 68 \n","Train loss: 0.000886 \n","Val loss: 0.000216 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 69 \n","Train loss: 0.001100 \n","Val loss: 0.000232 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 70 \n","Train loss: 0.001049 \n","Val loss: 0.000225 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 71 \n","Train loss: 0.000930 \n","Val loss: 0.000196 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 72 \n","Train loss: 0.001128 \n","Val loss: 0.000181 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 73 \n","Train loss: 0.000846 \n","Val loss: 0.000194 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 74 \n","Train loss: 0.000801 \n","Val loss: 0.000185 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 75 \n","Train loss: 0.000795 \n","Val loss: 0.000218 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 76 \n","Train loss: 0.000702 \n","Val loss: 0.000194 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 77 \n","Train loss: 0.000892 \n","Val loss: 0.000200 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 78 \n","Train loss: 0.000805 \n","Val loss: 0.000185 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 79 \n","Train loss: 0.001654 \n","Val loss: 0.000165 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 80 \n","Train loss: 0.000885 \n","Val loss: 0.000192 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 81 \n","Train loss: 0.000837 \n","Val loss: 0.000209 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 82 \n","Train loss: 0.000803 \n","Val loss: 0.000193 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 83 \n","Train loss: 0.000874 \n","Val loss: 0.000195 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 84 \n","Train loss: 0.000979 \n","Val loss: 0.000179 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 85 \n","Train loss: 0.000823 \n","Val loss: 0.000187 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 86 \n","Train loss: 0.000657 \n","Val loss: 0.000214 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 87 \n","Train loss: 0.000707 \n","Val loss: 0.000223 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 88 \n","Train loss: 0.000994 \n","Val loss: 0.000230 \n","Val acc: 0.984615\n","Val balanced acc: 0.744186\n","Epoch num: 89 \n","Train loss: 0.000840 \n","Val loss: 0.000199 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 90 \n","Train loss: 0.000602 \n","Val loss: 0.000192 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 91 \n","Train loss: 0.000802 \n","Val loss: 0.000203 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 92 \n","Train loss: 0.001360 \n","Val loss: 0.000204 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 93 \n","Train loss: 0.001803 \n","Val loss: 0.000183 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 94 \n","Train loss: 0.000957 \n","Val loss: 0.000194 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 95 \n","Train loss: 0.000791 \n","Val loss: 0.000221 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 96 \n","Train loss: 0.001119 \n","Val loss: 0.000195 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 97 \n","Train loss: 0.000958 \n","Val loss: 0.000215 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 98 \n","Train loss: 0.000861 \n","Val loss: 0.000201 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","Epoch num: 99 \n","Train loss: 0.000987 \n","Val loss: 0.000189 \n","Val acc: 0.984615\n","Val balanced acc: 0.496124\n","Epoch num: 100 \n","Train loss: 0.000778 \n","Val loss: 0.000201 \n","Val acc: 0.988462\n","Val balanced acc: 0.746124\n","All done!\n"]}]},{"cell_type":"markdown","source":["## Experiment with model heterogeneity"],"metadata":{"id":"WXbFtxg3cJkX"}},{"cell_type":"code","source":["FedPneu_heter = fedisca.FedISCA(test_data_dir=\"./\", model_weights_dir=\"./pneumonia_models\", exper_dir=\"./pneumonia_exper/federated\", input_size=28, in_channels=1, num_classes=2, batch_size=64, epochs=25, iter_mi=500, lr_steps = [15, 20], log_freq=25, is_medmnist=True, medmnist=\"pneumoniamnist\")\n","models = [ResNet18(in_channels=1, num_classes=2), ResNet50(in_channels=1, num_classes=2), ResNet18(in_channels=1, num_classes=2),ResNet50(in_channels=1, num_classes=2),ResNet50(in_channels=1, num_classes=2)]\n","fedpneu_local = FedPneu_heter.load_models(models)"],"metadata":{"id":"ro_kr8VFbuAu","executionInfo":{"status":"ok","timestamp":1738130065118,"user_tz":300,"elapsed":24458,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["fed_model, noise_adapt = FedPneu_heter.model_inversion(fedpneu_local, large_jtr=5, small_jtr=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Klhgw5AlkVWn","executionInfo":{"status":"ok","timestamp":1738149274250,"user_tz":300,"elapsed":16616303,"user":{"displayName":"Caleb Chin","userId":"07678352097565562723"}},"outputId":"244d04ea-4c77-4507-cc49-3f2c47f82960"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating images...\n","It 0\t Losses: total: 16926800.000,\ttarget: 2.350 \tR_feature_loss scaled:\t 16926798.000\n","It 25\t Losses: total: 226802.484,\ttarget: 1.868 \tR_feature_loss scaled:\t 226800.594\n","It 50\t Losses: total: 194629.797,\ttarget: 1.841 \tR_feature_loss scaled:\t 194627.938\n","It 75\t Losses: total: 188554.844,\ttarget: 1.849 \tR_feature_loss scaled:\t 188552.984\n","It 100\t Losses: total: 129710.117,\ttarget: 1.879 \tR_feature_loss scaled:\t 129708.219\n","It 125\t Losses: total: 157994.344,\ttarget: 1.860 \tR_feature_loss scaled:\t 157992.469\n","It 150\t Losses: total: 147361.734,\ttarget: 1.905 \tR_feature_loss scaled:\t 147359.812\n","It 175\t Losses: total: 129466.859,\ttarget: 1.907 \tR_feature_loss scaled:\t 129464.938\n","It 200\t Losses: total: 113909.695,\ttarget: 1.897 \tR_feature_loss scaled:\t 113907.781\n","It 225\t Losses: total: 121169.789,\ttarget: 1.902 \tR_feature_loss scaled:\t 121167.875\n","It 250\t Losses: total: 112131.734,\ttarget: 1.917 \tR_feature_loss scaled:\t 112129.805\n","It 275\t Losses: total: 110072.250,\ttarget: 1.886 \tR_feature_loss scaled:\t 110070.352\n","It 300\t Losses: total: 107804.891,\ttarget: 1.865 \tR_feature_loss scaled:\t 107803.008\n","It 325\t Losses: total: 146073.281,\ttarget: 1.866 \tR_feature_loss scaled:\t 146071.406\n","It 350\t Losses: total: 105695.500,\ttarget: 1.846 \tR_feature_loss scaled:\t 105693.641\n","It 375\t Losses: total: 111521.445,\ttarget: 1.858 \tR_feature_loss scaled:\t 111519.570\n","It 400\t Losses: total: 106367.992,\ttarget: 1.812 \tR_feature_loss scaled:\t 106366.164\n","It 425\t Losses: total: 102919.133,\ttarget: 1.788 \tR_feature_loss scaled:\t 102917.328\n","It 450\t Losses: total: 113427.359,\ttarget: 1.787 \tR_feature_loss scaled:\t 113425.555\n","It 475\t Losses: total: 102944.984,\ttarget: 1.671 \tR_feature_loss scaled:\t 102943.297\n","It 500\t Losses: total: 99185.516,\ttarget: 1.601 \tR_feature_loss scaled:\t 99183.898\n","Training classifier...\n","Test classifier\n","Loss: 2.304 | Acc: 37.500% (234/624), B. Acc: 50.000%\n","Generating images...\n","It 0\t Losses: total: 18109762.000,\ttarget: 2.292 \tR_feature_loss scaled:\t 18109760.000\n","It 25\t Losses: total: 232838.766,\ttarget: 1.881 \tR_feature_loss scaled:\t 232836.859\n","It 50\t Losses: total: 211416.062,\ttarget: 1.816 \tR_feature_loss scaled:\t 211414.234\n","It 75\t Losses: total: 157636.312,\ttarget: 1.858 \tR_feature_loss scaled:\t 157634.438\n","It 100\t Losses: total: 129632.055,\ttarget: 1.892 \tR_feature_loss scaled:\t 129630.148\n","It 125\t Losses: total: 137322.500,\ttarget: 1.871 \tR_feature_loss scaled:\t 137320.609\n","It 150\t Losses: total: 123267.914,\ttarget: 1.923 \tR_feature_loss scaled:\t 123265.977\n","It 175\t Losses: total: 121643.297,\ttarget: 1.904 \tR_feature_loss scaled:\t 121641.375\n","It 200\t Losses: total: 118375.695,\ttarget: 1.974 \tR_feature_loss scaled:\t 118373.703\n","It 225\t Losses: total: 112154.203,\ttarget: 1.938 \tR_feature_loss scaled:\t 112152.250\n","It 250\t Losses: total: 111234.180,\ttarget: 1.943 \tR_feature_loss scaled:\t 111232.219\n","It 275\t Losses: total: 109755.516,\ttarget: 1.968 \tR_feature_loss scaled:\t 109753.531\n","It 300\t Losses: total: 109912.031,\ttarget: 1.934 \tR_feature_loss scaled:\t 109910.086\n","It 325\t Losses: total: 107608.078,\ttarget: 1.922 \tR_feature_loss scaled:\t 107606.141\n","It 350\t Losses: total: 110819.852,\ttarget: 1.983 \tR_feature_loss scaled:\t 110817.852\n","It 375\t Losses: total: 106161.992,\ttarget: 1.904 \tR_feature_loss scaled:\t 106160.070\n","It 400\t Losses: total: 102331.594,\ttarget: 1.896 \tR_feature_loss scaled:\t 102329.680\n","It 425\t Losses: total: 106673.930,\ttarget: 1.897 \tR_feature_loss scaled:\t 106672.016\n","It 450\t Losses: total: 103258.625,\ttarget: 1.825 \tR_feature_loss scaled:\t 103256.789\n","It 475\t Losses: total: 103999.055,\ttarget: 1.759 \tR_feature_loss scaled:\t 103997.281\n","It 500\t Losses: total: 105552.398,\ttarget: 1.809 \tR_feature_loss scaled:\t 105550.578\n","Training classifier...\n","Test classifier\n","Loss: 3.624 | Acc: 37.500% (234/624), B. Acc: 50.000%\n","Generating images...\n","It 0\t Losses: total: 19728844.000,\ttarget: 2.071 \tR_feature_loss scaled:\t 19728842.000\n","It 25\t Losses: total: 222657.188,\ttarget: 1.856 \tR_feature_loss scaled:\t 222655.312\n","It 50\t Losses: total: 182779.062,\ttarget: 1.849 \tR_feature_loss scaled:\t 182777.203\n","It 75\t Losses: total: 139614.391,\ttarget: 1.862 \tR_feature_loss scaled:\t 139612.516\n","It 100\t Losses: total: 129694.055,\ttarget: 1.854 \tR_feature_loss scaled:\t 129692.180\n","It 125\t Losses: total: 123308.031,\ttarget: 1.836 \tR_feature_loss scaled:\t 123306.180\n","It 150\t Losses: total: 122109.664,\ttarget: 1.852 \tR_feature_loss scaled:\t 122107.797\n","It 175\t Losses: total: 121706.703,\ttarget: 1.880 \tR_feature_loss scaled:\t 121704.805\n","It 200\t Losses: total: 129732.734,\ttarget: 1.897 \tR_feature_loss scaled:\t 129730.820\n","It 225\t Losses: total: 114246.953,\ttarget: 1.923 \tR_feature_loss scaled:\t 114245.016\n","It 250\t Losses: total: 116317.969,\ttarget: 1.950 \tR_feature_loss scaled:\t 116316.000\n","It 275\t Losses: total: 116596.203,\ttarget: 1.950 \tR_feature_loss scaled:\t 116594.234\n","It 300\t Losses: total: 111125.578,\ttarget: 1.964 \tR_feature_loss scaled:\t 111123.602\n","It 325\t Losses: total: 115387.945,\ttarget: 1.976 \tR_feature_loss scaled:\t 115385.953\n","It 350\t Losses: total: 111930.117,\ttarget: 1.982 \tR_feature_loss scaled:\t 111928.117\n","It 375\t Losses: total: 107902.328,\ttarget: 1.930 \tR_feature_loss scaled:\t 107900.383\n","It 400\t Losses: total: 104408.500,\ttarget: 1.938 \tR_feature_loss scaled:\t 104406.547\n","It 425\t Losses: total: 107180.266,\ttarget: 1.930 \tR_feature_loss scaled:\t 107178.320\n","It 450\t Losses: total: 105302.430,\ttarget: 1.903 \tR_feature_loss scaled:\t 105300.516\n","It 475\t Losses: total: 116150.727,\ttarget: 1.877 \tR_feature_loss scaled:\t 116148.836\n","It 500\t Losses: total: 108849.102,\ttarget: 1.810 \tR_feature_loss scaled:\t 108847.273\n","Training classifier...\n","Test classifier\n","Loss: 4.189 | Acc: 39.583% (247/624), B. Acc: 51.325%\n","Generating images...\n","It 0\t Losses: total: 19168166.000,\ttarget: 2.313 \tR_feature_loss scaled:\t 19168164.000\n","It 25\t Losses: total: 225516.938,\ttarget: 1.890 \tR_feature_loss scaled:\t 225515.031\n","It 50\t Losses: total: 181459.000,\ttarget: 1.861 \tR_feature_loss scaled:\t 181457.125\n","It 75\t Losses: total: 140236.359,\ttarget: 1.869 \tR_feature_loss scaled:\t 140234.469\n","It 100\t Losses: total: 150565.719,\ttarget: 1.805 \tR_feature_loss scaled:\t 150563.891\n","It 125\t Losses: total: 131254.312,\ttarget: 1.821 \tR_feature_loss scaled:\t 131252.469\n","It 150\t Losses: total: 132183.766,\ttarget: 1.847 \tR_feature_loss scaled:\t 132181.906\n","It 175\t Losses: total: 117514.656,\ttarget: 1.864 \tR_feature_loss scaled:\t 117512.773\n","It 200\t Losses: total: 111312.641,\ttarget: 1.845 \tR_feature_loss scaled:\t 111310.781\n","It 225\t Losses: total: 113629.883,\ttarget: 1.855 \tR_feature_loss scaled:\t 113628.008\n","It 250\t Losses: total: 117585.148,\ttarget: 1.848 \tR_feature_loss scaled:\t 117583.281\n","It 275\t Losses: total: 116147.188,\ttarget: 1.831 \tR_feature_loss scaled:\t 116145.344\n","It 300\t Losses: total: 113675.102,\ttarget: 1.808 \tR_feature_loss scaled:\t 113673.281\n","It 325\t Losses: total: 112060.469,\ttarget: 1.793 \tR_feature_loss scaled:\t 112058.656\n","It 350\t Losses: total: 108153.602,\ttarget: 1.794 \tR_feature_loss scaled:\t 108151.789\n","It 375\t Losses: total: 102738.484,\ttarget: 1.745 \tR_feature_loss scaled:\t 102736.727\n","It 400\t Losses: total: 102999.594,\ttarget: 1.730 \tR_feature_loss scaled:\t 102997.852\n","It 425\t Losses: total: 117029.016,\ttarget: 1.734 \tR_feature_loss scaled:\t 117027.266\n","It 450\t Losses: total: 107283.961,\ttarget: 1.727 \tR_feature_loss scaled:\t 107282.219\n","It 475\t Losses: total: 102374.531,\ttarget: 1.657 \tR_feature_loss scaled:\t 102372.859\n","It 500\t Losses: total: 98859.617,\ttarget: 1.647 \tR_feature_loss scaled:\t 98857.953\n","Training classifier...\n","Test classifier\n","Loss: 2.959 | Acc: 39.263% (245/624), B. Acc: 50.897%\n","Generating images...\n","It 0\t Losses: total: 18258160.000,\ttarget: 2.313 \tR_feature_loss scaled:\t 18258158.000\n","It 25\t Losses: total: 234363.141,\ttarget: 1.903 \tR_feature_loss scaled:\t 234361.219\n","It 50\t Losses: total: 187554.859,\ttarget: 1.909 \tR_feature_loss scaled:\t 187552.938\n","It 75\t Losses: total: 144982.219,\ttarget: 1.847 \tR_feature_loss scaled:\t 144980.359\n","It 100\t Losses: total: 137956.219,\ttarget: 1.891 \tR_feature_loss scaled:\t 137954.312\n","It 125\t Losses: total: 128169.125,\ttarget: 1.889 \tR_feature_loss scaled:\t 128167.219\n","It 150\t Losses: total: 145121.734,\ttarget: 1.848 \tR_feature_loss scaled:\t 145119.875\n","It 175\t Losses: total: 125344.617,\ttarget: 1.859 \tR_feature_loss scaled:\t 125342.742\n","It 200\t Losses: total: 118107.328,\ttarget: 1.904 \tR_feature_loss scaled:\t 118105.406\n","It 225\t Losses: total: 112645.680,\ttarget: 1.898 \tR_feature_loss scaled:\t 112643.766\n","It 250\t Losses: total: 117243.078,\ttarget: 1.878 \tR_feature_loss scaled:\t 117241.188\n","It 275\t Losses: total: 121637.750,\ttarget: 1.878 \tR_feature_loss scaled:\t 121635.859\n","It 300\t Losses: total: 111838.039,\ttarget: 1.890 \tR_feature_loss scaled:\t 111836.133\n","It 325\t Losses: total: 119025.250,\ttarget: 1.892 \tR_feature_loss scaled:\t 119023.344\n","It 350\t Losses: total: 108743.992,\ttarget: 1.898 \tR_feature_loss scaled:\t 108742.078\n","It 375\t Losses: total: 116033.234,\ttarget: 1.824 \tR_feature_loss scaled:\t 116031.398\n","It 400\t Losses: total: 107347.195,\ttarget: 1.903 \tR_feature_loss scaled:\t 107345.281\n","It 425\t Losses: total: 104960.820,\ttarget: 1.811 \tR_feature_loss scaled:\t 104958.992\n","It 450\t Losses: total: 109096.039,\ttarget: 1.776 \tR_feature_loss scaled:\t 109094.250\n","It 475\t Losses: total: 101081.055,\ttarget: 1.821 \tR_feature_loss scaled:\t 101079.219\n","It 500\t Losses: total: 105116.359,\ttarget: 1.775 \tR_feature_loss scaled:\t 105114.570\n","Training classifier...\n","Test classifier\n","Loss: 3.399 | Acc: 37.500% (234/624), B. Acc: 50.000%\n","Generating images...\n","It 0\t Losses: total: 17976698.000,\ttarget: 2.199 \tR_feature_loss scaled:\t 17976696.000\n","It 25\t Losses: total: 226431.469,\ttarget: 1.945 \tR_feature_loss scaled:\t 226429.500\n","It 50\t Losses: total: 180906.594,\ttarget: 1.919 \tR_feature_loss scaled:\t 180904.656\n","It 75\t Losses: total: 178528.750,\ttarget: 1.944 \tR_feature_loss scaled:\t 178526.781\n","It 100\t Losses: total: 131244.422,\ttarget: 1.963 \tR_feature_loss scaled:\t 131242.438\n","It 125\t Losses: total: 126553.336,\ttarget: 1.961 \tR_feature_loss scaled:\t 126551.359\n","It 150\t Losses: total: 122947.984,\ttarget: 1.971 \tR_feature_loss scaled:\t 122946.000\n","It 175\t Losses: total: 117689.758,\ttarget: 2.004 \tR_feature_loss scaled:\t 117687.734\n","It 200\t Losses: total: 119137.672,\ttarget: 1.997 \tR_feature_loss scaled:\t 119135.656\n","It 225\t Losses: total: 112584.297,\ttarget: 2.011 \tR_feature_loss scaled:\t 112582.273\n","It 250\t Losses: total: 111202.781,\ttarget: 2.013 \tR_feature_loss scaled:\t 111200.750\n","It 275\t Losses: total: 113524.578,\ttarget: 2.002 \tR_feature_loss scaled:\t 113522.562\n","It 300\t Losses: total: 113067.977,\ttarget: 2.005 \tR_feature_loss scaled:\t 113065.953\n","It 325\t Losses: total: 110472.164,\ttarget: 1.994 \tR_feature_loss scaled:\t 110470.156\n","It 350\t Losses: total: 119801.664,\ttarget: 1.960 \tR_feature_loss scaled:\t 119799.688\n","It 375\t Losses: total: 107656.477,\ttarget: 1.958 \tR_feature_loss scaled:\t 107654.500\n","It 400\t Losses: total: 107040.781,\ttarget: 1.937 \tR_feature_loss scaled:\t 107038.828\n","It 425\t Losses: total: 108478.305,\ttarget: 1.918 \tR_feature_loss scaled:\t 108476.375\n","It 450\t Losses: total: 119383.094,\ttarget: 1.878 \tR_feature_loss scaled:\t 119381.203\n","It 475\t Losses: total: 106514.867,\ttarget: 1.852 \tR_feature_loss scaled:\t 106513.000\n","It 500\t Losses: total: 111083.484,\ttarget: 1.869 \tR_feature_loss scaled:\t 111081.602\n","Training classifier...\n","Test classifier\n","Loss: 3.712 | Acc: 37.500% (234/624), B. Acc: 50.000%\n","Generating images...\n","It 0\t Losses: total: 18541394.000,\ttarget: 2.269 \tR_feature_loss scaled:\t 18541392.000\n","It 25\t Losses: total: 227832.641,\ttarget: 1.915 \tR_feature_loss scaled:\t 227830.703\n","It 50\t Losses: total: 187107.500,\ttarget: 1.881 \tR_feature_loss scaled:\t 187105.594\n","It 75\t Losses: total: 144009.969,\ttarget: 1.906 \tR_feature_loss scaled:\t 144008.047\n","It 100\t Losses: total: 135281.766,\ttarget: 1.914 \tR_feature_loss scaled:\t 135279.828\n","It 125\t Losses: total: 129133.633,\ttarget: 1.904 \tR_feature_loss scaled:\t 129131.711\n","It 150\t Losses: total: 117429.742,\ttarget: 1.948 \tR_feature_loss scaled:\t 117427.781\n","It 175\t Losses: total: 119179.617,\ttarget: 1.931 \tR_feature_loss scaled:\t 119177.672\n","It 200\t Losses: total: 111076.391,\ttarget: 1.984 \tR_feature_loss scaled:\t 111074.391\n","It 225\t Losses: total: 108093.719,\ttarget: 1.988 \tR_feature_loss scaled:\t 108091.719\n","It 250\t Losses: total: 110926.445,\ttarget: 2.018 \tR_feature_loss scaled:\t 110924.414\n","It 275\t Losses: total: 124646.586,\ttarget: 1.968 \tR_feature_loss scaled:\t 124644.602\n","It 300\t Losses: total: 110615.742,\ttarget: 1.973 \tR_feature_loss scaled:\t 110613.758\n","It 325\t Losses: total: 122602.297,\ttarget: 2.008 \tR_feature_loss scaled:\t 122600.273\n","It 350\t Losses: total: 104347.844,\ttarget: 1.956 \tR_feature_loss scaled:\t 104345.875\n","It 375\t Losses: total: 105302.820,\ttarget: 1.951 \tR_feature_loss scaled:\t 105300.852\n","It 400\t Losses: total: 106813.094,\ttarget: 1.951 \tR_feature_loss scaled:\t 106811.125\n","It 425\t Losses: total: 109068.156,\ttarget: 1.951 \tR_feature_loss scaled:\t 109066.188\n","It 450\t Losses: total: 104662.453,\ttarget: 1.901 \tR_feature_loss scaled:\t 104660.539\n","It 475\t Losses: total: 106030.586,\ttarget: 1.916 \tR_feature_loss scaled:\t 106028.656\n","It 500\t Losses: total: 105286.602,\ttarget: 1.790 \tR_feature_loss scaled:\t 105284.797\n","Training classifier...\n","Test classifier\n","Loss: 3.513 | Acc: 37.500% (234/624), B. Acc: 50.000%\n","Generating images...\n","It 0\t Losses: total: 18219168.000,\ttarget: 2.305 \tR_feature_loss scaled:\t 18219166.000\n","It 25\t Losses: total: 232599.359,\ttarget: 1.930 \tR_feature_loss scaled:\t 232597.406\n","It 50\t Losses: total: 156546.359,\ttarget: 1.919 \tR_feature_loss scaled:\t 156544.422\n","It 75\t Losses: total: 187207.969,\ttarget: 1.928 \tR_feature_loss scaled:\t 187206.031\n","It 100\t Losses: total: 147467.141,\ttarget: 1.937 \tR_feature_loss scaled:\t 147465.188\n","It 125\t Losses: total: 131079.328,\ttarget: 1.960 \tR_feature_loss scaled:\t 131077.344\n","It 150\t Losses: total: 118792.336,\ttarget: 1.992 \tR_feature_loss scaled:\t 118790.328\n","It 175\t Losses: total: 124161.453,\ttarget: 2.003 \tR_feature_loss scaled:\t 124159.438\n","It 200\t Losses: total: 119745.141,\ttarget: 2.002 \tR_feature_loss scaled:\t 119743.125\n","It 225\t Losses: total: 111746.055,\ttarget: 2.015 \tR_feature_loss scaled:\t 111744.023\n","It 250\t Losses: total: 114552.086,\ttarget: 1.999 \tR_feature_loss scaled:\t 114550.070\n","It 275\t Losses: total: 115905.023,\ttarget: 1.977 \tR_feature_loss scaled:\t 115903.031\n","It 300\t Losses: total: 106919.531,\ttarget: 1.977 \tR_feature_loss scaled:\t 106917.539\n","It 325\t Losses: total: 110442.031,\ttarget: 1.936 \tR_feature_loss scaled:\t 110440.078\n","It 350\t Losses: total: 116189.094,\ttarget: 1.921 \tR_feature_loss scaled:\t 116187.156\n","It 375\t Losses: total: 104998.609,\ttarget: 1.903 \tR_feature_loss scaled:\t 104996.688\n","It 400\t Losses: total: 105277.969,\ttarget: 1.846 \tR_feature_loss scaled:\t 105276.109\n","It 425\t Losses: total: 102315.508,\ttarget: 1.851 \tR_feature_loss scaled:\t 102313.641\n","It 450\t Losses: total: 108508.484,\ttarget: 1.797 \tR_feature_loss scaled:\t 108506.672\n","It 475\t Losses: total: 112441.469,\ttarget: 1.813 \tR_feature_loss scaled:\t 112439.641\n","It 500\t Losses: total: 100312.797,\ttarget: 1.799 \tR_feature_loss scaled:\t 100310.984\n","Training classifier...\n","Test classifier\n","Loss: 3.722 | Acc: 37.500% (234/624), B. Acc: 50.000%\n","Generating images...\n","It 0\t Losses: total: 19124008.000,\ttarget: 2.314 \tR_feature_loss scaled:\t 19124006.000\n","It 25\t Losses: total: 228966.953,\ttarget: 1.991 \tR_feature_loss scaled:\t 228964.938\n","It 50\t Losses: total: 163413.656,\ttarget: 1.957 \tR_feature_loss scaled:\t 163411.688\n","It 75\t Losses: total: 164171.172,\ttarget: 1.959 \tR_feature_loss scaled:\t 164169.203\n","It 100\t Losses: total: 128214.336,\ttarget: 1.960 \tR_feature_loss scaled:\t 128212.359\n","It 125\t Losses: total: 132044.984,\ttarget: 1.956 \tR_feature_loss scaled:\t 132043.016\n","It 150\t Losses: total: 128812.523,\ttarget: 1.979 \tR_feature_loss scaled:\t 128810.531\n","It 175\t Losses: total: 124034.203,\ttarget: 1.982 \tR_feature_loss scaled:\t 124032.203\n","It 200\t Losses: total: 115757.344,\ttarget: 1.979 \tR_feature_loss scaled:\t 115755.352\n","It 225\t Losses: total: 115090.375,\ttarget: 1.991 \tR_feature_loss scaled:\t 115088.367\n","It 250\t Losses: total: 113733.133,\ttarget: 2.022 \tR_feature_loss scaled:\t 113731.094\n","It 275\t Losses: total: 111693.641,\ttarget: 2.028 \tR_feature_loss scaled:\t 111691.594\n","It 300\t Losses: total: 110018.375,\ttarget: 2.035 \tR_feature_loss scaled:\t 110016.328\n","It 325\t Losses: total: 117908.008,\ttarget: 2.049 \tR_feature_loss scaled:\t 117905.945\n","It 350\t Losses: total: 107934.516,\ttarget: 1.987 \tR_feature_loss scaled:\t 107932.516\n","It 375\t Losses: total: 111357.805,\ttarget: 1.971 \tR_feature_loss scaled:\t 111355.820\n","It 400\t Losses: total: 105913.688,\ttarget: 1.892 \tR_feature_loss scaled:\t 105911.781\n","It 425\t Losses: total: 101534.656,\ttarget: 1.893 \tR_feature_loss scaled:\t 101532.750\n","It 450\t Losses: total: 95527.023,\ttarget: 1.929 \tR_feature_loss scaled:\t 95525.078\n","It 475\t Losses: total: 105324.953,\ttarget: 1.931 \tR_feature_loss scaled:\t 105323.008\n","It 500\t Losses: total: 94292.133,\ttarget: 1.920 \tR_feature_loss scaled:\t 94290.195\n","Training classifier...\n","Test classifier\n","Loss: 3.506 | Acc: 37.821% (236/624), B. Acc: 50.256%\n","Generating images...\n","It 0\t Losses: total: 18924716.000,\ttarget: 2.310 \tR_feature_loss scaled:\t 18924714.000\n","It 25\t Losses: total: 218052.719,\ttarget: 1.843 \tR_feature_loss scaled:\t 218050.859\n","It 50\t Losses: total: 159075.250,\ttarget: 1.833 \tR_feature_loss scaled:\t 159073.406\n","It 75\t Losses: total: 156073.594,\ttarget: 1.888 \tR_feature_loss scaled:\t 156071.688\n","It 100\t Losses: total: 138818.250,\ttarget: 1.885 \tR_feature_loss scaled:\t 138816.344\n","It 125\t Losses: total: 127566.406,\ttarget: 1.857 \tR_feature_loss scaled:\t 127564.531\n","It 150\t Losses: total: 120879.094,\ttarget: 1.886 \tR_feature_loss scaled:\t 120877.188\n","It 175\t Losses: total: 118633.352,\ttarget: 1.895 \tR_feature_loss scaled:\t 118631.438\n","It 200\t Losses: total: 118588.266,\ttarget: 1.882 \tR_feature_loss scaled:\t 118586.367\n","It 225\t Losses: total: 113047.305,\ttarget: 1.889 \tR_feature_loss scaled:\t 113045.398\n","It 250\t Losses: total: 111785.719,\ttarget: 1.908 \tR_feature_loss scaled:\t 111783.797\n","It 275\t Losses: total: 111905.984,\ttarget: 1.876 \tR_feature_loss scaled:\t 111904.094\n","It 300\t Losses: total: 116216.055,\ttarget: 1.851 \tR_feature_loss scaled:\t 116214.188\n","It 325\t Losses: total: 113459.305,\ttarget: 1.857 \tR_feature_loss scaled:\t 113457.430\n","It 350\t Losses: total: 106318.516,\ttarget: 1.856 \tR_feature_loss scaled:\t 106316.641\n","It 375\t Losses: total: 109087.820,\ttarget: 1.834 \tR_feature_loss scaled:\t 109085.969\n","It 400\t Losses: total: 109096.031,\ttarget: 1.807 \tR_feature_loss scaled:\t 109094.211\n","It 425\t Losses: total: 112813.688,\ttarget: 1.848 \tR_feature_loss scaled:\t 112811.828\n","It 450\t Losses: total: 102745.633,\ttarget: 1.906 \tR_feature_loss scaled:\t 102743.711\n","It 475\t Losses: total: 103607.000,\ttarget: 1.944 \tR_feature_loss scaled:\t 103605.039\n","It 500\t Losses: total: 100725.891,\ttarget: 1.930 \tR_feature_loss scaled:\t 100723.945\n","Training classifier...\n","Test classifier\n","Loss: 2.218 | Acc: 44.231% (276/624), B. Acc: 52.821%\n","Generating images...\n","It 0\t Losses: total: 18877520.000,\ttarget: 2.403 \tR_feature_loss scaled:\t 18877518.000\n","It 25\t Losses: total: 227678.672,\ttarget: 1.849 \tR_feature_loss scaled:\t 227676.797\n","It 50\t Losses: total: 170774.109,\ttarget: 1.812 \tR_feature_loss scaled:\t 170772.281\n","It 75\t Losses: total: 149190.500,\ttarget: 1.824 \tR_feature_loss scaled:\t 149188.656\n","It 100\t Losses: total: 127699.008,\ttarget: 1.797 \tR_feature_loss scaled:\t 127697.195\n","It 125\t Losses: total: 130770.375,\ttarget: 1.829 \tR_feature_loss scaled:\t 130768.531\n","It 150\t Losses: total: 126591.812,\ttarget: 1.835 \tR_feature_loss scaled:\t 126589.961\n","It 175\t Losses: total: 122988.555,\ttarget: 1.858 \tR_feature_loss scaled:\t 122986.680\n","It 200\t Losses: total: 117428.383,\ttarget: 1.877 \tR_feature_loss scaled:\t 117426.492\n","It 225\t Losses: total: 124396.984,\ttarget: 1.905 \tR_feature_loss scaled:\t 124395.062\n","It 250\t Losses: total: 117465.742,\ttarget: 1.941 \tR_feature_loss scaled:\t 117463.789\n","It 275\t Losses: total: 109157.430,\ttarget: 1.948 \tR_feature_loss scaled:\t 109155.469\n","It 300\t Losses: total: 107408.609,\ttarget: 1.962 \tR_feature_loss scaled:\t 107406.633\n","It 325\t Losses: total: 113514.633,\ttarget: 1.962 \tR_feature_loss scaled:\t 113512.656\n","It 350\t Losses: total: 114158.117,\ttarget: 1.933 \tR_feature_loss scaled:\t 114156.172\n","It 375\t Losses: total: 114518.008,\ttarget: 1.894 \tR_feature_loss scaled:\t 114516.102\n","It 400\t Losses: total: 115389.188,\ttarget: 1.897 \tR_feature_loss scaled:\t 115387.273\n","It 425\t Losses: total: 110345.625,\ttarget: 1.867 \tR_feature_loss scaled:\t 110343.742\n","It 450\t Losses: total: 108873.250,\ttarget: 1.826 \tR_feature_loss scaled:\t 108871.406\n","It 475\t Losses: total: 100913.125,\ttarget: 1.721 \tR_feature_loss scaled:\t 100911.391\n","It 500\t Losses: total: 109430.117,\ttarget: 1.711 \tR_feature_loss scaled:\t 109428.391\n","Training classifier...\n","Test classifier\n","Loss: 3.846 | Acc: 39.103% (244/624), B. Acc: 51.111%\n","Generating images...\n","It 0\t Losses: total: 17357044.000,\ttarget: 2.289 \tR_feature_loss scaled:\t 17357042.000\n","It 25\t Losses: total: 207339.375,\ttarget: 1.797 \tR_feature_loss scaled:\t 207337.562\n","It 50\t Losses: total: 213324.469,\ttarget: 1.817 \tR_feature_loss scaled:\t 213322.641\n","It 75\t Losses: total: 136080.219,\ttarget: 1.832 \tR_feature_loss scaled:\t 136078.375\n","It 100\t Losses: total: 133152.719,\ttarget: 1.809 \tR_feature_loss scaled:\t 133150.891\n","It 125\t Losses: total: 136299.281,\ttarget: 1.820 \tR_feature_loss scaled:\t 136297.438\n","It 150\t Losses: total: 121149.828,\ttarget: 1.801 \tR_feature_loss scaled:\t 121148.008\n","It 175\t Losses: total: 117960.352,\ttarget: 1.866 \tR_feature_loss scaled:\t 117958.469\n","It 200\t Losses: total: 116180.812,\ttarget: 1.877 \tR_feature_loss scaled:\t 116178.922\n","It 225\t Losses: total: 113854.500,\ttarget: 1.874 \tR_feature_loss scaled:\t 113852.609\n","It 250\t Losses: total: 113805.195,\ttarget: 1.859 \tR_feature_loss scaled:\t 113803.320\n","It 275\t Losses: total: 107895.492,\ttarget: 1.884 \tR_feature_loss scaled:\t 107893.594\n","It 300\t Losses: total: 108505.117,\ttarget: 1.867 \tR_feature_loss scaled:\t 108503.234\n","It 325\t Losses: total: 116005.117,\ttarget: 1.803 \tR_feature_loss scaled:\t 116003.297\n","It 350\t Losses: total: 110269.391,\ttarget: 1.817 \tR_feature_loss scaled:\t 110267.562\n","It 375\t Losses: total: 103646.445,\ttarget: 1.745 \tR_feature_loss scaled:\t 103644.688\n","It 400\t Losses: total: 105092.859,\ttarget: 1.768 \tR_feature_loss scaled:\t 105091.078\n","It 425\t Losses: total: 100818.383,\ttarget: 1.699 \tR_feature_loss scaled:\t 100816.672\n","It 450\t Losses: total: 103275.500,\ttarget: 1.737 \tR_feature_loss scaled:\t 103273.750\n","It 475\t Losses: total: 99833.891,\ttarget: 1.736 \tR_feature_loss scaled:\t 99832.141\n","It 500\t Losses: total: 98902.086,\ttarget: 1.722 \tR_feature_loss scaled:\t 98900.352\n","Training classifier...\n","Test classifier\n","Loss: 4.336 | Acc: 39.583% (247/624), B. Acc: 51.239%\n","Generating images...\n","It 0\t Losses: total: 18534324.000,\ttarget: 2.287 \tR_feature_loss scaled:\t 18534322.000\n","It 25\t Losses: total: 232292.312,\ttarget: 1.887 \tR_feature_loss scaled:\t 232290.406\n","It 50\t Losses: total: 187851.219,\ttarget: 1.849 \tR_feature_loss scaled:\t 187849.359\n","It 75\t Losses: total: 134008.609,\ttarget: 1.846 \tR_feature_loss scaled:\t 134006.750\n","It 100\t Losses: total: 143646.234,\ttarget: 1.830 \tR_feature_loss scaled:\t 143644.391\n","It 125\t Losses: total: 123277.047,\ttarget: 1.843 \tR_feature_loss scaled:\t 123275.188\n","It 150\t Losses: total: 120797.086,\ttarget: 1.865 \tR_feature_loss scaled:\t 120795.203\n","It 175\t Losses: total: 118380.883,\ttarget: 1.866 \tR_feature_loss scaled:\t 118379.000\n","It 200\t Losses: total: 117930.672,\ttarget: 1.900 \tR_feature_loss scaled:\t 117928.758\n","It 225\t Losses: total: 119953.727,\ttarget: 1.917 \tR_feature_loss scaled:\t 119951.797\n","It 250\t Losses: total: 111447.664,\ttarget: 1.905 \tR_feature_loss scaled:\t 111445.742\n","It 275\t Losses: total: 114078.539,\ttarget: 1.897 \tR_feature_loss scaled:\t 114076.625\n","It 300\t Losses: total: 115491.867,\ttarget: 1.863 \tR_feature_loss scaled:\t 115489.992\n","It 325\t Losses: total: 112810.812,\ttarget: 1.850 \tR_feature_loss scaled:\t 112808.945\n","It 350\t Losses: total: 109737.305,\ttarget: 1.839 \tR_feature_loss scaled:\t 109735.453\n","It 375\t Losses: total: 107221.438,\ttarget: 1.829 \tR_feature_loss scaled:\t 107219.594\n","It 400\t Losses: total: 112152.945,\ttarget: 1.767 \tR_feature_loss scaled:\t 112151.164\n","It 425\t Losses: total: 105726.992,\ttarget: 1.742 \tR_feature_loss scaled:\t 105725.234\n","It 450\t Losses: total: 107907.453,\ttarget: 1.743 \tR_feature_loss scaled:\t 107905.695\n","It 475\t Losses: total: 107186.742,\ttarget: 1.679 \tR_feature_loss scaled:\t 107185.047\n","It 500\t Losses: total: 114703.867,\ttarget: 1.653 \tR_feature_loss scaled:\t 114702.203\n","Training classifier...\n","Test classifier\n","Loss: 5.514 | Acc: 39.904% (249/624), B. Acc: 51.325%\n","Generating images...\n","It 0\t Losses: total: 18116336.000,\ttarget: 2.293 \tR_feature_loss scaled:\t 18116334.000\n","It 25\t Losses: total: 218576.594,\ttarget: 1.886 \tR_feature_loss scaled:\t 218574.688\n","It 50\t Losses: total: 177067.797,\ttarget: 1.864 \tR_feature_loss scaled:\t 177065.922\n","It 75\t Losses: total: 133844.828,\ttarget: 1.859 \tR_feature_loss scaled:\t 133842.953\n","It 100\t Losses: total: 127379.867,\ttarget: 1.864 \tR_feature_loss scaled:\t 127377.984\n","It 125\t Losses: total: 131852.844,\ttarget: 1.799 \tR_feature_loss scaled:\t 131851.031\n","It 150\t Losses: total: 121643.328,\ttarget: 1.777 \tR_feature_loss scaled:\t 121641.531\n","It 175\t Losses: total: 114271.898,\ttarget: 1.801 \tR_feature_loss scaled:\t 114270.078\n","It 200\t Losses: total: 117596.930,\ttarget: 1.773 \tR_feature_loss scaled:\t 117595.141\n","It 225\t Losses: total: 124205.445,\ttarget: 1.776 \tR_feature_loss scaled:\t 124203.656\n","It 250\t Losses: total: 112226.031,\ttarget: 1.797 \tR_feature_loss scaled:\t 112224.219\n","It 275\t Losses: total: 119111.320,\ttarget: 1.771 \tR_feature_loss scaled:\t 119109.531\n","It 300\t Losses: total: 111413.609,\ttarget: 1.797 \tR_feature_loss scaled:\t 111411.797\n","It 325\t Losses: total: 112980.664,\ttarget: 1.775 \tR_feature_loss scaled:\t 112978.875\n","It 350\t Losses: total: 109437.133,\ttarget: 1.727 \tR_feature_loss scaled:\t 109435.391\n","It 375\t Losses: total: 106741.664,\ttarget: 1.764 \tR_feature_loss scaled:\t 106739.883\n","It 400\t Losses: total: 107749.945,\ttarget: 1.695 \tR_feature_loss scaled:\t 107748.234\n","It 425\t Losses: total: 102772.906,\ttarget: 1.733 \tR_feature_loss scaled:\t 102771.156\n","It 450\t Losses: total: 104288.875,\ttarget: 1.710 \tR_feature_loss scaled:\t 104287.148\n","It 475\t Losses: total: 100406.031,\ttarget: 1.690 \tR_feature_loss scaled:\t 100404.328\n","It 500\t Losses: total: 104141.719,\ttarget: 1.639 \tR_feature_loss scaled:\t 104140.062\n","Training classifier...\n","Test classifier\n","Loss: 4.417 | Acc: 40.064% (250/624), B. Acc: 51.538%\n","Generating images...\n","It 0\t Losses: total: 18525528.000,\ttarget: 2.226 \tR_feature_loss scaled:\t 18525526.000\n","It 25\t Losses: total: 229621.391,\ttarget: 1.911 \tR_feature_loss scaled:\t 229619.453\n","It 50\t Losses: total: 168903.234,\ttarget: 1.889 \tR_feature_loss scaled:\t 168901.328\n","It 75\t Losses: total: 138928.656,\ttarget: 1.893 \tR_feature_loss scaled:\t 138926.750\n","It 100\t Losses: total: 127563.922,\ttarget: 1.891 \tR_feature_loss scaled:\t 127562.016\n","It 125\t Losses: total: 129523.148,\ttarget: 1.898 \tR_feature_loss scaled:\t 129521.234\n","It 150\t Losses: total: 120255.258,\ttarget: 1.871 \tR_feature_loss scaled:\t 120253.367\n","It 175\t Losses: total: 116552.820,\ttarget: 1.901 \tR_feature_loss scaled:\t 116550.906\n","It 200\t Losses: total: 118902.289,\ttarget: 1.878 \tR_feature_loss scaled:\t 118900.398\n","It 225\t Losses: total: 113166.875,\ttarget: 1.875 \tR_feature_loss scaled:\t 113164.984\n","It 250\t Losses: total: 110961.586,\ttarget: 1.838 \tR_feature_loss scaled:\t 110959.734\n","It 275\t Losses: total: 111748.500,\ttarget: 1.852 \tR_feature_loss scaled:\t 111746.633\n","It 300\t Losses: total: 112529.742,\ttarget: 1.840 \tR_feature_loss scaled:\t 112527.891\n","It 325\t Losses: total: 110784.664,\ttarget: 1.825 \tR_feature_loss scaled:\t 110782.820\n","It 350\t Losses: total: 108516.594,\ttarget: 1.797 \tR_feature_loss scaled:\t 108514.781\n","It 375\t Losses: total: 112876.930,\ttarget: 1.799 \tR_feature_loss scaled:\t 112875.117\n","It 400\t Losses: total: 108726.734,\ttarget: 1.763 \tR_feature_loss scaled:\t 108724.953\n","It 425\t Losses: total: 110472.984,\ttarget: 1.756 \tR_feature_loss scaled:\t 110471.211\n","It 450\t Losses: total: 106715.945,\ttarget: 1.724 \tR_feature_loss scaled:\t 106714.203\n","It 475\t Losses: total: 104928.578,\ttarget: 1.659 \tR_feature_loss scaled:\t 104926.906\n","It 500\t Losses: total: 108987.133,\ttarget: 1.642 \tR_feature_loss scaled:\t 108985.477\n","Training classifier...\n","Test classifier\n","Loss: 6.481 | Acc: 38.141% (238/624), B. Acc: 50.513%\n","Generating images...\n","It 0\t Losses: total: 18716404.000,\ttarget: 2.187 \tR_feature_loss scaled:\t 18716402.000\n","It 25\t Losses: total: 229902.812,\ttarget: 1.915 \tR_feature_loss scaled:\t 229900.875\n","It 50\t Losses: total: 180274.609,\ttarget: 1.914 \tR_feature_loss scaled:\t 180272.672\n","It 75\t Losses: total: 155662.156,\ttarget: 1.919 \tR_feature_loss scaled:\t 155660.219\n","It 100\t Losses: total: 134530.359,\ttarget: 1.879 \tR_feature_loss scaled:\t 134528.469\n","It 125\t Losses: total: 128354.539,\ttarget: 1.837 \tR_feature_loss scaled:\t 128352.688\n","It 150\t Losses: total: 130097.773,\ttarget: 1.832 \tR_feature_loss scaled:\t 130095.922\n","It 175\t Losses: total: 130559.258,\ttarget: 1.887 \tR_feature_loss scaled:\t 130557.352\n","It 200\t Losses: total: 119477.211,\ttarget: 1.885 \tR_feature_loss scaled:\t 119475.312\n","It 225\t Losses: total: 116232.438,\ttarget: 1.909 \tR_feature_loss scaled:\t 116230.516\n","It 250\t Losses: total: 116812.391,\ttarget: 1.946 \tR_feature_loss scaled:\t 116810.430\n","It 275\t Losses: total: 117631.938,\ttarget: 1.892 \tR_feature_loss scaled:\t 117630.031\n","It 300\t Losses: total: 126155.664,\ttarget: 1.976 \tR_feature_loss scaled:\t 126153.672\n","It 325\t Losses: total: 113272.234,\ttarget: 1.992 \tR_feature_loss scaled:\t 113270.227\n","It 350\t Losses: total: 108931.875,\ttarget: 1.956 \tR_feature_loss scaled:\t 108929.906\n","It 375\t Losses: total: 107103.711,\ttarget: 1.907 \tR_feature_loss scaled:\t 107101.789\n","It 400\t Losses: total: 116309.617,\ttarget: 1.927 \tR_feature_loss scaled:\t 116307.672\n","It 425\t Losses: total: 103574.633,\ttarget: 1.837 \tR_feature_loss scaled:\t 103572.781\n","It 450\t Losses: total: 110804.578,\ttarget: 1.871 \tR_feature_loss scaled:\t 110802.695\n","It 475\t Losses: total: 105790.539,\ttarget: 1.815 \tR_feature_loss scaled:\t 105788.711\n","It 500\t Losses: total: 105388.969,\ttarget: 1.829 \tR_feature_loss scaled:\t 105387.125\n","Training classifier...\n","Test classifier\n","Loss: 7.342 | Acc: 38.942% (243/624), B. Acc: 51.068%\n","Generating images...\n","It 0\t Losses: total: 18323600.000,\ttarget: 2.307 \tR_feature_loss scaled:\t 18323598.000\n","It 25\t Losses: total: 233340.531,\ttarget: 1.892 \tR_feature_loss scaled:\t 233338.625\n","It 50\t Losses: total: 176284.047,\ttarget: 1.897 \tR_feature_loss scaled:\t 176282.125\n","It 75\t Losses: total: 140468.062,\ttarget: 1.825 \tR_feature_loss scaled:\t 140466.219\n","It 100\t Losses: total: 129412.867,\ttarget: 1.816 \tR_feature_loss scaled:\t 129411.031\n","It 125\t Losses: total: 126866.328,\ttarget: 1.820 \tR_feature_loss scaled:\t 126864.492\n","It 150\t Losses: total: 119068.750,\ttarget: 1.821 \tR_feature_loss scaled:\t 119066.914\n","It 175\t Losses: total: 127560.719,\ttarget: 1.829 \tR_feature_loss scaled:\t 127558.875\n","It 200\t Losses: total: 118638.766,\ttarget: 1.809 \tR_feature_loss scaled:\t 118636.938\n","It 225\t Losses: total: 116655.922,\ttarget: 1.810 \tR_feature_loss scaled:\t 116654.094\n","It 250\t Losses: total: 110102.031,\ttarget: 1.812 \tR_feature_loss scaled:\t 110100.203\n","It 275\t Losses: total: 109939.984,\ttarget: 1.797 \tR_feature_loss scaled:\t 109938.172\n","It 300\t Losses: total: 116623.664,\ttarget: 1.815 \tR_feature_loss scaled:\t 116621.836\n","It 325\t Losses: total: 110285.867,\ttarget: 1.774 \tR_feature_loss scaled:\t 110284.078\n","It 350\t Losses: total: 112553.453,\ttarget: 1.793 \tR_feature_loss scaled:\t 112551.648\n","It 375\t Losses: total: 106012.508,\ttarget: 1.775 \tR_feature_loss scaled:\t 106010.719\n","It 400\t Losses: total: 110064.875,\ttarget: 1.738 \tR_feature_loss scaled:\t 110063.125\n","It 425\t Losses: total: 116439.523,\ttarget: 1.737 \tR_feature_loss scaled:\t 116437.773\n","It 450\t Losses: total: 120866.289,\ttarget: 1.710 \tR_feature_loss scaled:\t 120864.562\n","It 475\t Losses: total: 108725.039,\ttarget: 1.672 \tR_feature_loss scaled:\t 108723.352\n","It 500\t Losses: total: 104657.516,\ttarget: 1.652 \tR_feature_loss scaled:\t 104655.852\n","Training classifier...\n","Test classifier\n","Loss: 9.493 | Acc: 38.782% (242/624), B. Acc: 50.940%\n","Generating images...\n","It 0\t Losses: total: 18295564.000,\ttarget: 2.371 \tR_feature_loss scaled:\t 18295562.000\n","It 25\t Losses: total: 225223.609,\ttarget: 1.884 \tR_feature_loss scaled:\t 225221.703\n","It 50\t Losses: total: 190985.234,\ttarget: 1.949 \tR_feature_loss scaled:\t 190983.266\n","It 75\t Losses: total: 158030.656,\ttarget: 1.916 \tR_feature_loss scaled:\t 158028.719\n","It 100\t Losses: total: 126403.258,\ttarget: 1.898 \tR_feature_loss scaled:\t 126401.344\n","It 125\t Losses: total: 144446.312,\ttarget: 1.891 \tR_feature_loss scaled:\t 144444.406\n","It 150\t Losses: total: 122332.961,\ttarget: 1.918 \tR_feature_loss scaled:\t 122331.023\n","It 175\t Losses: total: 119060.133,\ttarget: 1.943 \tR_feature_loss scaled:\t 119058.172\n","It 200\t Losses: total: 128717.516,\ttarget: 1.940 \tR_feature_loss scaled:\t 128715.562\n","It 225\t Losses: total: 125706.859,\ttarget: 1.960 \tR_feature_loss scaled:\t 125704.883\n","It 250\t Losses: total: 118265.500,\ttarget: 1.950 \tR_feature_loss scaled:\t 118263.531\n","It 275\t Losses: total: 109468.438,\ttarget: 1.925 \tR_feature_loss scaled:\t 109466.500\n","It 300\t Losses: total: 107273.188,\ttarget: 1.918 \tR_feature_loss scaled:\t 107271.258\n","It 325\t Losses: total: 112318.969,\ttarget: 1.904 \tR_feature_loss scaled:\t 112317.047\n","It 350\t Losses: total: 108702.578,\ttarget: 1.878 \tR_feature_loss scaled:\t 108700.688\n","It 375\t Losses: total: 104120.250,\ttarget: 1.877 \tR_feature_loss scaled:\t 104118.359\n","It 400\t Losses: total: 116887.461,\ttarget: 1.837 \tR_feature_loss scaled:\t 116885.609\n","It 425\t Losses: total: 118794.930,\ttarget: 1.825 \tR_feature_loss scaled:\t 118793.094\n","It 450\t Losses: total: 103015.000,\ttarget: 1.812 \tR_feature_loss scaled:\t 103013.172\n","It 475\t Losses: total: 105962.633,\ttarget: 1.810 \tR_feature_loss scaled:\t 105960.812\n","It 500\t Losses: total: 102005.797,\ttarget: 1.809 \tR_feature_loss scaled:\t 102003.977\n","Training classifier...\n","Test classifier\n","Loss: 11.091 | Acc: 38.782% (242/624), B. Acc: 50.940%\n","Generating images...\n","It 0\t Losses: total: 16735497.000,\ttarget: 2.246 \tR_feature_loss scaled:\t 16735495.000\n","It 25\t Losses: total: 234152.500,\ttarget: 1.883 \tR_feature_loss scaled:\t 234150.594\n","It 50\t Losses: total: 271294.656,\ttarget: 1.878 \tR_feature_loss scaled:\t 271292.750\n","It 75\t Losses: total: 145330.844,\ttarget: 1.856 \tR_feature_loss scaled:\t 145328.969\n","It 100\t Losses: total: 128452.812,\ttarget: 1.848 \tR_feature_loss scaled:\t 128450.945\n","It 125\t Losses: total: 136469.281,\ttarget: 1.851 \tR_feature_loss scaled:\t 136467.406\n","It 150\t Losses: total: 122576.938,\ttarget: 1.800 \tR_feature_loss scaled:\t 122575.125\n","It 175\t Losses: total: 120204.148,\ttarget: 1.838 \tR_feature_loss scaled:\t 120202.297\n","It 200\t Losses: total: 113796.625,\ttarget: 1.847 \tR_feature_loss scaled:\t 113794.766\n","It 225\t Losses: total: 115559.047,\ttarget: 1.829 \tR_feature_loss scaled:\t 115557.203\n","It 250\t Losses: total: 112489.414,\ttarget: 1.852 \tR_feature_loss scaled:\t 112487.547\n","It 275\t Losses: total: 122622.812,\ttarget: 1.810 \tR_feature_loss scaled:\t 122620.984\n","It 300\t Losses: total: 106397.727,\ttarget: 1.822 \tR_feature_loss scaled:\t 106395.891\n","It 325\t Losses: total: 108659.336,\ttarget: 1.782 \tR_feature_loss scaled:\t 108657.539\n","It 350\t Losses: total: 107264.969,\ttarget: 1.763 \tR_feature_loss scaled:\t 107263.188\n","It 375\t Losses: total: 113671.352,\ttarget: 1.719 \tR_feature_loss scaled:\t 113669.617\n","It 400\t Losses: total: 101227.852,\ttarget: 1.707 \tR_feature_loss scaled:\t 101226.133\n","It 425\t Losses: total: 103063.266,\ttarget: 1.650 \tR_feature_loss scaled:\t 103061.602\n","It 450\t Losses: total: 106291.945,\ttarget: 1.651 \tR_feature_loss scaled:\t 106290.281\n","It 475\t Losses: total: 102393.758,\ttarget: 1.572 \tR_feature_loss scaled:\t 102392.172\n","It 500\t Losses: total: 100860.523,\ttarget: 1.596 \tR_feature_loss scaled:\t 100858.914\n","Training classifier...\n","Test classifier\n","Loss: 10.614 | Acc: 38.942% (243/624), B. Acc: 50.726%\n","Generating images...\n","It 0\t Losses: total: 18886726.000,\ttarget: 2.215 \tR_feature_loss scaled:\t 18886724.000\n","It 25\t Losses: total: 232461.875,\ttarget: 1.886 \tR_feature_loss scaled:\t 232459.969\n","It 50\t Losses: total: 173164.391,\ttarget: 1.810 \tR_feature_loss scaled:\t 173162.562\n","It 75\t Losses: total: 172879.578,\ttarget: 1.809 \tR_feature_loss scaled:\t 172877.750\n","It 100\t Losses: total: 133172.500,\ttarget: 1.795 \tR_feature_loss scaled:\t 133170.688\n","It 125\t Losses: total: 130121.359,\ttarget: 1.808 \tR_feature_loss scaled:\t 130119.531\n","It 150\t Losses: total: 124744.367,\ttarget: 1.800 \tR_feature_loss scaled:\t 124742.547\n","It 175\t Losses: total: 118009.648,\ttarget: 1.807 \tR_feature_loss scaled:\t 118007.828\n","It 200\t Losses: total: 118774.359,\ttarget: 1.846 \tR_feature_loss scaled:\t 118772.500\n","It 225\t Losses: total: 139425.234,\ttarget: 1.854 \tR_feature_loss scaled:\t 139423.359\n","It 250\t Losses: total: 116094.945,\ttarget: 1.837 \tR_feature_loss scaled:\t 116093.094\n","It 275\t Losses: total: 111472.344,\ttarget: 1.855 \tR_feature_loss scaled:\t 111470.477\n","It 300\t Losses: total: 108523.914,\ttarget: 1.817 \tR_feature_loss scaled:\t 108522.078\n","It 325\t Losses: total: 110939.625,\ttarget: 1.770 \tR_feature_loss scaled:\t 110937.844\n","It 350\t Losses: total: 113110.852,\ttarget: 1.767 \tR_feature_loss scaled:\t 113109.070\n","It 375\t Losses: total: 116069.000,\ttarget: 1.808 \tR_feature_loss scaled:\t 116067.180\n","It 400\t Losses: total: 108702.297,\ttarget: 1.717 \tR_feature_loss scaled:\t 108700.562\n","It 425\t Losses: total: 106726.070,\ttarget: 1.777 \tR_feature_loss scaled:\t 106724.281\n","It 450\t Losses: total: 108670.641,\ttarget: 1.905 \tR_feature_loss scaled:\t 108668.719\n","It 475\t Losses: total: 98156.406,\ttarget: 1.824 \tR_feature_loss scaled:\t 98154.570\n","It 500\t Losses: total: 88848.961,\ttarget: 1.873 \tR_feature_loss scaled:\t 88847.070\n","Training classifier...\n","Test classifier\n","Loss: 6.866 | Acc: 39.423% (246/624), B. Acc: 51.026%\n","Generating images...\n","It 0\t Losses: total: 19225858.000,\ttarget: 2.315 \tR_feature_loss scaled:\t 19225856.000\n","It 25\t Losses: total: 228333.984,\ttarget: 1.929 \tR_feature_loss scaled:\t 228332.031\n","It 50\t Losses: total: 184455.141,\ttarget: 1.859 \tR_feature_loss scaled:\t 184453.266\n","It 75\t Losses: total: 163757.516,\ttarget: 1.858 \tR_feature_loss scaled:\t 163755.641\n","It 100\t Losses: total: 146582.234,\ttarget: 1.870 \tR_feature_loss scaled:\t 146580.344\n","It 125\t Losses: total: 139560.547,\ttarget: 1.876 \tR_feature_loss scaled:\t 139558.656\n","It 150\t Losses: total: 125702.695,\ttarget: 1.893 \tR_feature_loss scaled:\t 125700.789\n","It 175\t Losses: total: 129471.461,\ttarget: 1.894 \tR_feature_loss scaled:\t 129469.547\n","It 200\t Losses: total: 124710.352,\ttarget: 1.910 \tR_feature_loss scaled:\t 124708.422\n","It 225\t Losses: total: 122765.820,\ttarget: 1.897 \tR_feature_loss scaled:\t 122763.906\n","It 250\t Losses: total: 117003.258,\ttarget: 1.902 \tR_feature_loss scaled:\t 117001.344\n","It 275\t Losses: total: 114626.961,\ttarget: 1.870 \tR_feature_loss scaled:\t 114625.078\n","It 300\t Losses: total: 126513.453,\ttarget: 1.859 \tR_feature_loss scaled:\t 126511.578\n","It 325\t Losses: total: 109118.500,\ttarget: 1.835 \tR_feature_loss scaled:\t 109116.648\n","It 350\t Losses: total: 108147.914,\ttarget: 1.801 \tR_feature_loss scaled:\t 108146.102\n","It 375\t Losses: total: 121223.992,\ttarget: 1.798 \tR_feature_loss scaled:\t 121222.180\n","It 400\t Losses: total: 135865.359,\ttarget: 1.761 \tR_feature_loss scaled:\t 135863.578\n","It 425\t Losses: total: 108769.836,\ttarget: 1.777 \tR_feature_loss scaled:\t 108768.047\n","It 450\t Losses: total: 121044.500,\ttarget: 1.750 \tR_feature_loss scaled:\t 121042.734\n","It 475\t Losses: total: 110353.852,\ttarget: 1.722 \tR_feature_loss scaled:\t 110352.117\n","It 500\t Losses: total: 105208.734,\ttarget: 1.719 \tR_feature_loss scaled:\t 105207.000\n","Training classifier...\n","Test classifier\n","Loss: 9.949 | Acc: 39.423% (246/624), B. Acc: 51.111%\n","Generating images...\n","It 0\t Losses: total: 18589426.000,\ttarget: 2.321 \tR_feature_loss scaled:\t 18589424.000\n","It 25\t Losses: total: 206232.203,\ttarget: 1.834 \tR_feature_loss scaled:\t 206230.344\n","It 50\t Losses: total: 160543.000,\ttarget: 1.875 \tR_feature_loss scaled:\t 160541.109\n","It 75\t Losses: total: 138642.922,\ttarget: 1.874 \tR_feature_loss scaled:\t 138641.031\n","It 100\t Losses: total: 127321.938,\ttarget: 1.910 \tR_feature_loss scaled:\t 127320.008\n","It 125\t Losses: total: 123824.805,\ttarget: 1.914 \tR_feature_loss scaled:\t 123822.875\n","It 150\t Losses: total: 130191.117,\ttarget: 1.960 \tR_feature_loss scaled:\t 130189.141\n","It 175\t Losses: total: 114752.172,\ttarget: 1.957 \tR_feature_loss scaled:\t 114750.195\n","It 200\t Losses: total: 123098.109,\ttarget: 1.957 \tR_feature_loss scaled:\t 123096.133\n","It 225\t Losses: total: 116331.430,\ttarget: 1.973 \tR_feature_loss scaled:\t 116329.438\n","It 250\t Losses: total: 119856.078,\ttarget: 1.959 \tR_feature_loss scaled:\t 119854.102\n","It 275\t Losses: total: 115587.242,\ttarget: 1.957 \tR_feature_loss scaled:\t 115585.273\n","It 300\t Losses: total: 117044.164,\ttarget: 1.953 \tR_feature_loss scaled:\t 117042.195\n","It 325\t Losses: total: 109656.266,\ttarget: 1.989 \tR_feature_loss scaled:\t 109654.266\n","It 350\t Losses: total: 106830.102,\ttarget: 1.996 \tR_feature_loss scaled:\t 106828.094\n","It 375\t Losses: total: 105300.844,\ttarget: 1.986 \tR_feature_loss scaled:\t 105298.844\n","It 400\t Losses: total: 107625.758,\ttarget: 1.991 \tR_feature_loss scaled:\t 107623.750\n","It 425\t Losses: total: 105742.148,\ttarget: 1.972 \tR_feature_loss scaled:\t 105740.164\n","It 450\t Losses: total: 103032.039,\ttarget: 1.994 \tR_feature_loss scaled:\t 103030.031\n","It 475\t Losses: total: 103370.352,\ttarget: 1.939 \tR_feature_loss scaled:\t 103368.398\n","It 500\t Losses: total: 113793.461,\ttarget: 1.899 \tR_feature_loss scaled:\t 113791.547\n","Training classifier...\n","Test classifier\n","Loss: 8.057 | Acc: 39.744% (248/624), B. Acc: 51.282%\n","Generating images...\n","It 0\t Losses: total: 18092970.000,\ttarget: 2.210 \tR_feature_loss scaled:\t 18092968.000\n","It 25\t Losses: total: 234886.719,\ttarget: 1.881 \tR_feature_loss scaled:\t 234884.812\n","It 50\t Losses: total: 197163.453,\ttarget: 1.891 \tR_feature_loss scaled:\t 197161.547\n","It 75\t Losses: total: 136362.484,\ttarget: 1.883 \tR_feature_loss scaled:\t 136360.578\n","It 100\t Losses: total: 157529.156,\ttarget: 1.803 \tR_feature_loss scaled:\t 157527.344\n","It 125\t Losses: total: 161256.891,\ttarget: 1.823 \tR_feature_loss scaled:\t 161255.047\n","It 150\t Losses: total: 139911.266,\ttarget: 1.805 \tR_feature_loss scaled:\t 139909.438\n","It 175\t Losses: total: 121984.578,\ttarget: 1.793 \tR_feature_loss scaled:\t 121982.766\n","It 200\t Losses: total: 122230.375,\ttarget: 1.797 \tR_feature_loss scaled:\t 122228.562\n","It 225\t Losses: total: 118625.688,\ttarget: 1.779 \tR_feature_loss scaled:\t 118623.891\n","It 250\t Losses: total: 111946.688,\ttarget: 1.809 \tR_feature_loss scaled:\t 111944.859\n","It 275\t Losses: total: 112188.977,\ttarget: 1.814 \tR_feature_loss scaled:\t 112187.148\n","It 300\t Losses: total: 110119.484,\ttarget: 1.800 \tR_feature_loss scaled:\t 110117.672\n","It 325\t Losses: total: 108403.031,\ttarget: 1.800 \tR_feature_loss scaled:\t 108401.219\n","It 350\t Losses: total: 114009.461,\ttarget: 1.754 \tR_feature_loss scaled:\t 114007.688\n","It 375\t Losses: total: 105955.531,\ttarget: 1.758 \tR_feature_loss scaled:\t 105953.758\n","It 400\t Losses: total: 109991.133,\ttarget: 1.739 \tR_feature_loss scaled:\t 109989.375\n","It 425\t Losses: total: 103659.469,\ttarget: 1.731 \tR_feature_loss scaled:\t 103657.719\n","It 450\t Losses: total: 107173.844,\ttarget: 1.726 \tR_feature_loss scaled:\t 107172.102\n","It 475\t Losses: total: 104881.984,\ttarget: 1.719 \tR_feature_loss scaled:\t 104880.250\n","It 500\t Losses: total: 105359.812,\ttarget: 1.706 \tR_feature_loss scaled:\t 105358.094\n","Training classifier...\n","Test classifier\n","Loss: 9.869 | Acc: 39.263% (245/624), B. Acc: 50.983%\n","Generating images...\n","It 0\t Losses: total: 17941104.000,\ttarget: 2.291 \tR_feature_loss scaled:\t 17941102.000\n","It 25\t Losses: total: 227878.141,\ttarget: 1.932 \tR_feature_loss scaled:\t 227876.188\n","It 50\t Losses: total: 192103.344,\ttarget: 1.906 \tR_feature_loss scaled:\t 192101.422\n","It 75\t Losses: total: 151475.312,\ttarget: 1.879 \tR_feature_loss scaled:\t 151473.422\n","It 100\t Losses: total: 134703.344,\ttarget: 1.878 \tR_feature_loss scaled:\t 134701.453\n","It 125\t Losses: total: 142655.000,\ttarget: 1.890 \tR_feature_loss scaled:\t 142653.094\n","It 150\t Losses: total: 125141.852,\ttarget: 1.882 \tR_feature_loss scaled:\t 125139.953\n","It 175\t Losses: total: 119957.734,\ttarget: 1.877 \tR_feature_loss scaled:\t 119955.844\n","It 200\t Losses: total: 117554.617,\ttarget: 1.874 \tR_feature_loss scaled:\t 117552.727\n","It 225\t Losses: total: 118672.109,\ttarget: 1.864 \tR_feature_loss scaled:\t 118670.227\n","It 250\t Losses: total: 110614.852,\ttarget: 1.833 \tR_feature_loss scaled:\t 110613.000\n","It 275\t Losses: total: 113539.133,\ttarget: 1.842 \tR_feature_loss scaled:\t 113537.273\n","It 300\t Losses: total: 111037.320,\ttarget: 1.821 \tR_feature_loss scaled:\t 111035.484\n","It 325\t Losses: total: 107283.672,\ttarget: 1.795 \tR_feature_loss scaled:\t 107281.859\n","It 350\t Losses: total: 106902.883,\ttarget: 1.788 \tR_feature_loss scaled:\t 106901.078\n","It 375\t Losses: total: 118239.078,\ttarget: 1.753 \tR_feature_loss scaled:\t 118237.312\n","It 400\t Losses: total: 113538.188,\ttarget: 1.761 \tR_feature_loss scaled:\t 113536.414\n","It 425\t Losses: total: 112846.922,\ttarget: 1.746 \tR_feature_loss scaled:\t 112845.164\n","It 450\t Losses: total: 107303.133,\ttarget: 1.752 \tR_feature_loss scaled:\t 107301.367\n","It 475\t Losses: total: 100884.203,\ttarget: 1.701 \tR_feature_loss scaled:\t 100882.484\n","It 500\t Losses: total: 106763.820,\ttarget: 1.702 \tR_feature_loss scaled:\t 106762.102\n","Training classifier...\n","Test classifier\n","Loss: 10.236 | Acc: 38.942% (243/624), B. Acc: 50.812%\n","Generating images...\n","It 0\t Losses: total: 18394652.000,\ttarget: 2.247 \tR_feature_loss scaled:\t 18394650.000\n","It 25\t Losses: total: 229124.109,\ttarget: 1.912 \tR_feature_loss scaled:\t 229122.172\n","It 50\t Losses: total: 213161.031,\ttarget: 1.926 \tR_feature_loss scaled:\t 213159.094\n","It 75\t Losses: total: 146040.609,\ttarget: 1.883 \tR_feature_loss scaled:\t 146038.703\n","It 100\t Losses: total: 147700.359,\ttarget: 1.889 \tR_feature_loss scaled:\t 147698.453\n","It 125\t Losses: total: 120387.117,\ttarget: 1.914 \tR_feature_loss scaled:\t 120385.188\n","It 150\t Losses: total: 133274.031,\ttarget: 1.925 \tR_feature_loss scaled:\t 133272.094\n","It 175\t Losses: total: 117568.867,\ttarget: 1.945 \tR_feature_loss scaled:\t 117566.906\n","It 200\t Losses: total: 113692.312,\ttarget: 1.938 \tR_feature_loss scaled:\t 113690.359\n","It 225\t Losses: total: 111902.195,\ttarget: 1.939 \tR_feature_loss scaled:\t 111900.242\n","It 250\t Losses: total: 110132.617,\ttarget: 1.959 \tR_feature_loss scaled:\t 110130.641\n","It 275\t Losses: total: 107304.406,\ttarget: 1.927 \tR_feature_loss scaled:\t 107302.461\n","It 300\t Losses: total: 117720.781,\ttarget: 1.907 \tR_feature_loss scaled:\t 117718.859\n","It 325\t Losses: total: 117829.461,\ttarget: 1.934 \tR_feature_loss scaled:\t 117827.508\n","It 350\t Losses: total: 106239.531,\ttarget: 1.924 \tR_feature_loss scaled:\t 106237.594\n","It 375\t Losses: total: 110670.195,\ttarget: 1.912 \tR_feature_loss scaled:\t 110668.266\n","It 400\t Losses: total: 106841.141,\ttarget: 1.911 \tR_feature_loss scaled:\t 106839.211\n","It 425\t Losses: total: 105818.031,\ttarget: 1.884 \tR_feature_loss scaled:\t 105816.133\n","It 450\t Losses: total: 106531.703,\ttarget: 1.881 \tR_feature_loss scaled:\t 106529.805\n","It 475\t Losses: total: 102901.609,\ttarget: 1.916 \tR_feature_loss scaled:\t 102899.680\n","It 500\t Losses: total: 105206.359,\ttarget: 1.976 \tR_feature_loss scaled:\t 105204.367\n","Training classifier...\n","Test classifier\n","Loss: 10.671 | Acc: 38.782% (242/624), B. Acc: 50.598%\n","Test ensemble...\n","Loss: 0.435 | Acc: 87.340% (545/624), B. Acc: 83.803%\n","Test classifier\n","Loss: 10.641 | Acc: 38.782% (242/624), B. Acc: 50.598%\n"]}]},{"cell_type":"markdown","metadata":{"id":"7MxeaDa2pqtW"},"source":["## Demo platform"]},{"cell_type":"markdown","metadata":{"id":"GC6eQ3Gep-0N"},"source":["Here, we define some functions to help combine the parts of our platform into a rough UI. Improvements coming in the future!"]},{"cell_type":"markdown","metadata":{"id":"Anb4_iB0SMGK"},"source":["1. `train_resnet50_finetune` finetunes an existing model (transfer learning)\n","2. `federated_learn_model` does model federation\n","3. `train_mnist_model` does local model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ju8KIU0vhiyy"},"outputs":[],"source":["ABS_PATH_TO_DIR = \"/content/drive/MyDrive/OneFL/src\"\n","MEDMNIST_ROOT = ABS_PATH_TO_DIR\n","os.makedirs(MEDMNIST_ROOT, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqX3OGfv7XqH"},"outputs":[],"source":["def train_mnist_model(dataset_name):\n","    \"\"\"\n","    Train a model for a specified MedMNIST dataset.\n","\n","    Parameters:\n","        dataset_name (str): The name of the dataset (e.g., 'breast', 'blood', 'path').\n","    \"\"\"\n","    # Append 'mnist' to dataset_name for MedMNIST compatibility\n","    data_flag = dataset_name.lower() + 'mnist'\n","\n","    # Define paths to data and models\n","    data_dir = f\"{ABS_PATH_TO_DIR}/{dataset_name}_models\"\n","\n","    # Data flag and info setup\n","    info = medmnist.INFO[data_flag].copy()\n","    task = info['task']\n","    n_channels = info['n_channels']\n","    n_classes = len(info['label'])\n","\n","    DataClass = getattr(medmnist, info['python_class'])\n","\n","    # Set up client_0 for training\n","    root_client_0 = os.path.join(data_dir, \"client_0\")\n","    model_path_client_0 = os.path.join(root_client_0, \"best.pth\")\n","\n","    # Initialize the model for client_0\n","    model_client_0 = ResNet18(in_channels=n_channels, num_classes=n_classes)\n","\n","    # Attempt to load pre-trained weights, handle mismatched keys\n","    if os.path.exists(model_path_client_0):\n","        try:\n","            print(f\"Loading weights from {model_path_client_0}...\")\n","            state_dict = torch.load(model_path_client_0, map_location=torch.device('cpu'))\n","            model_client_0.load_state_dict(state_dict, strict=False)  # Allow partial weight loading\n","            print(\"Weights loaded successfully with non-strict matching.\")\n","        except RuntimeError as e:\n","            print(f\"Warning: Error loading state_dict. Mismatch detected.\\n{e}\")\n","            print(\"Continuing training with randomly initialized weights.\")\n","    else:\n","        print(\"No pre-trained weights found. Training will start from scratch.\")\n","\n","    # Set up training data for client_0 (use only client_0's data)\n","    train_dataset_client_0 = DataClass(root=root_client_0, split='train', download=True)\n","\n","    # Set up augmentation and preprocessing\n","    aug_list = [\n","        transforms.RandomCrop(28, padding=4),\n","        transforms.RandomHorizontalFlip()\n","    ]\n","    preprocess_list = [transforms.ToTensor(), transforms.Normalize(mean=[.5], std=[.5])]\n","\n","    # Initialize LocalTrainer for client_0\n","    loc_trainer_client_0 = LocalTrainer(\n","        model=model_client_0,\n","        dataset=DataClass,\n","        dir_save_model_weights=root_client_0,\n","        num_classes=n_classes,\n","        root=root_client_0,\n","        epochs=20,\n","        lr_adj=[10, 15],\n","        aug=aug_list,\n","        preprocess=preprocess_list,\n","        seed=0\n","    )\n","\n","    # Train client_0\n","    loc_trainer_client_0.train()\n","    return model_client_0  # Return trained model\n","\n","# Example usage\n","# train_mnist_model('breast')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qss5z9qJPY1S"},"outputs":[],"source":["def train_resnet50_finetune(dataset_name):\n","    \"\"\"\n","    Transfer learn and fine-tune a ResNet50 model for a specified MedMNIST dataset.\n","    \"\"\"\n","    # Append 'mnist' to dataset_name for MedMNIST compatibility\n","    data_flag = dataset_name.lower() + 'mnist'\n","    data_dir = f\"{ABS_PATH_TO_DIR}/{dataset_name}_models\"\n","\n","    # Data flag setup\n","    info = medmnist.INFO[data_flag].copy()\n","    task = info['task']\n","    n_channels = info['n_channels']\n","    n_classes = len(info['label'])\n","    DataClass = getattr(medmnist, info['python_class'])\n","\n","    root_client_0 = os.path.join(data_dir, \"client_0\")\n","    model_path_client_0 = os.path.join(root_client_0, \"best_resnet50.pth\")\n","\n","    # Load pre-trained ResNet50 and modify layers\n","    model = models.resnet50(pretrained=True)\n","    if n_channels != 3:\n","        model.conv1 = nn.Conv2d(n_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","    model.fc = nn.Linear(model.fc.in_features, n_classes)\n","\n","    # Attempt to load existing weights\n","    if os.path.exists(model_path_client_0):\n","        model.load_state_dict(torch.load(model_path_client_0, map_location=torch.device('cpu')))\n","\n","    # Prepare data\n","    train_dataset = DataClass(root=root_client_0, split='train', download=True)\n","    aug_list = [transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip()]\n","    preprocess_list = [transforms.ToTensor(), transforms.Normalize(mean=[.5] * n_channels, std=[.5] * n_channels)]\n","\n","    # Trainer\n","    trainer = LocalTrainer(\n","        model=model,\n","        dataset=DataClass,\n","        dir_save_model_weights=root_client_0,\n","        num_classes=n_classes,\n","        root=root_client_0,\n","        epochs=20,\n","        lr_adj=[10, 15],\n","        aug=aug_list,\n","        preprocess=preprocess_list,\n","        seed=0\n","    )\n","\n","    trainer.train()\n","    return model  # Return the trained model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a28UES76Znmy"},"outputs":[],"source":["# set up directory for medmnist data\n","def download_medmnist_dataset(dataset_name):\n","    \"\"\"\n","    Ensure the MedMNIST dataset is downloaded and available.\n","    \"\"\"\n","    dataset_name += 'mnist'\n","    print(f\"Checking availability of {dataset_name} dataset...\")\n","    DataClass = getattr(medmnist, INFO[dataset_name][\"python_class\"])\n","    DataClass(root=MEDMNIST_ROOT, split='train', download=True)\n","    DataClass(root=MEDMNIST_ROOT, split='val', download=True)\n","    DataClass(root=MEDMNIST_ROOT, split='test', download=True)\n","    print(f\"{dataset_name} dataset is ready!\\n\")\n","\n","def federated_learn_model(model_type):\n","    \"\"\"\n","    Perform federated learning for the specified MedMNIST dataset.\n","\n","    Parameters:\n","        model_type (str): Type of the model to use for federated learning (e.g., \"breast\", \"chest\").\n","\n","    Returns:\n","        federated_model: The federated learning model after training.\n","    \"\"\"\n","    print(f\"Running federated learning for model: {model_type}\")\n","\n","    # Setup directories\n","    #model_type = model_type.replace('mnist', '')\n","    model_weights_dir = os.path.join(ABS_PATH_TO_DIR, f\"{model_type}_models\")\n","    exper_dir = os.path.join(MEDMNIST_ROOT, f\"{model_type}_expr/federated\")\n","    os.makedirs(model_weights_dir, exist_ok=True)\n","    os.makedirs(exper_dir, exist_ok=True)\n","\n","    # Ensure the dataset is downloaded\n","    download_medmnist_dataset(f\"{model_type}\")\n","\n","    # Load dataset-specific parameters\n","    info = INFO[f\"{model_type}mnist\"]\n","    input_channels = info['n_channels']\n","    num_classes = len(info['label'])\n","    input_size = 28\n","   #FedBreast = fedisca.FedISCA(test_data_dir=\"./\", model_weights_dir=\"./breast_models\", exper_dir=\"./breast_exper/federated\", input_size=28, in_channels=1, num_classes=2, batch_size=30, epochs=25, iter_mi=500, lr_steps=[15, 20], log_freq=25, is_medmnist=True, medmnist=\"breastmnist\")\n","\n","    # Define FedISCA model\n","    FedModel = fedisca.FedISCA(\n","        test_data_dir=MEDMNIST_ROOT,\n","        model_weights_dir=model_weights_dir,\n","        exper_dir=exper_dir,\n","        input_size=input_size,\n","        in_channels=input_channels,\n","        num_classes=num_classes,\n","        batch_size=30,\n","        epochs=25,\n","        iter_mi=500,\n","        lr_steps=[15, 20],\n","        log_freq=25,\n","        is_medmnist=True,\n","        medmnist=f\"{model_type}mnist\"\n","    )\n","    ens_local = FedModel.load_models()\n","\n","\n","    # Perform federated learning\n","    print(\"Performing federated learning...\")\n","    fed_model, noise_adapt = FedModel.model_inversion(ens_local, large_jtr=5, small_jtr=1)\n","    print(f\"Federated learning completed for {model_type}!\")\n","\n","    # Save the federated model\n","    save_model(fed_model, f\"{model_type}_federated_learning\", save_dir=exper_dir)\n","    print(f\"Federated model saved in {exper_dir}\")\n","    return fed_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpaGm120OPhI"},"outputs":[],"source":["def save_model(model, model_name, save_dir=\"./saved_models\"):\n","    os.makedirs(save_dir, exist_ok=True)\n","    save_path = os.path.join(save_dir, f\"{model_name}.pth\")\n","    torch.save(model.state_dict(), save_path)\n","    print(f\"Model saved as {save_path}\\n\")\n","\n","def process_cli_query():\n","    print(\"Medical Image Model Selector (CLI Version)\")\n","    print(\"Enter 'exit' to stop the program.\\n\")\n","\n","    while True:\n","        query = input(\"Enter your medical query: \")\n","        if query.lower() == \"exit\":\n","            print(\"Exiting program...\")\n","            break\n","\n","        # Extract labels with the new return values\n","        detected_image_type, detected_disease, dataset_match, image_alts, disease_alts = sems.extract_labels_dynamic(query)\n","        #dataset_match = dataset_match.replace(\"mnist\", \"\")  # Remove 'mnist' suffix\n","        if detected_image_type and detected_disease and dataset_match:\n","            print(f\"\\nDetected Image Type: {detected_image_type}\")\n","            print(f\"Detected Disease: {detected_disease}\")\n","            print(f\"Detected Model: {dataset_match}\")\n","            confirm = input(\"Are the Image Type and Disease correct? (yes/no): \").strip().lower()\n","\n","            if confirm == \"yes\":\n","                print(\"Do you want to perform Transfer Learning (T), Federated Learning (F), or Train a Local Model (L)?\")\n","                choice = input(\"Enter 'T', 'F', or 'L': \").strip().upper()\n","                dataset_match = dataset_match.replace(\"mnist\", \"\")\n","                download_medmnist_dataset(dataset_match)  # Ensure dataset is downloaded\n","                print('dataset match ', dataset_match)\n","                if choice == 'T':\n","                    print(\"Training in Transfer Learning mode...\")\n","                    model = train_resnet50_finetune(dataset_match)\n","                    save_model(model, f\"{dataset_match}_transfer_learning\")\n","                    print(f\"Transfer Learning complete for {dataset_match}!\")\n","                elif choice == 'F':\n","                    print(\"Starting Federated Learning...\")\n","                    model = federated_learn_model(dataset_match)\n","                    save_model(model, f\"{dataset_match}_federated_learning\")\n","                    print(f\"Federated Learning complete for {dataset_match}!\")\n","                elif choice == 'L':\n","                    print(\"Training Local Model...\")\n","                    model = train_mnist_model(dataset_match)\n","                    save_model(model, f\"{dataset_match}_local_model\")\n","                    print(f\"Local Model training complete for {dataset_match}!\")\n","                else:\n","                    print(\"Invalid choice. Please select 'T', 'F', or 'L'.\\n\")\n","            else:\n","                print(\"Please refine your query and try again.\\n\")\n","        else:\n","            print(\"Unable to detect an exact match. Here are the top suggestions:\")\n","            print(\"Image Type Suggestions:\")\n","            for alt, score in image_alts:\n","                print(f\"- {alt} (Similarity: {score:.2f})\")\n","            print(\"Disease Suggestions:\")\n","            for alt, score in disease_alts:\n","                print(f\"- {alt} (Similarity: {score:.2f})\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LFiV_VbH68EF"},"source":["Use this cell to run the UI! Note that, in expectation, the federated learning process takes ~4 hours to train 30 epochs. Transfer learning and local model training should take just a couple of minutes. If you do not want to train the federated model yourself, we provide a binary for this in the GitHub release code."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":964},"executionInfo":{"elapsed":31236,"status":"error","timestamp":1734501215192,"user":{"displayName":"Caleb Chin","userId":"06217181483891520714"},"user_tz":300},"id":"A4fSd_mz67S4","outputId":"1c23969b-950a-4558-b598-028b373e8e67"},"outputs":[{"name":"stdout","output_type":"stream","text":["Medical Image Model Selector (CLI Version)\n","Enter 'exit' to stop the program.\n","\n","Enter your medical query: pneumonis\n","Unable to detect an exact match. Here are the top suggestions:\n","Image Type Suggestions:\n","- fundus camera (Similarity: 0.27)\n","- retinal oct (Similarity: 0.21)\n","- chest x-ray (Similarity: 0.21)\n","Disease Suggestions:\n","Enter your medical query: pneumonia\n","\n","Detected Image Type: chest x-ray\n","Detected Disease: pneumonia\n","Detected Model: pneumoniamnist\n","Are the Image Type and Disease correct? (yes/no): yes\n","Do you want to perform Transfer Learning (T), Federated Learning (F), or Train a Local Model (L)?\n","Enter 'T', 'F', or 'L': F\n","Checking availability of pneumoniamnist dataset...\n","Using downloaded and verified file: /content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/pneumoniamnist.npz\n","Using downloaded and verified file: /content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/pneumoniamnist.npz\n","Using downloaded and verified file: /content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/pneumoniamnist.npz\n","pneumoniamnist dataset is ready!\n","\n","dataset match  pneumonia\n","Starting Federated Learning...\n","Running federated learning for model: pneumonia\n","Checking availability of pneumoniamnist dataset...\n","Using downloaded and verified file: /content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/pneumoniamnist.npz\n","Using downloaded and verified file: /content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/pneumoniamnist.npz\n","Using downloaded and verified file: /content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/pneumoniamnist.npz\n","pneumoniamnist dataset is ready!\n","\n","Performing federated learning...\n","Generating images...\n","It 0\t Losses: total: 376317.000,\ttarget: 1.419 \tR_feature_loss scaled:\t 376315.562\n","It 25\t Losses: total: 68755.836,\ttarget: 2.634 \tR_feature_loss scaled:\t 68753.188\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-c1ed62e880fe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run CLI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprocess_cli_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-ddb014cffec4>\u001b[0m in \u001b[0;36mprocess_cli_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Federated Learning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_learn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{dataset_match}_federated_learning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Federated Learning complete for {dataset_match}!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-7065e133ae4f>\u001b[0m in \u001b[0;36mfederated_learn_model\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# Perform federated learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing federated learning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mfed_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_adapt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_inversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mens_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge_jtr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_jtr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Federated learning completed for {model_type}!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/CAP_The-Federation_asj53_ctc92-main/src/fedisca.py\u001b[0m in \u001b[0;36mmodel_inversion\u001b[0;34m(self, models, base_model, large_jtr, small_jtr)\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mbest_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m           \u001b[0mbest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Run CLI\n","if __name__ == \"__main__\":\n","    process_cli_query()"]},{"cell_type":"markdown","metadata":{"id":"ZQ-zRdbD0LAY"},"source":["### Evaluating performance of models"]},{"cell_type":"markdown","metadata":{"id":"SJjzR5Ht8CK_"},"source":["To evaluate the performance of your models, you can use the function below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXqrRn1p5EJq"},"outputs":[],"source":["def eval_model(model, data_class, root, criterion, fed_obj):\n","  test_transforms = transforms.Compose([\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=[.5], std=[.5])\n","  ])\n","  test_data = data_class(split='test', root=root, transform=test_transforms, download=False)\n","  test_loader = DataLoader(dataset=test_data, batch_size=128, shuffle=False, num_workers=0)\n","\n","  fed_obj.test_model(model, test_loader, criterion)\n"]},{"cell_type":"markdown","metadata":{"id":"ajALgUZN-BXP"},"source":["Here are some examples:"]},{"cell_type":"markdown","metadata":{"id":"bBfntjxJqvHd"},"source":["Let's say that we have a federated model at the path `saved_models/fed_best.pth`. Note that this path will vary depending on how you set up your files/where you train your classifier."]},{"cell_type":"markdown","metadata":{"id":"Esenp3srzKbn"},"source":["We need a FedISCA object to do this"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1734501627442,"user":{"displayName":"Caleb Chin","userId":"06217181483891520714"},"user_tz":300},"id":"rSeDBlAc-CYu","outputId":"8afc8ce4-a387-4c1a-a9e5-76986b674e3a"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-38-0d45386be276>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  fed_model = torch.load(\"saved_models/fed_best.pth\")\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 0.473 | Acc: 83.333% (520/624), B. Acc: 78.291%\n"]}],"source":["fed_model = torch.load(\"saved_models/fed_best.pth\")\n","FedPneu = fedisca.FedISCA(test_data_dir=\"./\", model_weights_dir=\"./pneumonia_models_dirich\", exper_dir=\"./pneumonia_exper_dirich/federated\", input_size=28, in_channels=1, num_classes=2, batch_size=128, epochs=25, iter_mi=500, lr_steps=[16, 20], log_freq=100, is_medmnist=True, medmnist=\"pneumoniamnist\")\n","eval_model(fed_model, DataClass, glb_test_dataset.root, nn.CrossEntropyLoss(), FedPneu)"]},{"cell_type":"markdown","metadata":{"id":"oCYv7sfE01ay"},"source":["We can also test the accuracy of the local client models. Suppose, as before, they are stored in `pneumonia_models`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":702,"status":"ok","timestamp":1734501636277,"user":{"displayName":"Caleb Chin","userId":"06217181483891520714"},"user_tz":300},"id":"48OuBjYf0w3r","outputId":"40b64cc0-cc22-483b-a182-cc679ce47299"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-39-0a9b0e5e0943>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  client_weights = torch.load(\"./pneumonia_models/client_2/best.pth\")\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 1.383 | Acc: 67.308% (420/624), B. Acc: 72.821%\n"]}],"source":["client_weights = torch.load(\"./pneumonia_models/client_2/best.pth\")\n","client_model = ResNet18(in_channels=1, num_classes=2)\n","client_model.load_state_dict(client_weights)\n","client_model.to('cuda')\n","eval_model(client_model, DataClass, glb_test_dataset.root, nn.CrossEntropyLoss(), FedPneu)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1k1XelL5_CfM_nFGpYcMffpPPo0gcS95j","timestamp":1734451622569},{"file_id":"1NRyElMqrgHBl4CvUOeiD2L8F9KmdCckQ","timestamp":1734451610454}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e72e59ff077542bf955f4ef09e8d985b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6710fa6bb764f348174162fa58ef85f","IPY_MODEL_30b9a721f7834e4d9ce2637158f8c22b","IPY_MODEL_0601eb475f474d819122d2aab6033ab5"],"layout":"IPY_MODEL_ad7fbf5cb5644aa994049d1c26c038f7"}},"f6710fa6bb764f348174162fa58ef85f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17e5efb1fb644d79a3c8bbef4ab5e713","placeholder":"​","style":"IPY_MODEL_3b02e7fb0fde43d39e195c80174cd302","value":"modules.json: 100%"}},"30b9a721f7834e4d9ce2637158f8c22b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b81c0edfd424ebf86ce57f5181a35ef","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e2d242258b74cd385eb1c1fb9fcba87","value":349}},"0601eb475f474d819122d2aab6033ab5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afc155a39d6140fdb044faca5163cc2a","placeholder":"​","style":"IPY_MODEL_062116cbb0bd44e79215ee61ff7e2862","value":" 349/349 [00:00&lt;00:00, 19.6kB/s]"}},"ad7fbf5cb5644aa994049d1c26c038f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17e5efb1fb644d79a3c8bbef4ab5e713":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b02e7fb0fde43d39e195c80174cd302":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b81c0edfd424ebf86ce57f5181a35ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e2d242258b74cd385eb1c1fb9fcba87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"afc155a39d6140fdb044faca5163cc2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"062116cbb0bd44e79215ee61ff7e2862":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03d51b68fd2f4b3bb671f1348670972c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c3ba1f4a108478eb6c47fc03f298245","IPY_MODEL_b7af2c03679443ffa731f672e85b91b6","IPY_MODEL_1ba96aad754d45c382fa6bedb2b9666d"],"layout":"IPY_MODEL_b4e3eea48f8045fbb1010a67b65baf48"}},"6c3ba1f4a108478eb6c47fc03f298245":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53b9825d721b4dd697836864c3b462a3","placeholder":"​","style":"IPY_MODEL_60a6aacd70224b05ba8bd7b8c44398c7","value":"config_sentence_transformers.json: 100%"}},"b7af2c03679443ffa731f672e85b91b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b4f9d602e2b44d787274710a36e483e","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_078b35207bf64d659bead32e92e4c17b","value":116}},"1ba96aad754d45c382fa6bedb2b9666d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8075bc29f4c494d98d9d44bfd74d079","placeholder":"​","style":"IPY_MODEL_31c0855f4cee47099003cb8ff4689cb0","value":" 116/116 [00:00&lt;00:00, 8.09kB/s]"}},"b4e3eea48f8045fbb1010a67b65baf48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53b9825d721b4dd697836864c3b462a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60a6aacd70224b05ba8bd7b8c44398c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b4f9d602e2b44d787274710a36e483e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"078b35207bf64d659bead32e92e4c17b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8075bc29f4c494d98d9d44bfd74d079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c0855f4cee47099003cb8ff4689cb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"606ef9e9d5d148d5b7980b02d0bcd4ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4525c4eed344707a222ebda07370ff2","IPY_MODEL_29d442e983e14f1e898dcf51b69038cc","IPY_MODEL_88bf7d7dd6394ba692d5bf60bc8529bf"],"layout":"IPY_MODEL_0c12eb341aa84a9287ffc455ac9cdcfb"}},"c4525c4eed344707a222ebda07370ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d79f846683cf48da9e22ddba3b53391a","placeholder":"​","style":"IPY_MODEL_8340ef952bb64b778c551b90b1c96614","value":"README.md: 100%"}},"29d442e983e14f1e898dcf51b69038cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4864a55a0f6430d8c7035dc65fae9a6","max":10659,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4aa22beaa5d6450fbfb0e8ef2483eab6","value":10659}},"88bf7d7dd6394ba692d5bf60bc8529bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_199e6b169769479681358cdff06d48a1","placeholder":"​","style":"IPY_MODEL_4d42bb94e93445939dec5900c54b6d9e","value":" 10.7k/10.7k [00:00&lt;00:00, 774kB/s]"}},"0c12eb341aa84a9287ffc455ac9cdcfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79f846683cf48da9e22ddba3b53391a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8340ef952bb64b778c551b90b1c96614":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4864a55a0f6430d8c7035dc65fae9a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa22beaa5d6450fbfb0e8ef2483eab6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"199e6b169769479681358cdff06d48a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d42bb94e93445939dec5900c54b6d9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcbadc9f22e449b1a946838d63da3180":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac847d75070a4c46a439ca5a097159bd","IPY_MODEL_08ff039e051b4b5da4b4e11d0b1305c7","IPY_MODEL_1db710a5ef1c47dd8c347054066fa207"],"layout":"IPY_MODEL_676b8b46c474407db6657fb4bbdb19fb"}},"ac847d75070a4c46a439ca5a097159bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffe708e312a84c3b923b79842591d727","placeholder":"​","style":"IPY_MODEL_2427897913f64b3b973eed0a784f57d6","value":"sentence_bert_config.json: 100%"}},"08ff039e051b4b5da4b4e11d0b1305c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67f011da12af4f2b80691595d4f346a4","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ddde210d04c0419b8c08349341033d44","value":53}},"1db710a5ef1c47dd8c347054066fa207":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf8ddbdaa6c84957bc91b767393ec023","placeholder":"​","style":"IPY_MODEL_694fe6b28aea4e38929ff388ac38c41d","value":" 53.0/53.0 [00:00&lt;00:00, 4.46kB/s]"}},"676b8b46c474407db6657fb4bbdb19fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffe708e312a84c3b923b79842591d727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2427897913f64b3b973eed0a784f57d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67f011da12af4f2b80691595d4f346a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddde210d04c0419b8c08349341033d44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf8ddbdaa6c84957bc91b767393ec023":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"694fe6b28aea4e38929ff388ac38c41d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64217dce8278444c8f46a0b034f6af7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f716c47129a043e7b0bb9ace4a5425dd","IPY_MODEL_279acabcc20240c4a3cf3975d9162f3c","IPY_MODEL_7a8f21d0be194ada9d757e13ab4cfeda"],"layout":"IPY_MODEL_5bd67a4956d54f809ecdd9a306f75423"}},"f716c47129a043e7b0bb9ace4a5425dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ad5946850b14549b88099aee912ab26","placeholder":"​","style":"IPY_MODEL_c518ed70cb5f4203a61987c27c40684a","value":"config.json: 100%"}},"279acabcc20240c4a3cf3975d9162f3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9494b76728f4f84b51aa89d8010f0b4","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a28fd9f8d784d23bdbd59ba1411ef63","value":612}},"7a8f21d0be194ada9d757e13ab4cfeda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b860f645ea2541d8ba2cfbddb23a9062","placeholder":"​","style":"IPY_MODEL_605fb77b34c14a74ad61e52235831bd9","value":" 612/612 [00:00&lt;00:00, 30.7kB/s]"}},"5bd67a4956d54f809ecdd9a306f75423":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad5946850b14549b88099aee912ab26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c518ed70cb5f4203a61987c27c40684a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9494b76728f4f84b51aa89d8010f0b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a28fd9f8d784d23bdbd59ba1411ef63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b860f645ea2541d8ba2cfbddb23a9062":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"605fb77b34c14a74ad61e52235831bd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2b2ef83443440f8970a90339e726c1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a302f88bcf06400eb65fc81c3d8bb3bd","IPY_MODEL_06124c6a1a3341e4bdf894b25f158f98","IPY_MODEL_0c36d1c7cf16414f866df2faace62b68"],"layout":"IPY_MODEL_84c80a3bd7284cb8b53a6b35a2c68aaf"}},"a302f88bcf06400eb65fc81c3d8bb3bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3bb95adb9a144f0965ef60b5cf4c585","placeholder":"​","style":"IPY_MODEL_44e3fc4bca384e46820fca8e375623fb","value":"model.safetensors: 100%"}},"06124c6a1a3341e4bdf894b25f158f98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d34b797bb3504521b94e6cc4175ba6c8","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a35bfe9f1fdb4b0fb0e0143d12e38177","value":90868376}},"0c36d1c7cf16414f866df2faace62b68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63d2e3a8e98c45349d88820fbf91b590","placeholder":"​","style":"IPY_MODEL_403caa4f5e16444182422e58808b10ab","value":" 90.9M/90.9M [00:00&lt;00:00, 197MB/s]"}},"84c80a3bd7284cb8b53a6b35a2c68aaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3bb95adb9a144f0965ef60b5cf4c585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44e3fc4bca384e46820fca8e375623fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d34b797bb3504521b94e6cc4175ba6c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35bfe9f1fdb4b0fb0e0143d12e38177":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63d2e3a8e98c45349d88820fbf91b590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"403caa4f5e16444182422e58808b10ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"667760e316e648fa8797c2a8dc90f0a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35766f471d0f423bad81e7f9c09f47ab","IPY_MODEL_a32bba96239a4296b1d560be00396c00","IPY_MODEL_7b6e5bdab3e541d29b754b703e8ad4ab"],"layout":"IPY_MODEL_4505de68ab704fe7becbac2e96589e94"}},"35766f471d0f423bad81e7f9c09f47ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_497e662249e1470c993c7a503c735fc8","placeholder":"​","style":"IPY_MODEL_e1629ee018b044a8abb24dd876df0700","value":"tokenizer_config.json: 100%"}},"a32bba96239a4296b1d560be00396c00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4260183325e4714aee5787570d0ae1d","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e86bd969cae411b879048116ccb043b","value":350}},"7b6e5bdab3e541d29b754b703e8ad4ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1cdaf5443394988ac481e00e46007e0","placeholder":"​","style":"IPY_MODEL_1c3e0ea5e2c746ccaee0b535449deeef","value":" 350/350 [00:00&lt;00:00, 23.5kB/s]"}},"4505de68ab704fe7becbac2e96589e94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497e662249e1470c993c7a503c735fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1629ee018b044a8abb24dd876df0700":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4260183325e4714aee5787570d0ae1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e86bd969cae411b879048116ccb043b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1cdaf5443394988ac481e00e46007e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c3e0ea5e2c746ccaee0b535449deeef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faf17580bb8a4516986835e0e08c3537":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6800912879ba49238a501fcb48264546","IPY_MODEL_afd1223b66404cf4acf652e67a70123e","IPY_MODEL_310860f143f3412d8f77ab7fedd36099"],"layout":"IPY_MODEL_8abf0042e2164af6911004b67fbf5fab"}},"6800912879ba49238a501fcb48264546":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1deeccb91ec744569db28f0bd621e426","placeholder":"​","style":"IPY_MODEL_3554febdc74348b4b256fdb536037a81","value":"vocab.txt: 100%"}},"afd1223b66404cf4acf652e67a70123e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02e28d7f9d8542f4bd8a85334ef49bca","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f5e1958a42e42f4a6d05cd8dc0316d9","value":231508}},"310860f143f3412d8f77ab7fedd36099":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8999697fd70f4c13a47b721b6f9b6164","placeholder":"​","style":"IPY_MODEL_ee3071c6f59d4b3aafa99e70845d4489","value":" 232k/232k [00:00&lt;00:00, 3.50MB/s]"}},"8abf0042e2164af6911004b67fbf5fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1deeccb91ec744569db28f0bd621e426":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3554febdc74348b4b256fdb536037a81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02e28d7f9d8542f4bd8a85334ef49bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f5e1958a42e42f4a6d05cd8dc0316d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8999697fd70f4c13a47b721b6f9b6164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee3071c6f59d4b3aafa99e70845d4489":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e899a4951c9d4a7fb967d141c0dcbede":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f16f2cfd45c414886dc68a4e9b5cf34","IPY_MODEL_52cf5c7002664fe580dcd6f7a9e2bf62","IPY_MODEL_0f421cc2e6124c38b6aac9d7c21a9647"],"layout":"IPY_MODEL_60f76ea852e64b1db4a74e9d433a61b6"}},"3f16f2cfd45c414886dc68a4e9b5cf34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_caf50034fb144fc4b1f8cd4ec92e7c4f","placeholder":"​","style":"IPY_MODEL_da4f18f408bc4f2698d929ade84358ff","value":"tokenizer.json: 100%"}},"52cf5c7002664fe580dcd6f7a9e2bf62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a61104836a1d4573aae72ee8f2fd2a9c","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80ebf767d72646ffb00c62c663740642","value":466247}},"0f421cc2e6124c38b6aac9d7c21a9647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc6b98cda2b94710810aad1e5c11514a","placeholder":"​","style":"IPY_MODEL_a77a05513da4483a8e7229623bbe0f59","value":" 466k/466k [00:00&lt;00:00, 6.79MB/s]"}},"60f76ea852e64b1db4a74e9d433a61b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caf50034fb144fc4b1f8cd4ec92e7c4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da4f18f408bc4f2698d929ade84358ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a61104836a1d4573aae72ee8f2fd2a9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ebf767d72646ffb00c62c663740642":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc6b98cda2b94710810aad1e5c11514a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a77a05513da4483a8e7229623bbe0f59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"865ee26bccea4487a08fb6ed3b0b8288":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0004b56803a24a27bdb28dfa33b92f90","IPY_MODEL_2715fefd1222474e87401e35e316b38b","IPY_MODEL_28de121298b34888b5dfa5409481929c"],"layout":"IPY_MODEL_f2f1567b1a924fdfa9294d3ba0d16bda"}},"0004b56803a24a27bdb28dfa33b92f90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1ffee9773e2419eb477c7d805c37c67","placeholder":"​","style":"IPY_MODEL_096754f92a0943bc9b5d8c05d2fa377e","value":"special_tokens_map.json: 100%"}},"2715fefd1222474e87401e35e316b38b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73cbbb23fbf4465795a5b101541f81ba","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_040d6417172e44dd8d3b653235564239","value":112}},"28de121298b34888b5dfa5409481929c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d87904121248f998134ba9c164b36a","placeholder":"​","style":"IPY_MODEL_3eff7536f8ad4134bdb795268b8146f6","value":" 112/112 [00:00&lt;00:00, 9.61kB/s]"}},"f2f1567b1a924fdfa9294d3ba0d16bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1ffee9773e2419eb477c7d805c37c67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"096754f92a0943bc9b5d8c05d2fa377e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73cbbb23fbf4465795a5b101541f81ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"040d6417172e44dd8d3b653235564239":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5d87904121248f998134ba9c164b36a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eff7536f8ad4134bdb795268b8146f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af9d1de993e14a6ead7b9bf4b29ad263":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa2cef53b5c94aadb65993b9e8643516","IPY_MODEL_36d8d89d38e74a0a8c6a1752796b64ed","IPY_MODEL_1f814c3783104cfaad874cce67030d18"],"layout":"IPY_MODEL_5ade96e501dc4ab4992afd4c9fe35857"}},"aa2cef53b5c94aadb65993b9e8643516":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b4ff6b93fb7466e82d779e3d9f40142","placeholder":"​","style":"IPY_MODEL_69ec8a1567c940e9b4c3d8589f068c6a","value":"1_Pooling/config.json: 100%"}},"36d8d89d38e74a0a8c6a1752796b64ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c84d656f95a64809a3e31dbbfcf79a35","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_218c3091ecfb4d5693159932c47d9e54","value":190}},"1f814c3783104cfaad874cce67030d18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5b0e40c0ae41e796b24bbeb7c87bb3","placeholder":"​","style":"IPY_MODEL_896097a80d154dd29ec2998fc7478381","value":" 190/190 [00:00&lt;00:00, 7.58kB/s]"}},"5ade96e501dc4ab4992afd4c9fe35857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b4ff6b93fb7466e82d779e3d9f40142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69ec8a1567c940e9b4c3d8589f068c6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c84d656f95a64809a3e31dbbfcf79a35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"218c3091ecfb4d5693159932c47d9e54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c5b0e40c0ae41e796b24bbeb7c87bb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"896097a80d154dd29ec2998fc7478381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}